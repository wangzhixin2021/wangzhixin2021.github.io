[{"title":"TCP三次握手-接收synack","url":"/2026/01/01/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B-%E6%8E%A5%E6%94%B6synack/","content":"我们知道，所有的ipv4的tcp包，进入tcp层的入口点，就是tcp_v4_rcv，客户端、服务端均是如此。在connect系统调用执行过程中，__inet_check_established中，会将该sk插入到ehash中，因此在tcp_v4_rcv中，收到synack包，__inet_lookup_skb查找到的就是ehash中的这个sk。并且此时的sk处于SYN_SENT状态，会走入tcp_v4_do_rcv的处理逻辑。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;\t...lookup:\t/* 查找该数据包所属的sk\t * 可能返回established sk，也可能是listen sk，也可能是NULL \t * 对于服务端来说，第一次握手包找到的是listen sk，客户端的ack(三次握手包)后查找到的应该是established sk\t * 返回NULL 代表没有TCP监听该端口，所以要给对端发reset包 */\tsk = __inet_lookup_skb(net-&gt;ipv4.tcp_death_row.hashinfo,\t\t\t       skb, __tcp_hdrlen(th), th-&gt;source,\t\t\t       th-&gt;dest, sdif, &amp;refcounted);\tif (!sk)\t\tgoto no_tcp_socket;\t...\tbh_lock_sock_nested(sk);\ttcp_segs_in(tcp_sk(sk), skb);\tret = 0;\tif (!sock_owned_by_user(sk)) &#123;\t\t/* 非listen，非timewait状态的，走这里 */\t\tret = tcp_v4_do_rcv(sk, skb);\t&#125; else &#123;\t\tif (tcp_add_backlog(sk, skb, &amp;drop_reason))\t\t\tgoto discard_and_relse;\t&#125;\tbh_unlock_sock(sk);\t...&#125;\n\n\n在tcp_v4_do_rcv，由于sk_state处于SYN_SENT状态，所以会直接调入tcp_rcv_state_process中。\n/*  * 由 tcp_v4_rcv 调用 * established状态的，收包 */int tcp_v4_do_rcv(struct sock *sk, struct sk_buff *skb)&#123;\tenum skb_drop_reason reason;\tstruct sock *rsk;\t/* sk 处于 ESTABLISHED 状态，走这里 */\tif (sk-&gt;sk_state == TCP_ESTABLISHED) &#123; /* Fast path */\t\tstruct dst_entry *dst;\t\tdst = rcu_dereference_protected(sk-&gt;sk_rx_dst,\t\t\t\t\t\tlockdep_sock_is_held(sk));\t\tsock_rps_save_rxhash(sk, skb);\t\tsk_mark_napi_id(sk, skb);\t\tif (dst) &#123;\t\t\tif (sk-&gt;sk_rx_dst_ifindex != skb-&gt;skb_iif ||\t\t\t    !INDIRECT_CALL_1(dst-&gt;ops-&gt;check, ipv4_dst_check,\t\t\t\t\t     dst, 0)) &#123;\t\t\t\tRCU_INIT_POINTER(sk-&gt;sk_rx_dst, NULL);\t\t\t\tdst_release(dst);\t\t\t&#125;\t\t&#125;\t\ttcp_rcv_established(sk, skb);\t\treturn 0;\t&#125;\t/* 校验和检查 */\treason = SKB_DROP_REASON_NOT_SPECIFIED;\tif (tcp_checksum_complete(skb))\t\tgoto csum_err;\t/* sk 处于 LISTEN 状态，走这里，即对第一次握手包的处理，\t * 也有特殊情况，比如 syn cookies，第一次、第三次握手包都会走进这里 */\tif (sk-&gt;sk_state == TCP_LISTEN) &#123;\t\t/* 处理syn cookie*/\t\tstruct sock *nsk = tcp_v4_cookie_check(sk, skb);\t\t/* 如果nsk为空，那一定是开启了syn cookies，走到了其中的处理逻辑，但是处理还失败了 */\t\tif (!nsk)\t\t\tgoto discard;\t\t/* 不相等，则代表syn cookie生效了，并且此时肯定是第三次握手，\t\t * nsk是新创建的client socket，这个nsk的状态是 TCP_SYN_RECV,\t\t * 是在 inet_csk_clone_lock 中设置的 nsk的状态 */\t\tif (nsk != sk) &#123;\t\t\t/* 这代表肯定新创建了syn cookie的nsk，并且是第三次握手，直接处理它即可 */\t\t\tif (tcp_child_process(sk, nsk, skb)) &#123;\t\t\t\trsk = nsk;\t\t\t\tgoto reset;\t\t\t&#125;\t\t\treturn 0;\t\t&#125;\t&#125; else &#123;\t\tsock_rps_save_rxhash(sk, skb);\t&#125;\t/* sk 的 状态进行处理，状态机？第一次握手肯定走这里(无论开没开启 syn cookies), 这里面会发送第二次握手包\t * 返回1 就会回个reset报文 */\tif (tcp_rcv_state_process(sk, skb)) &#123;\t\trsk = sk;\t\tgoto reset;\t&#125;\treturn 0;reset:\ttcp_v4_send_reset(rsk, skb);discard:\tkfree_skb_reason(skb, reason);\t/* Be careful here. If this function gets more complicated and\t * gcc suffers from register pressure on the x86, sk (in %ebx)\t * might be destroyed here. This current version compiles correctly,\t * but you have been warned.\t */\treturn 0;csum_err:\treason = SKB_DROP_REASON_TCP_CSUM;\ttrace_tcp_bad_csum(skb);\tTCP_INC_STATS(sock_net(sk), TCP_MIB_CSUMERRORS);\tTCP_INC_STATS(sock_net(sk), TCP_MIB_INERRS);\tgoto discard;&#125;EXPORT_SYMBOL(tcp_v4_do_rcv);\n\n\n在tcp_rcv_state_process中，更新下tcp相关时间戳，直接调用tcp_rcv_synsent_state_process，如果返回值大于等于0，直接return即可。如果小于0，检查是否设置了urg紧急指针，释放数据包，检查是否需要发送数据或ACK。\nint tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)&#123;\t...\tswitch (sk-&gt;sk_state) &#123;\tcase TCP_CLOSE:\t\tSKB_DR_SET(reason, TCP_CLOSE);\t\tgoto discard;\tcase TCP_LISTEN:\t\t/* listen状态，不处理ack包 */\t\tif (th-&gt;ack)\t\t\treturn 1;\t\t/* listen状态，rst，直接释放掉该包 */\t\tif (th-&gt;rst) &#123;\t\t\tSKB_DR_SET(reason, TCP_RESET);\t\t\tgoto discard;\t\t&#125;\t\t/* syn置位，这里是对第一次握手包的处理 */\t\tif (th-&gt;syn) &#123;\t\t\t/* fin也置位了，直接释放掉该包 */\t\t\tif (th-&gt;fin) &#123;\t\t\t\tSKB_DR_SET(reason, TCP_FLAGS);\t\t\t\tgoto discard;\t\t\t&#125;\t\t\t/* It is possible that we process SYN packets from backlog,\t\t\t * so we need to make sure to disable BH and RCU right there.\t\t\t */\t\t\trcu_read_lock();\t\t\tlocal_bh_disable();\t\t\t/* tcp_v4_conn_request ，里面会发送第二次握手包 */\t\t\tacceptable = icsk-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &gt;= 0;\t\t\tlocal_bh_enable();\t\t\trcu_read_unlock();\t\t\t/* 对第一次握手包的处理失败了，直接 return */\t\t\tif (!acceptable)\t\t\t\treturn 1;\t\t\t\t\t\t/* 对第一次握手包的处理成功了，第二次握手包发送完了，这里直接将第一次握手包消费掉 */\t\t\tconsume_skb(skb);\t\t\treturn 0;\t\t&#125;\t\tSKB_DR_SET(reason, TCP_FLAGS);\t\tgoto discard;\tcase TCP_SYN_SENT:\t\t/* 客户端收到第二次握手包后的处理逻辑 */\t\t/* 重置时间戳接收状态，当前处于协商期，不能沿用之前的状态 */\t\ttp-&gt;rx_opt.saw_tstamp = 0;\t\t/* 刷新 TCP 时间戳，用于rtt计算，rack、超时重传等 */\t\ttcp_mstamp_refresh(tp);\t\t/* &gt;= 0 ，代表数据包被消费了，\t\t * &lt; 0，该包不完全是 握手包，可能是带数据的包 */\t\tqueued = tcp_rcv_synsent_state_process(sk, skb, th);\t\tif (queued &gt;= 0)\t\t\treturn queued;\t\t/* Do step6 onward by hand. */\t\ttcp_urg(sk, skb, th);\t\t__kfree_skb(skb);\t\ttcp_data_snd_check(sk);\t\treturn 0;\t&#125;\t...&#125;\n\n\n在tcp_rcv_synsent_state_process中，主要就是负责对 第二次握手包进行处理。首先会解析发来的数据包里的tcp选项部分。收到的包正常情况下一般是syn+ack包。但是也可能是其他情况，比如纯rst包、rst+ack包、纯syn包等，也有相应的处理。我们主要看对携带了ack的报文的处理。首先会判断 应答序列号 是否在（snd_una, snd_nxt]区间内，如果不在，则是非法的ack报文，查看是否启动过重传定时器，如果没启动过，就启动重传定时器。goto reset_and_undo，恢复option状态。如果是合法的ack报文，判断时间戳是否合法。如果时间戳不合法，goto reset_and_undo，恢复option状态。如果ack报文中，rst置位了，那直接处理rst报文，释放数据包。如果ack报文中，syn没置位，说明是非法的，直接结束。如果syn置位了，那代表这是合法的syn+ack 第二次握手包。处理ECN协商，调用tcp_ack，然后更新rcv_nxt、rcv_wup，更新发送窗口大小、窗口扩大因子、时间戳、mss等。调用 tcp_finish_connect，它里面会将sk_state状态改为established。然后判断sock是否dead，没dead就唤醒 __inet_stream_connect 中阻塞等待connect完成的线程、epoll阻塞的线程。如果有未完成的写操作，或者延迟接受连接，或者pingpong模式，那么就不发送第三次握手包，等一会儿再说。如果没有，则直接调用tcp_send_ack，发送第三次握手包。\n/* 只由 tcp_rcv_state_process 调用， * 负责对 第二次握手包 的处理 */static int tcp_rcv_synsent_state_process(struct sock *sk, struct sk_buff *skb,\t\t\t\t\t const struct tcphdr *th)&#123;\tstruct inet_connection_sock *icsk = inet_csk(sk);\tstruct tcp_sock *tp = tcp_sk(sk);\tstruct tcp_fastopen_cookie foc = &#123; .len = -1 &#125;;\tint saved_clamp = tp-&gt;rx_opt.mss_clamp;\tbool fastopen_fail;\tSKB_DR(reason);\t/* 解析tcp选项，如 mss、window、timestamp、sack、fastopen */\ttcp_parse_options(sock_net(sk), skb, &amp;tp-&gt;rx_opt, 0, &amp;foc);\tif (tp-&gt;rx_opt.saw_tstamp &amp;&amp; tp-&gt;rx_opt.rcv_tsecr)\t\ttp-&gt;rx_opt.rcv_tsecr -= tp-&gt;tsoffset;\t/* 一般正常情况下，第二次握手包ack都应该置位了 */\tif (th-&gt;ack) &#123;\t\t/* rfc793:\t\t * &quot;If the state is SYN-SENT then\t\t *    first check the ACK bit\t\t *      If the ACK bit is set\t\t *\t  If SEG.ACK =&lt; ISS, or SEG.ACK &gt; SND.NXT, send\t\t *        a reset (unless the RST bit is set, if so drop\t\t *        the segment and return)&quot;\t\t * \t\t * 如果 ACK &lt;= snd_una（太旧）或 ACK &gt; snd_nxt（越界），\t\t * 说明对端 ACK 不合法\t\t */\t\tif (!after(TCP_SKB_CB(skb)-&gt;ack_seq, tp-&gt;snd_una) ||\t\t    after(TCP_SKB_CB(skb)-&gt;ack_seq, tp-&gt;snd_nxt)) &#123;\t\t\t/* Previous FIN/ACK or RST/ACK might be ignored. \t\t\t * 如果这是第一次重传之前就遇到非法 ACK，\t\t\t * 需要重新启动重传定时器\t\t\t */\t\t\tif (icsk-&gt;icsk_retransmits == 0)\t\t\t\tinet_csk_reset_xmit_timer(sk,\t\t\t\t\t\tICSK_TIME_RETRANS,\t\t\t\t\t\tTCP_TIMEOUT_MIN, TCP_RTO_MAX);\t\t\t/* 因为收到了非法ack，恢复 option 状态 */\t\t\tgoto reset_and_undo;\t\t&#125;\t\t/* 时间戳必须在合法窗口内 */\t\tif (tp-&gt;rx_opt.saw_tstamp &amp;&amp; tp-&gt;rx_opt.rcv_tsecr &amp;&amp;\t\t    !between(tp-&gt;rx_opt.rcv_tsecr, tp-&gt;retrans_stamp,\t\t\t     tcp_time_stamp(tp))) &#123;\t\t\tNET_INC_STATS(sock_net(sk),\t\t\t\t\tLINUX_MIB_PAWSACTIVEREJECTED);\t\t\tgoto reset_and_undo;\t\t&#125;\t\t/* Now ACK is acceptable.\t\t *\t\t * &quot;If the RST bit is set\t\t *    If the ACK was acceptable then signal the user &quot;error:\t\t *    connection reset&quot;, drop the segment, enter CLOSED state,\t\t *    delete TCB, and return.&quot;\t\t *  如果第二次握手包里面是带有rst的ack包，直接结束\t\t */\t\tif (th-&gt;rst) &#123;\t\t\ttcp_reset(sk, skb);consume:\t\t\t__kfree_skb(skb);\t\t\treturn 0;\t\t&#125;\t\t/* rfc793:\t\t *   &quot;fifth, if neither of the SYN or RST bits is set then\t\t *    drop the segment and return.&quot;\t\t *\t\t *    See note below!\t\t *                                        --ANK(990513)\t\t *  如果第二次握手包里面是没有syn的ack包，说明是非法的，直接结束\t\t */\t\tif (!th-&gt;syn) &#123;\t\t\tSKB_DR_SET(reason, TCP_FLAGS);\t\t\tgoto discard_and_undo;\t\t&#125;\t\t/* 走到这里一定是不含rst，包含syn、ack的包 */\t\t/* rfc793:\t\t *   &quot;If the SYN bit is on ...\t\t *    are acceptable then ...\t\t *    (our SYN has been ACKed), change the connection\t\t *    state to ESTABLISHED...&quot;\t\t */\t\t/* 处理 ECN 协商 */\t\ttcp_ecn_rcv_synack(tp, th);\t\t/* 初始化 snd_wl1 */\t\ttcp_init_wl(tp, TCP_SKB_CB(skb)-&gt;seq);\t\ttcp_try_undo_spurious_syn(sk);\t\ttcp_ack(sk, skb, FLAG_SLOWPATH);\t\t/* Ok.. it&#x27;s good. Set up sequence numbers and\t\t * move to established.\t\t */\t\t/* 更新下一个希望接收的序列号 */\t\tWRITE_ONCE(tp-&gt;rcv_nxt, TCP_SKB_CB(skb)-&gt;seq + 1);\t\ttp-&gt;rcv_wup = TCP_SKB_CB(skb)-&gt;seq + 1;\t\t/* RFC1323: The window in SYN &amp; SYN/ACK segments is\t\t * never scaled.\t\t */\t\t\t\t/* 这里是发送窗口的大小，从接收的报文中获取的 */\t\ttp-&gt;snd_wnd = ntohs(th-&gt;window);\t\t/* 是否支持窗口扩大因子 */\t\tif (!tp-&gt;rx_opt.wscale_ok) &#123;\t\t\ttp-&gt;rx_opt.snd_wscale = tp-&gt;rx_opt.rcv_wscale = 0;\t\t\ttp-&gt;window_clamp = min(tp-&gt;window_clamp, 65535U);\t\t&#125;\t\t/* 是否有时间戳选项 */\t\tif (tp-&gt;rx_opt.saw_tstamp) &#123;\t\t\ttp-&gt;rx_opt.tstamp_ok\t   = 1;\t\t\ttp-&gt;tcp_header_len =\t\t\t\tsizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED;\t\t\ttp-&gt;advmss\t    -= TCPOLEN_TSTAMP_ALIGNED;\t\t\ttcp_store_ts_recent(tp);\t\t&#125; else &#123;\t\t\ttp-&gt;tcp_header_len = sizeof(struct tcphdr);\t\t&#125;\t\t/* mss相关处理 */\t\ttcp_sync_mss(sk, icsk-&gt;icsk_pmtu_cookie);\t\ttcp_initialize_rcv_mss(sk);\t\t/* Remember, tcp_poll() does not lock socket!\t\t * Change state from SYN-SENT only after copied_seq\t\t * is initialized. */\t\tWRITE_ONCE(tp-&gt;copied_seq, tp-&gt;rcv_nxt);\t\tsmc_check_reset_syn(tp);\t\tsmp_mb();\t\t/* established状态在这个里面置位的，\t\t * 并且会判断是否需要设置保活定时器 */\t\ttcp_finish_connect(sk, skb);\t\tfastopen_fail = (tp-&gt;syn_fastopen || tp-&gt;syn_data) &amp;&amp;\t\t\t\ttcp_rcv_fastopen_synack(sk, skb, &amp;foc);\t\tif (!sock_flag(sk, SOCK_DEAD)) &#123;\t\t\t/* 唤醒 __inet_stream_connect 中阻塞等待connect完成的线程 */\t\t\tsk-&gt;sk_state_change(sk);\t\t\t/* 唤醒epoll阻塞的线程 */\t\t\tsk_wake_async(sk, SOCK_WAKE_IO, POLL_OUT);\t\t&#125;\t\tif (fastopen_fail)\t\t\treturn -1;\t\t\t\t/* 如果有未完成的写操作，或者延迟接受连接，或者pingpong模式，\t\t * 那么就不发送第三次握手包，等一会儿再说 */\t\tif (sk-&gt;sk_write_pending ||\t\t    READ_ONCE(icsk-&gt;icsk_accept_queue.rskq_defer_accept) ||\t\t    inet_csk_in_pingpong_mode(sk)) &#123;\t\t\t/* Save one ACK. Data will be ready after\t\t\t * several ticks, if write_pending is set.\t\t\t *\t\t\t * It may be deleted, but with this feature tcpdumps\t\t\t * look so _wonderfully_ clever, that I was not able\t\t\t * to stand against the temptation 8)     --ANK\t\t\t */\t\t\tinet_csk_schedule_ack(sk);\t\t\ttcp_enter_quickack_mode(sk, TCP_MAX_QUICKACKS);\t\t\tinet_csk_reset_xmit_timer(sk, ICSK_TIME_DACK,\t\t\t\t\t\t  TCP_DELACK_MAX, TCP_RTO_MAX);\t\t\tgoto consume;\t\t&#125;\t\t/* 发送第三次握手包 */\t\ttcp_send_ack(sk);\t\treturn -1;\t&#125;\t/* No ACK in the segment \t * 收到的第二次握手包，没有ack，特殊情况的处理，可能是reset了 */\tif (th-&gt;rst) &#123;\t\t/* rfc793:\t\t * &quot;If the RST bit is set\t\t *\t\t *      Otherwise (no ACK) drop the segment and return.&quot;\t\t */\t\tSKB_DR_SET(reason, TCP_RESET);\t\tgoto discard_and_undo;\t&#125;\t/* PAWS check. */\tif (tp-&gt;rx_opt.ts_recent_stamp &amp;&amp; tp-&gt;rx_opt.saw_tstamp &amp;&amp;\t    tcp_paws_reject(&amp;tp-&gt;rx_opt, 0)) &#123;\t\tSKB_DR_SET(reason, TCP_RFC7323_PAWS);\t\tgoto discard_and_undo;\t&#125;\t/* 走到这里的是，对方给我发了syn 无ack的包(对方发来第一次握手包) */ \tif (th-&gt;syn) &#123;\t\t/* We see SYN without ACK. It is attempt of\t\t * simultaneous connect with crossed SYNs.\t\t * Particularly, it can be connect to self.\t\t * tcp自连接？\t\t */\t\ttcp_set_state(sk, TCP_SYN_RECV);\t\tif (tp-&gt;rx_opt.saw_tstamp) &#123;\t\t\ttp-&gt;rx_opt.tstamp_ok = 1;\t\t\ttcp_store_ts_recent(tp);\t\t\ttp-&gt;tcp_header_len =\t\t\t\tsizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED;\t\t&#125; else &#123;\t\t\ttp-&gt;tcp_header_len = sizeof(struct tcphdr);\t\t&#125;\t\tWRITE_ONCE(tp-&gt;rcv_nxt, TCP_SKB_CB(skb)-&gt;seq + 1);\t\tWRITE_ONCE(tp-&gt;copied_seq, tp-&gt;rcv_nxt);\t\ttp-&gt;rcv_wup = TCP_SKB_CB(skb)-&gt;seq + 1;\t\t/* RFC1323: The window in SYN &amp; SYN/ACK segments is\t\t * never scaled.\t\t */\t\ttp-&gt;snd_wnd    = ntohs(th-&gt;window);\t\ttp-&gt;snd_wl1    = TCP_SKB_CB(skb)-&gt;seq;\t\ttp-&gt;max_window = tp-&gt;snd_wnd;\t\ttcp_ecn_rcv_syn(tp, th);\t\ttcp_mtup_init(sk);\t\ttcp_sync_mss(sk, icsk-&gt;icsk_pmtu_cookie);\t\ttcp_initialize_rcv_mss(sk);\t\ttcp_send_synack(sk);#if 0\t\t/* Note, we could accept data and URG from this segment.\t\t * There are no obstacles to make this (except that we must\t\t * either change tcp_recvmsg() to prevent it from returning data\t\t * before 3WHS completes per RFC793, or employ TCP Fast Open).\t\t *\t\t * However, if we ignore data in ACKless segments sometimes,\t\t * we have no reasons to accept it sometimes.\t\t * Also, seems the code doing it in step6 of tcp_rcv_state_process\t\t * is not flawless. So, discard packet for sanity.\t\t * Uncomment this return to process the data.\t\t */\t\treturn -1;#else\t\tgoto consume;#endif\t&#125;\t/* &quot;fifth, if neither of the SYN or RST bits is set then\t * drop the segment and return.&quot;\t */discard_and_undo:\ttcp_clear_options(&amp;tp-&gt;rx_opt);\ttp-&gt;rx_opt.mss_clamp = saved_clamp;\ttcp_drop_reason(sk, skb, reason);\treturn 0;reset_and_undo:\ttcp_clear_options(&amp;tp-&gt;rx_opt);\ttp-&gt;rx_opt.mss_clamp = saved_clamp;\treturn 1;&#125;\n\n\n在tcp_finish_connect，会将sk_state置为established，更新最后一次接收到数据包的时间戳，查看是否需要开启保活定时器。\n/* 只由 tcp_rcv_synsent_state_process 、 tcp_connect 调用 */void tcp_finish_connect(struct sock *sk, struct sk_buff *skb)&#123;\tstruct tcp_sock *tp = tcp_sk(sk);\tstruct inet_connection_sock *icsk = inet_csk(sk);\t/* 收到了第二次握手包，并且握手包是合法的，状态置为established */\ttcp_set_state(sk, TCP_ESTABLISHED);\t/* 更新下最后一次接收到数据包的时间戳 */\ticsk-&gt;icsk_ack.lrcvtime = tcp_jiffies32;\tif (skb) &#123;\t\ticsk-&gt;icsk_af_ops-&gt;sk_rx_dst_set(sk, skb);\t\tsecurity_inet_conn_established(sk, skb);\t\tsk_mark_napi_id(sk, skb);\t&#125;\ttcp_init_transfer(sk, BPF_SOCK_OPS_ACTIVE_ESTABLISHED_CB, skb);\t/* Prevent spurious tcp_cwnd_restart() on first data\t * packet.\t */\ttp-&gt;lsndtime = tcp_jiffies32;\t/* 如果开启了tcp保活机制，那就设置下保活定时器 */\tif (sock_flag(sk, SOCK_KEEPOPEN))\t\tinet_csk_reset_keepalive_timer(sk, keepalive_time_when(tp));\tif (!tp-&gt;rx_opt.snd_wscale)\t\t__tcp_fast_path_on(tp, tp-&gt;snd_wnd);\telse\t\ttp-&gt;pred_flags = 0;&#125;\n\n","categories":["linux6.6内核"],"tags":["socket","网络","tcp建连"]},{"title":"TCP三次握手-接收syn（一）","url":"/2025/12/25/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B-%E6%8E%A5%E6%94%B6syn%EF%BC%88%E4%B8%80%EF%BC%89/","content":"数据包达到网卡，以及触发硬中断、软中断接收数据包，然后送往内核网络协议栈部分，我们暂时省略，后续再介绍。我们直接从 tcp_v4_rcv 开始看，这是tcp数据包从网络层到传输层的入口点。\nsyn包达到服务端后，通过 tcp_v4_rcv 送到了传输层tcp处理入口。首先会从 skb-&gt;pkt_type 中判断，这个数据包是不是发往本机的(PACKET_HOST)，如果不是发往本机的，直接跳转到 discard_it，将数据包释放掉。\n/*   *  tcp_protocol， *  由 ip_protocol_deliver_rcu 调用 *  这是tcp数据包从网络层到传输层的入口点 *\tFrom tcp_input.c  */int tcp_v4_rcv(struct sk_buff *skb)&#123;\t/* 先拿到skb的所属网络设备的所属网络命名空间 */\tstruct net *net = dev_net(skb-&gt;dev);\tenum skb_drop_reason drop_reason;\tint sdif = inet_sdif(skb);\tint dif = inet_iif(skb);\tconst struct iphdr *iph;\tconst struct tcphdr *th;\t/* 该值为true时，代表找到的sk是ehash里面的，在 __inet_lookup_established 中有加引用计数\t * 所以搞个标志，便于后面不用的时候要减掉引用计数 */\tbool refcounted;\tstruct sock *sk;\tint ret;\tdrop_reason = SKB_DROP_REASON_NOT_SPECIFIED;\t/* 不是发给本机的包，直接丢弃，比如 网卡处于混杂模式*/\tif (skb-&gt;pkt_type != PACKET_HOST)\t\tgoto discard_it;        ...discard_it:\tSKB_DR_OR(drop_reason, NOT_SPECIFIED);\t/* Discard frame. */\tkfree_skb_reason(skb, drop_reason);\treturn 0;&#125;\n\n\n无论包是否合法，只要是发给tcp的，并且是发给本机的包，都增加计数。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;    ...\t/* Count it even if it&#x27;s bad ，\t * 无论包是否合法，只要是发给tcp的，并且是发给本机的包，都增加计数，\t * 该计数可以在 netstat -st | grep segments 看到 */\t__TCP_INC_STATS(net, TCP_MIB_INSEGS);    ...&#125;\n\n\n然后调用 pskb_may_pull 确保 skb的线性部分必须至少包含tcp报文头，防止其在非线性部分，因为我们需要tcp头中的数据来做一些基本判断。因为ip层已经确保过ip头了，并且在 ip_local_deliver_finish 中，已经将data拉过ip头了，所以这里仅需要pull tcphdr大小即可。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;    ...\t/*  确保 skb 中线性部分至少包含完整 TCP 报文头，确保完整性，防止 tcp头 在非线性部分\t *  这里为什么只确保了tcphdr？\t *  原因是 数据包已经从网络层到达传输层，在交付过来时，已经对skb做过处理\t *  可查看 ip_local_deliver_finish ，调用了 __skb_pull */\tif (!pskb_may_pull(skb, sizeof(struct tcphdr)))\t\tgoto discard_it;    ...&#125;\n\n\n此时的skb的data一定指向的就是tcp头，但是我感觉直接用 tcp_hdr更好点。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;    ...     /* 正是因为传递过来之前已经__skb_pull了，所以skb-&gt;data指向的就已经是tcp头这块了 \t * 但是其实最好还是调用 tcp_hdr 会更安全 */\tth = (const struct tcphdr *)skb-&gt;data;    ...&#125;\n\n\n判断下tcp头部的doff，注意它占四位，最多表示15，但是它的单位是4字节，也就是最多60字节，tcp选项最多也就是60-固定长度(20)&#x3D;40字节。如果doff小于5，那铁定包有问题。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;    ... \t/* 坏包 */\tif (unlikely(th-&gt;doff &lt; sizeof(struct tcphdr) / 4)) &#123;\t\tdrop_reason = SKB_DROP_REASON_PKT_TOO_SMALL;\t\tgoto bad_packet;\t&#125;    ...&#125;\n\n\n可能有tcp选项，但是刚才我们只确保了线性部分至少包含tcphdr(20字节)，现在我们由doff，我们就再次确保整个tcp固定头部+选项头部全部在线性部分。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;    ... \t/* 可能有tcp选项，再pull下，确保skb线性部分至少包含tcp固定头部加tcp选项部分 */\tif (!pskb_may_pull(skb, th-&gt;doff * 4))\t\tgoto discard_it;    ...&#125;\n\n\n初始化并验证 TCP 校验和的计算条件，如果校验和明显不可能正确（或无法计算），直接判定为校验错误，丢包。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;    ... \tif (skb_checksum_init(skb, IPPROTO_TCP, inet_compute_pseudo))\t\tgoto csum_error;    ...&#125;\n\n\n因为前面为了确保tcp选项也在线性部分，调用该pskb_may_pull了，当长度不够时，它会重新申请内存挪过去，所以还得再次更新下tcp头部指针，防止其指向的是已失效的地址。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;    ... \t/* pskb_may_pull了，所以再次更新下tcp头指针 */\tth = (const struct tcphdr *)skb-&gt;data;\tiph = ip_hdr(skb);    ...&#125;\n\n\n进入关键逻辑，来了一个发送本机的包，并且基本信息没明显问题，那就应该要寻找这个skb到底是属于哪个sk了，这决定哪个sk来接收这个skb啊。是调用__inet_lookup_skb来查找的，传入的 net-&gt;ipv4.tcp_death_row.hashinfo，很明显，这里面是该skb所属 网络命名空间 中来管理tcp各种哈希表集合的结构，such as ehash 、 bhash 、 bhash2 、 lhash2。它是在 tcp_set_hashinfo 中设置的, 如果是初始网络命名空间(init_net)，它指向 全局变量 tcp_hashinfo， 如果不是初始网络命名空间，它指向 动态申请的 inet_hashinfo结构。如果没找到sk，那就要根据其校验和是否正确来做处理，如果校验和正确，那给对方回个rst。如果校验和不对，那就不回rst了，直接更新下计数，释放掉包即可。如果找到了sk，才继续走后面的处理。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;    ... lookup:\t/* 查找该数据包所属的sk\t * 可能返回established sk，也可能是listen sk，也可能是NULL \t * 对于服务端来说，第一次握手包找到的是listen sk，客户端的ack(三次握手包)后查找到的应该是established sk\t * 返回NULL 代表没有TCP监听该端口，所以要给对端发reset包 */\tsk = __inet_lookup_skb(net-&gt;ipv4.tcp_death_row.hashinfo,\t\t\t       skb, __tcp_hdrlen(th), th-&gt;source,\t\t\t       th-&gt;dest, sdif, &amp;refcounted);\tif (!sk)\t\tgoto no_tcp_socket;    ...no_tcp_socket:\tdrop_reason = SKB_DROP_REASON_NO_SOCKET;\tif (!xfrm4_policy_check(NULL, XFRM_POLICY_IN, skb))\t\tgoto discard_it;\ttcp_v4_fill_cb(skb, iph, th);\tif (tcp_checksum_complete(skb)) &#123;csum_error:\t\tdrop_reason = SKB_DROP_REASON_TCP_CSUM;\t\ttrace_tcp_bad_csum(skb);\t\t__TCP_INC_STATS(net, TCP_MIB_CSUMERRORS);bad_packet:\t\t__TCP_INC_STATS(net, TCP_MIB_INERRS);\t&#125; else &#123;\t\t/* 校验和正确，没有找到所属的sk，回个reset包 */\t\ttcp_v4_send_reset(NULL, skb);\t&#125;    ...&#125;\n\nstruct inet_hashinfo &#123;\t/* This is for sockets with full identity only.  Sockets here will\t * always be without wildcards and will have the following invariant:\t *\t *          TCP_ESTABLISHED &lt;= sk-&gt;sk_state &lt; TCP_CLOSE\t *\t * 存储 established 状态sk的哈希表\t * key为 四元组 、 随机值 、 hash_mix\t * 哈希函数为 inet_ehashfn  */\tstruct inet_ehash_bucket\t*ehash;\tspinlock_t\t\t\t*ehash_locks;\t/* ehash_mask 为 ehash 哈希桶数量减1 */\tunsigned int\t\t\tehash_mask;\tunsigned int\t\t\tehash_locks_mask;\t/* Ok, let&#x27;s try this, I give up, we do need a local binding\t * TCP hash as well as the others for fast bind/connect.\t */\tstruct kmem_cache\t\t*bind_bucket_cachep;\t/* This bind table is hashed by local port \t * 存储 端口 相关sk的哈希表\t * key为 本地端口 、 hash_mix\t * 哈希函数为inet_bhashfn \t */\tstruct inet_bind_hashbucket\t*bhash;\tstruct kmem_cache\t\t*bind2_bucket_cachep;\t/* This bind table is hashed by local port and sk-&gt;sk_rcv_saddr (ipv4)\t * or sk-&gt;sk_v6_rcv_saddr (ipv6). This 2nd bind table is used\t * primarily for expediting bind conflict resolution.\t * 存储 地址、端口 相关sk的哈希表2\t * key为 本地地址、本地端口、hash_mix\t * 哈希函数为 ipv4_portaddr_hash\t */\tstruct inet_bind_hashbucket\t*bhash2;\tunsigned int\t\t\tbhash_size;\t/* The 2nd listener table hashed by local port and address \t * ehash_mask 为 ehash 哈希桶数量减1 */\tunsigned int\t\t\tlhash2_mask;\t/* 存储 listen 状态sk的哈希表2\t * key为 本地地址、本地端口 、hash_mix \t * 哈希函数为 ipv4_portaddr_hash \t */\tstruct inet_listen_hashbucket\t*lhash2;\tbool\t\t\t\tpernet;&#125; ____cacheline_aligned_in_smp;struct inet_timewait_death_row &#123;\trefcount_t\t\ttw_refcount;\t/* Padding to avoid false sharing, tw_refcount can be often written \t * 在 tcp_set_hashinfo 中设置的, 如果是初始网络命名空间(init_net)，它指向 tcp_hashinfo \t * 如果不是初始网络命名空间，它指向 动态申请的 inet_hashinfo */\tstruct inet_hashinfo \t*hashinfo ____cacheline_aligned_in_smp;\tint\t\t\tsysctl_max_tw_buckets;&#125;;\n\n\n\n先尝试查看是否早期解复用，找到过skb所属sk，如果解复用过，那就直接返回sk即可。解复用是在 ip_rcv_finish_core中做的。\n没有解复用过，调用 __inet_lookup 去查找。\n\n/* 由 tcp_v4_rcv 调用  * 查找skb所属的sk * 按照以下顺序查找：先看是否早期解复用过、established 查找、listener 查找 */static inline struct sock *__inet_lookup_skb(struct inet_hashinfo *hashinfo,\t\t\t\t\t     struct sk_buff *skb,\t\t\t\t\t     int doff,\t\t\t\t\t     const __be16 sport,\t\t\t\t\t     const __be16 dport,\t\t\t\t\t     const int sdif,\t\t\t\t\t     bool *refcounted)&#123;\tstruct net *net = dev_net(skb_dst(skb)-&gt;dev);\tconst struct iphdr *iph = ip_hdr(skb);\tstruct sock *sk;\t/* 尝试查看是否早期解复用，找到过skb所属sk */\tsk = inet_steal_sock(net, skb, doff, iph-&gt;saddr, sport, iph-&gt;daddr, dport,\t\t\t     refcounted, inet_ehashfn);\tif (IS_ERR(sk))\t\treturn NULL;\tif (sk)\t\treturn sk;\t/* 没有早期解复用过，去skb的所属网络设备的所属网络命名空间的哈希表里查下 */\treturn __inet_lookup(net, hashinfo, skb,\t\t\t     doff, iph-&gt;saddr, sport,\t\t\t     iph-&gt;daddr, dport, inet_iif(skb), sdif,\t\t\t     refcounted);&#125;\n\n\n可以看到，解复用就是判断了下tcp头部是否合法，合法则去 tcp哈希表集合中的 ehash哈希表中查找是否能找到匹配的sk。\n/* 由 ip_rcv_finish_core 调用 */int tcp_v4_early_demux(struct sk_buff *skb)&#123;\tstruct net *net = dev_net(skb-&gt;dev);\tconst struct iphdr *iph;\tconst struct tcphdr *th;\tstruct sock *sk;\tif (skb-&gt;pkt_type != PACKET_HOST)\t\treturn 0;\tif (!pskb_may_pull(skb, skb_transport_offset(skb) + sizeof(struct tcphdr)))\t\treturn 0;\tiph = ip_hdr(skb);\tth = tcp_hdr(skb);\tif (th-&gt;doff &lt; sizeof(struct tcphdr) / 4)\t\treturn 0;\tsk = __inet_lookup_established(net, net-&gt;ipv4.tcp_death_row.hashinfo,\t\t\t\t       iph-&gt;saddr, th-&gt;source,\t\t\t\t       iph-&gt;daddr, ntohs(th-&gt;dest),\t\t\t\t       skb-&gt;skb_iif, inet_sdif(skb));\tif (sk) &#123;\t\tskb-&gt;sk = sk;\t\tskb-&gt;destructor = sock_edemux;\t\tif (sk_fullsock(sk)) &#123;\t\t\tstruct dst_entry *dst = rcu_dereference(sk-&gt;sk_rx_dst);\t\t\tif (dst)\t\t\t\tdst = dst_check(dst, 0);\t\t\tif (dst &amp;&amp;\t\t\t    sk-&gt;sk_rx_dst_ifindex == skb-&gt;skb_iif)\t\t\t\tskb_dst_set_noref(skb, dst);\t\t&#125;\t&#125;\treturn 0;&#125;\n\n\n在**__inet_lookup**中，也是先去 ehash 中查找，如果有匹配的sk，就直接返回。如果没有匹配的sk，代表跟发这个包的客户端还没有建立连接，那就去 lhash2 中找下，如果找到了，那当前肯定就处于建连过程，直接返回该 listen sk。如果没找到，就代表没有sk监听这个端口，那这个包就没有所属的sk，那就返回空。\n/* 由 __inet_lookup_skb 、 inet_lookup 调用  * 查找skb所属sk，先从established里找，找不到再从listener里面找 */static inline struct sock *__inet_lookup(struct net *net,\t\t\t\t\t struct inet_hashinfo *hashinfo,\t\t\t\t\t struct sk_buff *skb, int doff,\t\t\t\t\t const __be32 saddr, const __be16 sport,\t\t\t\t\t const __be32 daddr, const __be16 dport,\t\t\t\t\t const int dif, const int sdif,\t\t\t\t\t bool *refcounted)&#123;\tu16 hnum = ntohs(dport);\tstruct sock *sk;\t/* 先去 hashinfo 的 ehash 哈希表里面查下 */\tsk = __inet_lookup_established(net, hashinfo, saddr, sport,\t\t\t\t       daddr, hnum, dif, sdif);\t*refcounted = true;\tif (sk)\t\treturn sk;\t*refcounted = false;\t/* 再去 hashinfo 的 lhash2 哈希表里面查下 */\treturn __inet_lookup_listener(net, hashinfo, skb, doff, saddr,\t\t\t\t      sport, daddr, hnum, dif, sdif);&#125;\n\n\n计算ehash上的hash值，拿到对应哈希桶，遍历所有entry。如果ip port 收发网口均匹配，那就增加引用计数。再次判断是否匹配，因为加引用计数时，socket信息可能被并发修改了。还匹配，那就是找到了已连接的sk，返回它。反之，再次去查找。\n/* 由 __inet_lookup 、 tcp_v4_early_demux 调用 */struct sock *__inet_lookup_established(struct net *net,\t\t\t\t  struct inet_hashinfo *hashinfo,\t\t\t\t  const __be32 saddr, const __be16 sport,\t\t\t\t  const __be32 daddr, const u16 hnum,\t\t\t\t  const int dif, const int sdif)&#123;\tINET_ADDR_COOKIE(acookie, saddr, daddr);\tconst __portpair ports = INET_COMBINED_PORTS(sport, hnum);\tstruct sock *sk;\tconst struct hlist_nulls_node *node;\t/* Optimize here for direct hit, only listening connections can\t * have wildcards anyways.\t * 计算哈希，并拿到所在ehash的哈希桶\t */\tunsigned int hash = inet_ehashfn(net, daddr, hnum, saddr, sport);\tunsigned int slot = hash &amp; hashinfo-&gt;ehash_mask;\t/* 拿到具体的哈希桶 */\tstruct inet_ehash_bucket *head = &amp;hashinfo-&gt;ehash[slot];begin:\t/* 遍历所属的哈希桶上的所有entry */\tsk_nulls_for_each_rcu(sk, node, &amp;head-&gt;chain) &#123;\t\t/* hash不相等，那只是哈希冲突了，落在一个桶上，此sk不是我们的目标 */\t\tif (sk-&gt;sk_hash != hash)\t\t\tcontinue;\t\t/* 比较ip port 收发网口是否完全匹配 */\t\tif (likely(inet_match(net, sk, acookie, ports, dif, sdif))) &#123;\t\t\t/* 如果找到了匹配的sk ，但是它正在销毁，那就返回空 */\t\t\tif (unlikely(!refcount_inc_not_zero(&amp;sk-&gt;sk_refcnt)))\t\t\t\tgoto out;\t\t\t/* 再次检查是否匹配，因为加引用过程，可能socket的信息又被并发改了 */\t\t\tif (unlikely(!inet_match(net, sk, acookie,\t\t\t\t\t\t ports, dif, sdif))) &#123;\t\t\t\tsock_gen_put(sk);\t\t\t\tgoto begin;\t\t\t&#125;\t\t\tgoto found;\t\t&#125;\t&#125;\t/*\t * if the nulls value we got at the end of this lookup is\t * not the expected one, we must restart lookup.\t * We probably met an item that was moved to another chain.\t */\tif (get_nulls_value(node) != slot)\t\tgoto begin;out:\tsk = NULL;found:\treturn sk;&#125;EXPORT_SYMBOL_GPL(__inet_lookup_established);\n\n\n如果 ehash 中没找到匹配的sk，那就在 lhash2 上找，首先是 daddr 和 hnum 去找，如果没有，则尝试 INADDR_ANY hnum 去找，因为有可能绑定的地址就是 INADDR_ANY。\n/* 由 __inet_lookup 、 inet_lookup_listener 、 tcp_v4_send_reset 调用 */struct sock *__inet_lookup_listener(struct net *net,\t\t\t\t    struct inet_hashinfo *hashinfo,\t\t\t\t    struct sk_buff *skb, int doff,\t\t\t\t    const __be32 saddr, __be16 sport,\t\t\t\t    const __be32 daddr, const unsigned short hnum,\t\t\t\t    const int dif, const int sdif)&#123;\t/* lhash2上的哈希桶 */\tstruct inet_listen_hashbucket *ilb2;\t/* 存储查找到的sk */\tstruct sock *result = NULL;\t/* 存储daddr和hnum计算的hash值 */\tunsigned int hash2;\t/* Lookup redirect from BPF */\tif (static_branch_unlikely(&amp;bpf_sk_lookup_enabled) &amp;&amp;\t    hashinfo == net-&gt;ipv4.tcp_death_row.hashinfo) &#123;\t\tresult = inet_lookup_run_sk_lookup(net, IPPROTO_TCP, skb, doff,\t\t\t\t\t\t   saddr, sport, daddr, hnum, dif,\t\t\t\t\t\t   inet_ehashfn);\t\tif (result)\t\t\tgoto done;\t&#125;\t/* 根据daddr、hnum 计算lhash2表上的hash值 */\thash2 = ipv4_portaddr_hash(net, daddr, hnum);\t/* 根据hash2，拿到lhash2上对应的哈希桶 */\tilb2 = inet_lhash2_bucket(hashinfo, hash2);\t/* 先根据 skb里面ip头中的daddr 去找，如果找到了，直接返回 */\tresult = inet_lhash2_lookup(net, ilb2, skb, doff,\t\t\t\t    saddr, sport, daddr, hnum,\t\t\t\t    dif, sdif);\tif (result)\t\tgoto done;\t/* Lookup lhash2 with INADDR_ANY \t * 根据 INADDR_ANY 、hnum 计算lhash2表上的hash值 */\thash2 = ipv4_portaddr_hash(net, htonl(INADDR_ANY), hnum);\t/* 再次拿到 新hash2 对应的lhash2上的哈希桶 */\tilb2 = inet_lhash2_bucket(hashinfo, hash2);\t/* 再根据 INADDR_ANY 去找 */\tresult = inet_lhash2_lookup(net, ilb2, skb, doff,\t\t\t\t    saddr, sport, htonl(INADDR_ANY), hnum,\t\t\t\t    dif, sdif);done:\tif (IS_ERR(result))\t\treturn NULL;\treturn result;&#125;EXPORT_SYMBOL_GPL(__inet_lookup_listener);\n\n\n经过上面的流程，我们又回到了 tcp_v4_rcv 中，此时已经找到了匹配的sk，则去判断 sk当前处于什么状态。针对首次建立连接，此时的sk大概率是从 lhash2 中找到的listen sk，此时应该处于 TCP_LISTEN。会调用 tcp_v4_do_rcv，处理完后，直接第一次握手包接收就结束了。因此我们要着重看  tcp_v4_do_rcv 的逻辑实现。我们放到下篇来介绍。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;    ...\t/* 处于 TCP_LISTEN 状态的服务端收到发往该sk上的包后，走这里的处理逻辑\t * 这个sk是在lhash2里面找到的\t * 即第一次握手包是在这里接收的，第二次握手包是在这里面发送的 */\tif (sk-&gt;sk_state == TCP_LISTEN) &#123;\t\t/* listen状态的，走这里 */\t\tret = tcp_v4_do_rcv(sk, skb);\t\tgoto put_and_return;\t&#125;    ...put_and_return:\tif (refcounted)\t\tsock_put(sk);\treturn ret;    ...&#125;\n\n","categories":["linux6.6内核"],"tags":["socket","网络","tcp建连"]},{"title":"TCP三次握手-接收ack","url":"/2026/01/05/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B-%E6%8E%A5%E6%94%B6ack/","content":"我们知道，所有的ipv4的tcp包，进入tcp层的入口点，就是tcp_v4_rcv，客户端、服务端均是如此。所以第三次握手包，服务端一定是在tcp_v4_rcv中，收到ack包的，__inet_lookup_skb查找到的就是ehash中的req sock。并且此时的sk处于TCP_NEW_SYN_RECV状态。我们可以看到，在判断完sk_state是TCP_NEW_SYN_RECV状态后，立刻就将查找到的sk，转换为了request_sock，并且将sk更新为了request_sock关联的listen sock。然后做ipsec相关检查。做校验和计算。然后判断listen sock是否还是TCP_LISTEN状态(因为有可能关闭了)，如果关闭了，调用reuseport_migrate_sock查看是否能找到一个合适的sk迁移。过lsm bpf钩子点。如果钩子点放行了，调用tcp_check_req，创建child sock，这个就是用来跟对端通信的sock。如果创建失败了，则表示收到的报文大概率不合法，默默丢弃。如果创建成功了，复位连接跟踪相关。紧接着调用tcp_child_process完成对第三次握手包的处理。如果失败了，回rst包。如果成功了，则return结束。\nint tcp_v4_rcv(struct sk_buff *skb)&#123;\t...lookup:\t/* 查找该数据包所属的sk\t * 可能返回established sk，也可能是listen sk，也可能是NULL \t * 对于服务端来说，第一次握手包找到的是listen sk，客户端的ack(三次握手包)后查找到的应该是established sk\t * 返回NULL 代表没有TCP监听该端口，所以要给对端发reset包 */\tsk = __inet_lookup_skb(net-&gt;ipv4.tcp_death_row.hashinfo,\t\t\t       skb, __tcp_hdrlen(th), th-&gt;source,\t\t\t       th-&gt;dest, sdif, &amp;refcounted);\tif (!sk)\t\tgoto no_tcp_socket;\t...\t/* 如果是正常的三次握手，服务端收到客户端的ack包(第三次握手包)后，会走进这个分支 */\tif (sk-&gt;sk_state == TCP_NEW_SYN_RECV) &#123;\t\t/* 处于这种状态的sk，属于半连接状态的sk，request_sock，不完全的sk */\t\tstruct request_sock *req = inet_reqsk(sk);\t\tbool req_stolen = false;\t\tstruct sock *nsk;\t\t/* 从这个不完全sk上面，获取其相关的监听套接字 */\t\tsk = req-&gt;rsk_listener;\t\t\t\t/* ipsec相关 */\t\tif (!xfrm4_policy_check(sk, XFRM_POLICY_IN, skb))\t\t\tdrop_reason = SKB_DROP_REASON_XFRM_POLICY;\t\telse\t\t\tdrop_reason = tcp_inbound_md5_hash(sk, skb,\t\t\t\t\t\t   &amp;iph-&gt;saddr, &amp;iph-&gt;daddr,\t\t\t\t\t\t   AF_INET, dif, sdif);\t\tif (unlikely(drop_reason)) &#123;\t\t\tsk_drops_add(sk, skb);\t\t\treqsk_put(req);\t\t\tgoto discard_it;\t\t&#125;\t\t/* 计算校验和，如果这里硬件计算过了，软件就不算了 */\t\tif (tcp_checksum_complete(skb)) &#123;\t\t\treqsk_put(req);\t\t\tgoto csum_error;\t\t&#125;\t\t\t\t/* 查看 req sk 所关联的 listen sk，还是不是listen状态，看它是否close了 */\t\tif (unlikely(sk-&gt;sk_state != TCP_LISTEN)) &#123;\t\t\t/* 如果启用了端口重用，看看能不找到一个可以替代的sk，然后继续，否则goto要重新查找一下\t\t\t * 这里如果再找一遍没找到是不是就直接rst了？？？*/\t\t\tnsk = reuseport_migrate_sock(sk, req_to_sk(req), skb);\t\t\tif (!nsk) &#123;\t\t\t\tinet_csk_reqsk_queue_drop_and_put(sk, req);\t\t\t\tgoto lookup;\t\t\t&#125;\t\t\t/* 这里是找到了可以迁移的sock */\t\t\tsk = nsk;\t\t\t/* reuseport_migrate_sock() has already held one sk_refcnt\t\t\t * before returning.\t\t\t */\t\t&#125; else &#123;\t\t\t/* We own a reference on the listener, increase it again\t\t\t * as we might lose it too soon.\t\t\t */\t\t\tsock_hold(sk);\t\t&#125;\t\trefcounted = true;\t\tnsk = NULL;\t\t/* lsm 及 bpf 相关的过滤钩子，返回0表示接收，非0 drop数据包 */\t\tif (!tcp_filter(sk, skb)) &#123;\t\t\tth = (const struct tcphdr *)skb-&gt;data;\t\t\tiph = ip_hdr(skb);\t\t\t/* 根据数据包字段填充私有控制结构 */\t\t\ttcp_v4_fill_cb(skb, iph, th);\t\t\t/* 创建新的sock，这里可能返回监听sk，或者空，或者新的sock */\t\t\tnsk = tcp_check_req(sk, skb, req, false, &amp;req_stolen);\t\t&#125; else &#123;\t\t\tdrop_reason = SKB_DROP_REASON_SOCKET_FILTER;\t\t&#125;\t\t/* 如果返回空则表示收到的报文可能不合法，大概率默默丢弃了 */\t\tif (!nsk) &#123;\t\t\treqsk_put(req);\t\t\tif (req_stolen) &#123;\t\t\t\t/* Another cpu got exclusive access to req\t\t\t\t * and created a full blown socket.\t\t\t\t * Try to feed this packet to this socket\t\t\t\t * instead of discarding it.\t\t\t\t */\t\t\t\ttcp_v4_restore_cb(skb);\t\t\t\tsock_put(sk);\t\t\t\tgoto lookup;\t\t\t&#125;\t\t\tgoto discard_and_relse;\t\t&#125;\t\t/* 连接跟踪相关复位 */\t\tnf_reset_ct(skb);\t\tif (nsk == sk) &#123;\t\t\treqsk_put(req);\t\t\ttcp_v4_restore_cb(skb);\t\t&#125; else if (tcp_child_process(sk, nsk, skb)) &#123; \t/* 正常情况下走这个流程并返回0，失败了要发reset包 */\t\t\ttcp_v4_send_reset(nsk, skb);\t\t\tgoto discard_and_relse;\t\t&#125; else &#123;\t\t\tsock_put(sk);\t\t\treturn 0;\t\t&#125;\t&#125;\t...&#125;\n\n\n在 tcp_check_req 中，做的事情主要就是判断数据包是否合法，合法则创建child sock，将其挂到req sock上，并将req sock从ehash中移除，将child sock加到ehash中。并且将req sock加入到全连接队列中，等待accept取走。\nstruct sock *tcp_check_req(struct sock *sk, struct sk_buff *skb,\t\t\t   struct request_sock *req,\t\t\t   bool fastopen, bool *req_stolen)&#123;\t...\t/* 收到了第三次握手包，创建完整版的client sk，完成建连\t * tcp_v4_syn_recv_sock\t */\tchild = inet_csk(sk)-&gt;icsk_af_ops-&gt;syn_recv_sock(sk, skb, req, NULL,\t\t\t\t\t\t\t req, &amp;own_req);\tif (!child)\t\tgoto listen_overflow;\tif (own_req &amp;&amp; rsk_drop_req(req)) &#123;\t\t/* 将req从半连接队列移除 */\t\treqsk_queue_removed(&amp;inet_csk(req-&gt;rsk_listener)-&gt;icsk_accept_queue, req);\t\tinet_csk_reqsk_queue_drop_and_put(req-&gt;rsk_listener, req);\t\treturn child;\t&#125;\tsock_rps_save_rxhash(child, skb);\ttcp_synack_rtt_meas(child, req);\t*req_stolen = !own_req;\treturn inet_csk_complete_hashdance(sk, child, req, own_req);\t...&#125;\n\n * 由 tcp_check_req 调用 * 服务端被动打开，收到第三次握手包后会调用，完成建连，创建client sk */struct sock *tcp_v4_syn_recv_sock(const struct sock *sk, struct sk_buff *skb,\t\t\t\t  struct request_sock *req,\t\t\t\t  struct dst_entry *dst,\t\t\t\t  struct request_sock *req_unhash,\t\t\t\t  bool *own_req)&#123;\tstruct inet_request_sock *ireq;\tbool found_dup_sk = false;\tstruct inet_sock *newinet;\tstruct tcp_sock *newtp;\tstruct sock *newsk;#ifdef CONFIG_TCP_MD5SIG\tconst union tcp_md5_addr *addr;\tstruct tcp_md5sig_key *key;\tint l3index;#endif\tstruct ip_options_rcu *inet_opt;\t/* 注意三次握手完成的数量如果大于了 min(listen设置的第二个参数, somaxconn)，这里直接goto\t * 最外层会返回NULL 等于什么也不做 */\tif (sk_acceptq_is_full(sk))\t\tgoto exit_overflow;\t/* 创建一个新的sock并初始化一些列字段,例如各个序列号 */\tnewsk = tcp_create_openreq_child(sk, req, skb);\tif (!newsk)\t\tgoto exit_nonewsk;\t/* 这里设置了GSO的类型 */\tnewsk-&gt;sk_gso_type = SKB_GSO_TCPV4;\t/* 将sock关联skb的dst */\tinet_sk_rx_dst_set(newsk, skb);\tnewtp\t\t      = tcp_sk(newsk);\tnewinet\t\t      = inet_sk(newsk);\tireq\t\t      = inet_rsk(req);\t/* 设置地址，网口，ipoption，多播等字段 */\tsk_daddr_set(newsk, ireq-&gt;ir_rmt_addr);\tsk_rcv_saddr_set(newsk, ireq-&gt;ir_loc_addr);\tnewsk-&gt;sk_bound_dev_if = ireq-&gt;ir_iif;\tnewinet-&gt;inet_saddr   = ireq-&gt;ir_loc_addr;\tinet_opt\t      = rcu_dereference(ireq-&gt;ireq_opt);\tRCU_INIT_POINTER(newinet-&gt;inet_opt, inet_opt);\tnewinet-&gt;mc_index     = inet_iif(skb);\tnewinet-&gt;mc_ttl\t      = ip_hdr(skb)-&gt;ttl;\tnewinet-&gt;rcv_tos      = ip_hdr(skb)-&gt;tos;\tinet_csk(newsk)-&gt;icsk_ext_hdr_len = 0;\tif (inet_opt)\t\tinet_csk(newsk)-&gt;icsk_ext_hdr_len = inet_opt-&gt;opt.optlen;\t/* 用于设置ipid的，这里随机生成 */\tatomic_set(&amp;newinet-&gt;inet_id, get_random_u16());\t/* Set ToS of the new socket based upon the value of incoming SYN.\t * ECT bits are set later in tcp_init_transfer().\t * 默认不开启这个系统选项，决定是否使用客户端syn包的tos\t */\tif (READ_ONCE(sock_net(sk)-&gt;ipv4.sysctl_tcp_reflect_tos))\t\tnewinet-&gt;tos = tcp_rsk(req)-&gt;syn_tos &amp; ~INET_ECN_MASK;\t/* 如果是第三次握手这里一定是空的 */\tif (!dst) &#123;\t\t/* 调用查路由的接口 */\t\tdst = inet_csk_route_child_sock(sk, newsk, req);\t\tif (!dst)\t\t\tgoto put_and_exit;\t&#125; else &#123;\t\t/* syncookie case : see end of cookie_v4_check() */\t&#125;\t/* 设置GSO能力 */\tsk_setup_caps(newsk, dst);\t/* 这里设置了拥塞算法 */\ttcp_ca_openreq_child(newsk, dst);\t/* 如果用户没有显示配置mtu则拿到设备的mtu 后计算mss */\ttcp_sync_mss(newsk, dst_mtu(dst));\t/* 从dst_metric_advmss （用户配置或者是1460）和用户显式设置的 MSS 之间取一个更小的合法值。 */\tnewtp-&gt;advmss = tcp_mss_clamp(tcp_sk(sk), dst_metric_advmss(dst));\t/* 上述计算的两个mss中选个最小值，给延迟ack使用！ */\ttcp_initialize_rcv_mss(newsk);#ifdef CONFIG_TCP_MD5SIG\tl3index = l3mdev_master_ifindex_by_index(sock_net(sk), ireq-&gt;ir_iif);\t/* Copy over the MD5 key from the original socket */\taddr = (union tcp_md5_addr *)&amp;newinet-&gt;inet_daddr;\tkey = tcp_md5_do_lookup(sk, l3index, addr, AF_INET);\tif (key) &#123;\t\tif (tcp_md5_key_copy(newsk, addr, AF_INET, 32, l3index, key))\t\t\tgoto put_and_exit;\t\tsk_gso_disable(newsk);\t&#125;#endif\t/* 将新创建的sock加入bhash中， 因为bhash是管理端口的，新创建的sock也理所应当被管理 */\tif (__inet_inherit_port(sk, newsk) &lt; 0)\t\tgoto put_and_exit;\t/* 将新创建的sock加入ehash中，同时移除了原本存在的 req */\t*own_req = inet_ehash_nolisten(newsk, req_to_sk(req_unhash),\t\t\t\t       &amp;found_dup_sk);\tif (likely(*own_req)) &#123;\t\t/* syn相关的选项 */\t\ttcp_move_syn(newtp, req);\t\tireq-&gt;ireq_opt = NULL;\t&#125; else &#123;\t\tnewinet-&gt;inet_opt = NULL;\t\tif (!req_unhash &amp;&amp; found_dup_sk) &#123;\t\t\t/* This code path should only be executed in the\t\t\t * syncookie case only\t\t\t */\t\t\tbh_unlock_sock(newsk);\t\t\tsock_put(newsk);\t\t\tnewsk = NULL;\t\t&#125;\t&#125;\t/* 这里返回了新创建的sock */\treturn newsk;exit_overflow:\tNET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);exit_nonewsk:\tdst_release(dst);exit:\ttcp_listendrop(sk);\treturn NULL;put_and_exit:\tnewinet-&gt;inet_opt = NULL;\tinet_csk_prepare_forced_close(newsk);\ttcp_done(newsk);\tgoto exit;&#125;EXPORT_SYMBOL(tcp_v4_syn_recv_sock);\n\n/* 由 tcp_check_req 调用 */struct sock *inet_csk_complete_hashdance(struct sock *sk, struct sock *child,\t\t\t\t\t struct request_sock *req, bool own_req)&#123;\tif (own_req) &#123;\t\t/* 将半连接队列数量减1 */\t\tinet_csk_reqsk_queue_drop(req-&gt;rsk_listener, req);\t\treqsk_queue_removed(&amp;inet_csk(req-&gt;rsk_listener)-&gt;icsk_accept_queue, req);\t\tif (sk != req-&gt;rsk_listener) &#123;\t\t\t/* another listening sk has been selected,\t\t\t * migrate the req to it.\t\t\t */\t\t\tstruct request_sock *nreq;\t\t\t/* hold a refcnt for the nreq-&gt;rsk_listener\t\t\t * which is assigned in inet_reqsk_clone()\t\t\t */\t\t\tsock_hold(sk);\t\t\tnreq = inet_reqsk_clone(req, sk);\t\t\tif (!nreq) &#123;\t\t\t\tinet_child_forget(sk, req, child);\t\t\t\tgoto child_put;\t\t\t&#125;\t\t\trefcount_set(&amp;nreq-&gt;rsk_refcnt, 1);\t\t\tif (inet_csk_reqsk_queue_add(sk, nreq, child)) &#123;\t\t\t\t__NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPMIGRATEREQSUCCESS);\t\t\t\treqsk_migrate_reset(req);\t\t\t\treqsk_put(req);\t\t\t\treturn child;\t\t\t&#125;\t\t\t__NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPMIGRATEREQFAILURE);\t\t\treqsk_migrate_reset(nreq);\t\t\t__reqsk_free(nreq);\t\t&#125; else if (inet_csk_reqsk_queue_add(sk, req, child)) &#123;\t\t\treturn child;\t\t&#125;\t&#125;\t/* Too bad, another child took ownership of the request, undo. */child_put:\tbh_unlock_sock(child);\tsock_put(child);\treturn NULL;&#125;EXPORT_SYMBOL(inet_csk_complete_hashdance);\n\n/* 由 inet_csk_complete_hashdance 调用 * 三次握手完成，将req加入到全连接队列中, * sk: 监听sk * req: 半连接req sk * child: 全连接sk */struct sock *inet_csk_reqsk_queue_add(struct sock *sk,\t\t\t\t      struct request_sock *req,\t\t\t\t      struct sock *child)&#123;\t/* 先拿到这个监听sk的管理全连接队列的queue */\tstruct request_sock_queue *queue = &amp;inet_csk(sk)-&gt;icsk_accept_queue;\tspin_lock(&amp;queue-&gt;rskq_lock);\t/* 如果这个监听sk状态不是LISTEN了，那它大概率是CLOSE了，\t * 那就没必要再往req queue塞了，并且要把 */\tif (unlikely(sk-&gt;sk_state != TCP_LISTEN)) &#123;\t\tinet_child_forget(sk, req, child);\t\tchild = NULL;\t&#125; else &#123;\t\t/* 走到这里，代表 监听sk 还处于正常 LISTEN 状态 */\t\t/* 先将这个 child socket 指针赋值给 req，这个是全连接 sk，\t\t * 这样在 inet_csk_accept 时，可以直接从 req queue 里取出来它 */\t\treq-&gt;sk = child;\t\treq-&gt;dl_next = NULL;\t\t/* 将 req sk 加入到全连接队列，并递增全连接队列数量 */\t\tif (queue-&gt;rskq_accept_head == NULL)\t\t\tWRITE_ONCE(queue-&gt;rskq_accept_head, req);\t\telse\t\t\tqueue-&gt;rskq_accept_tail-&gt;dl_next = req;\t\tqueue-&gt;rskq_accept_tail = req;\t\t/* 全连接队列计数 +1 */\t\tsk_acceptq_added(sk);\t&#125;\tspin_unlock(&amp;queue-&gt;rskq_lock);\treturn child;&#125;EXPORT_SYMBOL(inet_csk_reqsk_queue_add);\n\n\n在tcp_child_process中，保存child sk_state的状态，检查用户是否持有sock，如果持有，则将数据包加入到backlog队列中。如果没持有，调用tcp_rcv_state_process处理第三次握手包。处理完后，检查child的sk_state状态是否由TCP_NEW_RECV发生了改变，如果改变了，则调用sk_data_ready，唤醒在listen sock上等待的线程。\n/* 只由 tcp_v4_rcv 、 tcp_v4_do_rcv 、 tcp_v6_rcv 、 tcp_v6_do_rcv 调用 * 注意这里可没有req sock啊，只有 listen sock 和 child sock * parent 为监听 socket， * child 为新创建的连接 socket */int tcp_child_process(struct sock *parent, struct sock *child,\t\t      struct sk_buff *skb)\t__releases(&amp;((child)-&gt;sk_lock.slock))&#123;\tint ret = 0;\tint state = child-&gt;sk_state;\t/* record sk_napi_id and sk_rx_queue_mapping of child. */\tsk_mark_napi_id_set(child, skb);\ttcp_segs_in(tcp_sk(child), skb);\tif (!sock_owned_by_user(child)) &#123;\t\tret = tcp_rcv_state_process(child, skb);\t\t/* Wakeup parent, send SIGIO */\t\tif (state == TCP_SYN_RECV &amp;&amp; child-&gt;sk_state != state)\t\t\tparent-&gt;sk_data_ready(parent);\t&#125; else &#123;\t\t/* Alas, it is possible again, because we do lookup\t\t * in main socket hash table and lock on listening\t\t * socket does not protect us more.\t\t */\t\t__sk_add_backlog(child, skb);\t&#125;\tbh_unlock_sock(child);\tsock_put(child);\treturn ret;&#125;\n\n\n在tcp_rcv_state_process中，传入的sk其实就是child sock，其状态处于TCP_SYN_RECV，主要工作是进行rtt、fastopen的辅助逻辑。然后将状态置为established，并调用sk_state_change，通知 与该 child sock 关联的等待者状态发生变化。更新发送窗口等状态信息，调用tcp_fast_path_on，判断是否启用tcp fast path。后面又调用tcp_data_queue对同一个skb再次进行处理，因为第三次握手的 ACK 包，在 TCP 语义上，是允许携带数据的。最后检查是否需要发送 ACK 或者 有没有待发送的数据。\nint tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)&#123;\t...\tswitch (sk-&gt;sk_state) &#123;\t/* 第三次握手包走到这里 */\tcase TCP_SYN_RECV:\t\ttp-&gt;delivered++; /* SYN-ACK delivery isn&#x27;t tracked in tcp_ack */\t\tif (!tp-&gt;srtt_us)\t\t\ttcp_synack_rtt_meas(sk, req);\t\tif (req) &#123;\t\t\ttcp_rcv_synrecv_state_fastopen(sk);\t\t&#125; else &#123;\t\t\ttcp_try_undo_spurious_syn(sk);\t\t\ttp-&gt;retrans_stamp = 0;\t\t\ttcp_init_transfer(sk, BPF_SOCK_OPS_PASSIVE_ESTABLISHED_CB,\t\t\t\t\t  skb);\t\t\tWRITE_ONCE(tp-&gt;copied_seq, tp-&gt;rcv_nxt);\t\t&#125;\t\tsmp_mb();\t\t/* 收到了第三次握手包，状态置为established */\t\ttcp_set_state(sk, TCP_ESTABLISHED);\t\t/* 通知 与该 child sock 关联的等待者状态发生变化 */\t\tsk-&gt;sk_state_change(sk);\t\t/* Note, that this wakeup is only for marginal crossed SYN case.\t\t * Passively open sockets are not waked up, because\t\t * sk-&gt;sk_sleep == NULL and sk-&gt;sk_socket == NULL.\t\t */\t\tif (sk-&gt;sk_socket)\t\t\tsk_wake_async(sk, SOCK_WAKE_IO, POLL_OUT);\t\ttp-&gt;snd_una = TCP_SKB_CB(skb)-&gt;ack_seq;\t\ttp-&gt;snd_wnd = ntohs(th-&gt;window) &lt;&lt; tp-&gt;rx_opt.snd_wscale;\t\ttcp_init_wl(tp, TCP_SKB_CB(skb)-&gt;seq);\t\tif (tp-&gt;rx_opt.tstamp_ok)\t\t\ttp-&gt;advmss -= TCPOLEN_TSTAMP_ALIGNED;\t\tif (!inet_csk(sk)-&gt;icsk_ca_ops-&gt;cong_control)\t\t\ttcp_update_pacing_rate(sk);\t\t/* Prevent spurious tcp_cwnd_restart() on first data packet */\t\ttp-&gt;lsndtime = tcp_jiffies32;\t\ttcp_initialize_rcv_mss(sk);\t\ttcp_fast_path_on(tp);\t\tbreak;\t&#125;\t/* step 7: process the segment text */\tswitch (sk-&gt;sk_state) &#123;\tcase TCP_ESTABLISHED:\t\ttcp_data_queue(sk, skb);\t\tqueued = 1;\t\tbreak;\t&#125;\t\t/* tcp_data could move socket to TIME-WAIT */\tif (sk-&gt;sk_state != TCP_CLOSE) &#123;\t\ttcp_data_snd_check(sk);\t\ttcp_ack_snd_check(sk);\t&#125;\tif (!queued) &#123;discard:\t\ttcp_drop_reason(sk, skb, reason);\t&#125;\treturn 0;&#125;\n","categories":["linux6.6内核"],"tags":["socket","网络","tcp建连"]},{"title":"TCP三次握手-接收syn（二）","url":"/2025/12/28/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B-%E6%8E%A5%E6%94%B6syn%EF%BC%88%E4%BA%8C%EF%BC%89/","content":"接上文被动打开-接收syn（一）\n\n在 tcp_v4_do_rcv 中，由于我们之前找的sk，是listen sk，所以其状态处于 TCP_LISTEN状态，首先会调用 tcp_v4_cookie_check，判断当前包是否携带了syn cookies，如果携带了，会创建req sock 及 child sock，并将req sock插入到全连接队列中。如果它的返回值nsk如果不等于sk了，那代表一定是收到syn cookies第三次握手包了，那就调用tcp_child_process去将处理第三次握手包。如果只是普通的三次握手，那这里nsk一定是跟sk相等，然后会调用到tcp_rcv_state_process，常见req sock，并将其加入到 ehash 中，然后回复第二次握手包。\nint tcp_v4_do_rcv(struct sock *sk, struct sk_buff *skb)&#123;\tenum skb_drop_reason reason;\tstruct sock *rsk;\t/* sk 处于 ESTABLISHED 状态，走这里 */\tif (sk-&gt;sk_state == TCP_ESTABLISHED) &#123; /* Fast path */\t\tstruct dst_entry *dst;\t\tdst = rcu_dereference_protected(sk-&gt;sk_rx_dst,\t\t\t\t\t\tlockdep_sock_is_held(sk));\t\tsock_rps_save_rxhash(sk, skb);\t\tsk_mark_napi_id(sk, skb);\t\tif (dst) &#123;\t\t\tif (sk-&gt;sk_rx_dst_ifindex != skb-&gt;skb_iif ||\t\t\t    !INDIRECT_CALL_1(dst-&gt;ops-&gt;check, ipv4_dst_check,\t\t\t\t\t     dst, 0)) &#123;\t\t\t\tRCU_INIT_POINTER(sk-&gt;sk_rx_dst, NULL);\t\t\t\tdst_release(dst);\t\t\t&#125;\t\t&#125;\t\ttcp_rcv_established(sk, skb);\t\treturn 0;\t&#125;\t/* 校验和检查 */\treason = SKB_DROP_REASON_NOT_SPECIFIED;\tif (tcp_checksum_complete(skb))\t\tgoto csum_err;\t/* sk 处于 LISTEN 状态，走这里，即对第一次握手包的处理，\t * 也有特殊情况，比如 syn cookies，第一次、第三次握手包都会走进这里 */\tif (sk-&gt;sk_state == TCP_LISTEN) &#123;\t\t/* 处理syn cookie*/\t\tstruct sock *nsk = tcp_v4_cookie_check(sk, skb);\t\t/* 如果nsk为空，那一定是开启了syn cookies，走到了其中的处理逻辑，但是处理还失败了 */\t\tif (!nsk)\t\t\tgoto discard;\t\t/* 不相等，则代表syn cookie生效了，并且此时肯定是第三次握手，\t\t * nsk是新创建的client socket，这个nsk的状态是 TCP_SYN_RECV,\t\t * 是在 inet_csk_clone_lock 中设置的 nsk的状态 */\t\tif (nsk != sk) &#123;\t\t\t/* 这代表肯定新创建了syn cookie的nsk，并且是第三次握手，直接处理它即可 */\t\t\tif (tcp_child_process(sk, nsk, skb)) &#123;\t\t\t\trsk = nsk;\t\t\t\tgoto reset;\t\t\t&#125;\t\t\treturn 0;\t\t&#125;\t&#125; else &#123;\t\tsock_rps_save_rxhash(sk, skb);\t&#125;\t/* sk 的 状态进行处理，状态机？第一次握手肯定走这里(无论开没开启 syn cookies), 这里面会发送第二次握手包\t * 返回1 就会回个reset报文 */\tif (tcp_rcv_state_process(sk, skb)) &#123;\t\trsk = sk;\t\tgoto reset;\t&#125;\treturn 0;reset:\ttcp_v4_send_reset(rsk, skb);discard:\tkfree_skb_reason(skb, reason);\t/* Be careful here. If this function gets more complicated and\t * gcc suffers from register pressure on the x86, sk (in %ebx)\t * might be destroyed here. This current version compiles correctly,\t * but you have been warned.\t */\treturn 0;csum_err:\treason = SKB_DROP_REASON_TCP_CSUM;\ttrace_tcp_bad_csum(skb);\tTCP_INC_STATS(sock_net(sk), TCP_MIB_CSUMERRORS);\tTCP_INC_STATS(sock_net(sk), TCP_MIB_INERRS);\tgoto discard;&#125;EXPORT_SYMBOL(tcp_v4_do_rcv);\n\n\n在 tcp_v4_cookie_check 中，会判断是否支持 SYN_COOKIES，如果不支持，那什么都不做，直接返回sk即可。如果支持 SYN_COOKIES，判断当前syn是否置位了，如果当前syn置位了，则不需要任何处理，因为syn cookies应该在第三次握手包时才去调用cookie_v4_check去创建req sock、child sock，做相应处理。我们关注普通三次握手逻辑，这里先不深入cookie_v4_check的逻辑。\n/* 只由 tcp_v4_do_rcv 调用 ， * 只有处于listen状态的套接字，在首次握手时才会调用 */static struct sock *tcp_v4_cookie_check(struct sock *sk, struct sk_buff *skb)&#123;\t/* 检查 syn cookies 是否开启了 */#ifdef CONFIG_SYN_COOKIES\tconst struct tcphdr *th = tcp_hdr(skb);\t/* 这里是处理syncookie的逻辑，在服务端收到 非 SYN 的包时(一般就是 第三次握手 再走进去)，\t * 检查该报文是否携带有效的 sync cookie，如果校验通过，\t * 就 创建req sock 及 child sock，从而绕过半连接队列，\t * syn cookie 就是防syn攻击的，如果成功，这里返回的sk其实就是新创建的服务端这边的 client socket */\tif (!th-&gt;syn)\t\tsk = cookie_v4_check(sk, skb);#endif\treturn sk;&#125;\n\n\n在 tcp_rcv_state_process 中，因为这是第一次握手包，所以此时的sk为listen sk，状态为 TCP_LISTEN，检查当前包头部ack是否置位了，如果置位了，直接返回1，也就是listen状态，不处理ack包。如果rst置位了，直接释放掉该包。如果syn置位了，那就是第一次握手包，如果fin置位了，直接释放掉该包。如果fin没置位，那就去调用 tcp_v4_conn_request ，对第一次握手包进行处理。如果处理失败了，acceptable为false，直接return 1，如果处理成功了，acceptable为true，调用 consume_skb 消费掉第一次握手包。\nint tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)&#123;\t...\tswitch (sk-&gt;sk_state) &#123;\tcase TCP_CLOSE:\t\tSKB_DR_SET(reason, TCP_CLOSE);\t\tgoto discard;\tcase TCP_LISTEN:\t\t/* listen状态，不处理ack包 */\t\tif (th-&gt;ack)\t\t\treturn 1;\t\t/* listen状态，rst，直接释放掉该包 */\t\tif (th-&gt;rst) &#123;\t\t\tSKB_DR_SET(reason, TCP_RESET);\t\t\tgoto discard;\t\t&#125;\t\t/* syn置位，这里是对第一次握手包的处理 */\t\tif (th-&gt;syn) &#123;\t\t\t/* fin也置位了，直接释放掉该包 */\t\t\tif (th-&gt;fin) &#123;\t\t\t\tSKB_DR_SET(reason, TCP_FLAGS);\t\t\t\tgoto discard;\t\t\t&#125;\t\t\t/* It is possible that we process SYN packets from backlog,\t\t\t * so we need to make sure to disable BH and RCU right there.\t\t\t */\t\t\trcu_read_lock();\t\t\tlocal_bh_disable();\t\t\t/* tcp_v4_conn_request ，里面会发送第二次握手包 */\t\t\tacceptable = icsk-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &gt;= 0;\t\t\tlocal_bh_enable();\t\t\trcu_read_unlock();\t\t\t/* 对第一次握手包的处理失败了，直接 return */\t\t\tif (!acceptable)\t\t\t\treturn 1;\t\t\t\t\t\t/* 对第一次握手包的处理成功了，第二次握手包发送完了，这里直接将第一次握手包消费掉 */\t\t\tconsume_skb(skb);\t\t\treturn 0;\t\t&#125;\t\tSKB_DR_SET(reason, TCP_FLAGS);\t\tgoto discard;\tcase TCP_SYN_SENT:\t\t/* 客户端收到第二次握手包后的处理逻辑 */\t\ttp-&gt;rx_opt.saw_tstamp = 0;\t\ttcp_mstamp_refresh(tp);\t\tqueued = tcp_rcv_synsent_state_process(sk, skb, th);\t\tif (queued &gt;= 0)\t\t\treturn queued;\t\t/* Do step6 onward by hand. */\t\ttcp_urg(sk, skb, th);\t\t__kfree_skb(skb);\t\ttcp_data_snd_check(sk);\t\treturn 0;\t&#125;\t...&#125;\n\n\n在 tcp_v4_conn_request 中，首先根据路由标志，判断是否是多播、广播，tcp是面向连接的，只能点对点，非单播直接goto drop。如果是单播，则调用 tcp_conn_request。\n/* 由 tcp_rcv_state_process 调用  * listen状态下，处理syn的回调 */int tcp_v4_conn_request(struct sock *sk, struct sk_buff *skb)&#123;\t/* Never answer to SYNs send to broadcast or multicast \t * 防止 TCP 协议栈响应发送到广播地址或组播地址的 SYN 数据包，\t * TCP是面向连接，点对点的，只能处理单播 */\tif (skb_rtable(skb)-&gt;rt_flags &amp; (RTCF_BROADCAST | RTCF_MULTICAST))\t\tgoto drop;\t/* 对第一次握手包进行处理，发送第二次握手包 */\treturn tcp_conn_request(&amp;tcp_request_sock_ops,\t\t\t\t&amp;tcp_request_sock_ipv4_ops, sk, skb);drop:\ttcp_listendrop(sk);\treturn 0;&#125;EXPORT_SYMBOL(tcp_v4_conn_request);\n\n\n在 tcp_conn_request 中，判断是否开启了 syn cookies，syncookies为2时代表强制开启。inet_csk_reqsk_queue_is_full是判断当前半连接队列数量是否超出了全连接队列的最大值(很奇怪吧，但内核就这样实现的)。tcp_syn_flood_action 是去判断是否是洪水流攻击，是则去打印警告日志信息。sk_acceptq_is_full是判断全连接队列是否已满，如果满了，直接goto drop。全连接队列没满，则去申请 req sock，做一些初始化操作。 如果此次并没有使用 syn cookies ，并且没有 isn，则进入半连接队列保护逻辑。普通三次握手，会将 req sock 使用 inet_csk_reqsk_queue_hash_add，将 req sock 插入到 ehash 中，并将半连接队列数量加1。如果是syn cookies类型，则不需要加入到ehash，不需要半连接队列数量加1，因为syn cookies是防syn攻击的，就是用来避免占用半连接队列的。然后调用 tcp_v4_send_synack 发送第二次握手包。\n/* 由 tcp_v4_conn_request 调用  * 对第一次握手包进行处理，负责发送第二次握手包 */int tcp_conn_request(struct request_sock_ops *rsk_ops,\t\t     const struct tcp_request_sock_ops *af_ops,\t\t     struct sock *sk, struct sk_buff *skb)&#123;\tstruct tcp_fastopen_cookie foc = &#123; .len = -1 &#125;;\t__u32 isn = TCP_SKB_CB(skb)-&gt;tcp_tw_isn;\tstruct tcp_options_received tmp_opt;\tstruct tcp_sock *tp = tcp_sk(sk);\tstruct net *net = sock_net(sk);\tstruct sock *fastopen_sk = NULL;\tstruct request_sock *req;\tbool want_cookie = false;\tstruct dst_entry *dst;\tstruct flowi fl;\tu8 syncookies;\tsyncookies = READ_ONCE(net-&gt;ipv4.sysctl_tcp_syncookies);\t/* TW buckets are converted to open requests without\t * limitations, they conserve resources and peer is\t * evidently real one.\t * syncookies  0-不启用   1-半连接队列(syn队列)数超出全连接大小限制时启用  2-强制所有的都启用syn cookies\t * 如果强制所有的都启用了syncookies 或者 syn队列已满 ，并且没有初始序列号（isn），则进入 SYN 洪水防护流程\t */\tif ((syncookies == 2 || inet_csk_reqsk_queue_is_full(sk)) &amp;&amp; !isn) &#123;\t\t/* 获取syn cookie失败，直接drop */\t\twant_cookie = tcp_syn_flood_action(sk, rsk_ops-&gt;slab_name);\t\tif (!want_cookie)\t\t\tgoto drop;\t&#125;\t/* 查看sk的全连接队列(accept队列)是否已满，满了就drop掉，\t * 因为全连接都已经满了，就算启用syn cookies，可能也无能为力了，\t * 这主要是 并发量大、用户态accept太慢 、全连接队列太小的原因 */\tif (sk_acceptq_is_full(sk)) &#123;\t\tNET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);\t\tgoto drop;\t&#125;\t/* 走到这里，代表全连接队列未满，\t * 申请下 req sock 结构 */\treq = inet_reqsk_alloc(rsk_ops, sk, !want_cookie);\tif (!req)\t\tgoto drop;\treq-&gt;syncookie = want_cookie;\t/* tcp_request_sock_ipv4_ops */\ttcp_rsk(req)-&gt;af_specific = af_ops;\ttcp_rsk(req)-&gt;ts_off = 0;#if IS_ENABLED(CONFIG_MPTCP)\ttcp_rsk(req)-&gt;is_mptcp = 0;#endif\t\t/* 解析请求中的 TCP 选项，并根据需要启用 SYN cookies 或其他连接选项 */\ttcp_clear_options(&amp;tmp_opt);\ttmp_opt.mss_clamp = af_ops-&gt;mss_clamp;\ttmp_opt.user_mss  = tp-&gt;rx_opt.user_mss;\ttcp_parse_options(sock_net(sk), skb, &amp;tmp_opt, 0,\t\t\t  want_cookie ? NULL : &amp;foc);\tif (want_cookie &amp;&amp; !tmp_opt.saw_tstamp)\t\ttcp_clear_options(&amp;tmp_opt);\tif (IS_ENABLED(CONFIG_SMC) &amp;&amp; want_cookie)\t\ttmp_opt.smc_ok = 0;\ttmp_opt.tstamp_ok = tmp_opt.saw_tstamp;\ttcp_openreq_init(req, &amp;tmp_opt, skb, sk);\tinet_rsk(req)-&gt;no_srccheck = inet_test_bit(TRANSPARENT, sk);\t/* Note: tcp_v6_init_req() might override ir_iif for link locals */\tinet_rsk(req)-&gt;ir_iif = inet_request_bound_dev_if(sk, skb);\tdst = af_ops-&gt;route_req(sk, skb, &amp;fl, req);\tif (!dst)\t\tgoto drop_and_free;\tif (tmp_opt.tstamp_ok)\t\ttcp_rsk(req)-&gt;ts_off = af_ops-&gt;init_ts_off(net, skb);\t/* 如果此次并没有使用 syn cookies ，并且没有 isn，则进入半连接队列保护逻辑 */\tif (!want_cookie &amp;&amp; !isn) &#123;\t\t/* 半连接队列的伪最大值(因为下面明明限制的是它的四分之三。。。) */\t\tint max_syn_backlog = READ_ONCE(net-&gt;ipv4.sysctl_max_syn_backlog);\t\t/* Kill the following clause, if you dislike this way. \t\t * syncookies是0时，半连接队列的大小限制为max_syn_backlog * 3 / 4 */\t\tif (!syncookies &amp;&amp;\t\t    (max_syn_backlog - inet_csk_reqsk_queue_len(sk) &lt;\t\t     (max_syn_backlog &gt;&gt; 2)) &amp;&amp;\t\t    !tcp_peer_is_proven(req, dst)) &#123;\t\t\t/* Without syncookies last quarter of\t\t\t * backlog is filled with destinations,\t\t\t * proven to be alive.\t\t\t * It means that we continue to communicate\t\t\t * to destinations, already remembered\t\t\t * to the moment of synflood.\t\t\t */\t\t\tpr_drop_req(req, ntohs(tcp_hdr(skb)-&gt;source),\t\t\t\t    rsk_ops-&gt;family);\t\t\tgoto drop_and_release;\t\t&#125;\t\t/* tcp_v4_init_seq ， 计算服务端的初始序列号 */\t\tisn = af_ops-&gt;init_seq(skb);\t&#125;\ttcp_ecn_create_request(req, skb, sk, dst);\tif (want_cookie) &#123;\t\tisn = cookie_init_sequence(af_ops, sk, skb, &amp;req-&gt;mss);\t\tif (!tmp_opt.tstamp_ok)\t\t\tinet_rsk(req)-&gt;ecn_ok = 0;\t&#125;\ttcp_rsk(req)-&gt;snt_isn = isn;\ttcp_rsk(req)-&gt;txhash = net_tx_rndhash();\ttcp_rsk(req)-&gt;syn_tos = TCP_SKB_CB(skb)-&gt;ip_dsfield;\ttcp_openreq_init_rwin(req, sk, dst);\tsk_rx_queue_set(req_to_sk(req), skb);\tif (!want_cookie) &#123;\t\ttcp_reqsk_record_syn(sk, req, skb);\t\tfastopen_sk = tcp_try_fastopen(sk, skb, req, &amp;foc, dst);\t&#125;\t/* fast open */\tif (fastopen_sk) &#123;\t\t/* tcp_v4_send_synack 发送第二次握手包 */\t\taf_ops-&gt;send_synack(fastopen_sk, dst, &amp;fl, req,\t\t\t\t    &amp;foc, TCP_SYNACK_FASTOPEN, skb);\t\t/* Add the child socket directly into the accept queue */\t\tif (!inet_csk_reqsk_queue_add(sk, req, fastopen_sk)) &#123;\t\t\treqsk_fastopen_remove(fastopen_sk, req, false);\t\t\tbh_unlock_sock(fastopen_sk);\t\t\tsock_put(fastopen_sk);\t\t\tgoto drop_and_free;\t\t&#125;\t\tsk-&gt;sk_data_ready(sk);\t\tbh_unlock_sock(fastopen_sk);\t\tsock_put(fastopen_sk);\t&#125; else &#123;\t\t/* normal 或 syn cookie 类型 */\t\ttcp_rsk(req)-&gt;tfo_listener = false;\t\t/* normal 类型，才将 req sock 插入到 ehash，\t\t * 如果是 syn cookie，是不需要的 */\t\tif (!want_cookie) &#123;\t\t\treq-&gt;timeout = tcp_timeout_init((struct sock *)req);\t\t\t/* 半连接队列计数 + 1，\t\t\t * 并且将 req sock 插入到 ehash 中,\t\t\t * 还会根据 req-&gt;timeout 启动 req sock timer -&gt; reqsk_timer_handler  */\t\t\tinet_csk_reqsk_queue_hash_add(sk, req, req-&gt;timeout);\t\t&#125;\t\t/* tcp_v4_send_synack 发送第二次握手包，这里都不判断返回值的吗？\t\t * 应该是几乎不可能失败 */\t\taf_ops-&gt;send_synack(sk, dst, &amp;fl, req, &amp;foc,\t\t\t\t    !want_cookie ? TCP_SYNACK_NORMAL :\t\t\t\t\t\t   TCP_SYNACK_COOKIE,\t\t\t\t    skb);\t\t/* syn cookies 类型，将req释放掉 */\t\tif (want_cookie) &#123;\t\t\treqsk_free(req);\t\t\treturn 0;\t\t&#125;\t&#125;\treqsk_put(req);\treturn 0;drop_and_release:\tdst_release(dst);drop_and_free:\t__reqsk_free(req);drop:\ttcp_listendrop(sk);\treturn 0;&#125;EXPORT_SYMBOL(tcp_conn_request);\n\n\nreqsk_queue_hash_req就是启动 req sock timer，并 将 req sock 插入到 ehash 中。inet_csk_reqsk_queue_added 是将 半连接队列数量 加1，实际上，6.6内核已经没有单独的半连接队列结构了，这里只维护一个数量信息，其实是将req sock 插入到 ehash 中管理的。\n/* 由 tcp_conn_request 调用 */void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,\t\t\t\t   unsigned long timeout)&#123;\t/* 启动 req sock timer，并 将 req sock 插入到 ehash 中 */\treqsk_queue_hash_req(req, timeout);\t/* 半连接队列数量 + 1*/\tinet_csk_reqsk_queue_added(sk);&#125;EXPORT_SYMBOL_GPL(inet_csk_reqsk_queue_hash_add);/* 由 inet_csk_reqsk_queue_hash_add 调用 */static void reqsk_queue_hash_req(struct request_sock *req,\t\t\t\t unsigned long timeout)&#123;\ttimer_setup(&amp;req-&gt;rsk_timer, reqsk_timer_handler, TIMER_PINNED);\tmod_timer(&amp;req-&gt;rsk_timer, jiffies + timeout);\t/* 将 req sock 插入到 ehash 中 */\tinet_ehash_insert(req_to_sk(req), NULL, NULL);\t/* before letting lookups find us, make sure all req fields\t * are committed to memory and refcnt initialized.\t */\tsmp_wmb();\trefcount_set(&amp;req-&gt;rsk_refcnt, 2 + 1);&#125;/* 由 inet_csk_reqsk_queue_hash_add 调用  * 半连接队列数量+1 */static inline void inet_csk_reqsk_queue_added(struct sock *sk)&#123;\treqsk_queue_added(&amp;inet_csk(sk)-&gt;icsk_accept_queue);&#125;\n\n\ntcp_v4_send_synack 查询路由，如果失败，直接退出，不再发送第二次握手包。然后根据当前的传输控制块、查询到的路由，以及连接请求块中的信息构建第二次握手包。调用 ip_build_and_send_pkt 将数据包发送出去。\n/* *\tSend a SYN-ACK after having received a SYN. *\tThis still operates on a request_sock only, not on a big *\tsocket. *  由 tcp_conn_request 调用， *  用来发送第二次握手包 */static int tcp_v4_send_synack(const struct sock *sk, struct dst_entry *dst,\t\t\t      struct flowi *fl,\t\t\t      struct request_sock *req,\t\t\t      struct tcp_fastopen_cookie *foc,\t\t\t      enum tcp_synack_type synack_type,\t\t\t      struct sk_buff *syn_skb)&#123;\tconst struct inet_request_sock *ireq = inet_rsk(req);\tstruct flowi4 fl4;\tint err = -1;\tstruct sk_buff *skb;\tu8 tos;\t/* First, grab a route. \t * 根据连接请求块中的信息查询路由。如果失败，则直接退出，不再发送第二次握手包 */\tif (!dst &amp;&amp; (dst = inet_csk_route_req(sk, &amp;fl4, req)) == NULL)\t\treturn -1;\t/* 根据当前的传输控制块、查询到的路由，以及连接请求块中的信息构建第二次握手包\t * 构造synack报文，这里传入了req，synack的类型（正常，syn cookie，TFO），和收到的syn包 */\tskb = tcp_make_synack(sk, dst, req, foc, synack_type, syn_skb);\tif (skb) &#123;\t\t__tcp_v4_send_check(skb, ireq-&gt;ir_loc_addr, ireq-&gt;ir_rmt_addr);\t\ttos = READ_ONCE(sock_net(sk)-&gt;ipv4.sysctl_tcp_reflect_tos) ? /* 叫做反射tos? 默认是不启用的 */\t\t\t\t(tcp_rsk(req)-&gt;syn_tos &amp; ~INET_ECN_MASK) |\t\t\t\t(inet_sk(sk)-&gt;tos &amp; INET_ECN_MASK) :\t\t\t\tinet_sk(sk)-&gt;tos;\t/* 直接使用服务器端的 TOS 值 */\t\t/* bpf相关 */\t\tif (!INET_ECN_is_capable(tos) &amp;&amp;\t\t    tcp_bpf_ca_needs_ecn((struct sock *)req))\t\t\ttos |= INET_ECN_ECT_0;\t\trcu_read_lock();\t\t/* 构造第二次握手包，并发送出去 */\t\terr = ip_build_and_send_pkt(skb, sk, ireq-&gt;ir_loc_addr,\t\t\t\t\t    ireq-&gt;ir_rmt_addr,\t\t\t\t\t    rcu_dereference(ireq-&gt;ireq_opt),\t/* ip_option */\t\t\t\t\t    tos);\t\trcu_read_unlock();\t\terr = net_xmit_eval(err);\t&#125;\treturn err;&#125;\n\n\n构建ip头信息，调用 ip_local_out 将包发出去。\n/* *\t\tAdd an ip header to a skbuff and send it out. *  由 tcp_v4_send_synack 调用 */int ip_build_and_send_pkt(struct sk_buff *skb, const struct sock *sk,\t\t\t  __be32 saddr, __be32 daddr, struct ip_options_rcu *opt,\t\t\t  u8 tos)&#123;\tconst struct inet_sock *inet = inet_sk(sk);\tstruct rtable *rt = skb_rtable(skb);\tstruct net *net = sock_net(sk);\tstruct iphdr *iph;\t/* Build the IP header. */\tskb_push(skb, sizeof(struct iphdr) + (opt ? opt-&gt;opt.optlen : 0));\tskb_reset_network_header(skb);\tiph = ip_hdr(skb);\tiph-&gt;version  = 4;\tiph-&gt;ihl      = 5;\tiph-&gt;tos      = tos;\tiph-&gt;ttl      = ip_select_ttl(inet, &amp;rt-&gt;dst);\tiph-&gt;daddr    = (opt &amp;&amp; opt-&gt;opt.srr ? opt-&gt;opt.faddr : daddr);\tiph-&gt;saddr    = saddr;\tiph-&gt;protocol = sk-&gt;sk_protocol;\t/* Do not bother generating IPID for small packets (eg SYNACK) */\tif (skb-&gt;len &lt;= IPV4_MIN_MTU || ip_dont_fragment(sk, &amp;rt-&gt;dst)) &#123;\t\tiph-&gt;frag_off = htons(IP_DF);\t\tiph-&gt;id = 0;\t&#125; else &#123;\t\tiph-&gt;frag_off = 0;\t\t/* TCP packets here are SYNACK with fat IPv4/TCP options.\t\t * Avoid using the hashed IP ident generator.\t\t */\t\tif (sk-&gt;sk_protocol == IPPROTO_TCP)\t\t\tiph-&gt;id = (__force __be16)get_random_u16();\t\telse\t\t\t__ip_select_ident(net, iph, 1);\t&#125;\tif (opt &amp;&amp; opt-&gt;opt.optlen) &#123;\t\tiph-&gt;ihl += opt-&gt;opt.optlen&gt;&gt;2;\t\tip_options_build(skb, &amp;opt-&gt;opt, daddr, rt);\t&#125;\tskb-&gt;priority = READ_ONCE(sk-&gt;sk_priority);\tif (!skb-&gt;mark)\t\tskb-&gt;mark = READ_ONCE(sk-&gt;sk_mark);\t/* Send it out. */\treturn ip_local_out(net, skb-&gt;sk, skb);&#125;EXPORT_SYMBOL_GPL(ip_build_and_send_pkt);\n","categories":["linux6.6内核"],"tags":["socket","网络","tcp建连"]},{"title":"bind系统调用","url":"/2025/12/16/bind%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","content":"glibc bind函数介绍我们使用的bind函数，原型如下。代码位置为：&#x2F;usr&#x2F;include&#x2F;x86_64-linux-gnu&#x2F;sys&#x2F;socket.h\nextern int bind (int __fd, __CONST_SOCKADDR_ARG __addr, socklen_t __len)\n\n\n\n\n参数\n介绍\n\n\n\n__fd\nsocket返回的fd\n\n\n__addr\n为套接字 sockfd 指定本地地址\n\n\n__len\n__addr的大小\n\n\n而bind函数是glibc中提供的函数，我们看下glibc中的bind函数实现。代码位置在：glibc-2.41&#x2F;sysdeps&#x2F;unix&#x2F;sysv&#x2F;linux&#x2F;bind.c\n#include &lt;sys/socket.h&gt;#include &lt;socketcall.h&gt;int__bind (int fd, __CONST_SOCKADDR_ARG addr, socklen_t len)&#123;#ifdef __ASSUME_BIND_SYSCALL  return INLINE_SYSCALL_CALL (bind, fd, addr.__sockaddr__, len);#else  return SOCKETCALL (bind, fd, addr.__sockaddr__, len, 0, 0, 0);#endif&#125;weak_alias (__bind, bind)\n\nglibc中的bind函数也几乎什么都没做，可以理解为仅仅是内核bind系统调用(__do_sys_bind)的一个封装。中间的步骤在syscall调用流程分析中有做展开讲解，这里不再赘述。\nbind系统调用我们首先来看下bind系统调用的入口。可以看到__do_sys_bind，什么都没做，只是再次调用了__sys_bind。\nSYSCALL_DEFINE3(bind, int, fd, struct sockaddr __user *, umyaddr, int, addrlen)&#123;    return __sys_bind(fd, umyaddr, addrlen);&#125;\n\n\n在__sys_bind中，首先需要使用sockfd_lookup_light将fd转换出对应的socket结构，fd只是用户态使用的，在内核会对应一个socket结构。如果没找到，那代表传的是个垃圾fd，直接返回错误。如果找到了，代表传递的fd是有效的。如果找到了sock，那就调用move_addr_to_kernel，将传入的umyaddr转换到内核态的address结构中(因为传递的是地址，内核态是不能直接访问用户态的地址的)。然后过lsm socket_bind hook点，没有返回错误，那就直接调用inet_bind函数。\n/* *  由 __do_sys_bind 调用 */int __sys_bind(int fd, struct sockaddr __user *umyaddr, int addrlen)&#123;\tstruct socket *sock;\tstruct sockaddr_storage address;\tint err, fput_needed;\t/* fd -&gt; socket */\tsock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);\tif (sock) &#123;\t\t/* copy_from_user */\t\terr = move_addr_to_kernel(umyaddr, addrlen, &amp;address);\t\tif (!err) &#123;\t\t\t/* lsm socket_bind hook点 */\t\t\terr = security_socket_bind(sock,\t\t\t\t\t\t   (struct sockaddr *)&amp;address,\t\t\t\t\t\t   addrlen);\t\t\tif (!err) &#123;\t\t\t\t/* inet_bind */\t\t\t\terr = READ_ONCE(sock-&gt;ops)-&gt;bind(sock,\t\t\t\t\t\t      (struct sockaddr *)\t\t\t\t\t\t      &amp;address, addrlen);\t\t\t&#125;\t\t&#125;\t\tfput_light(sock-&gt;file, fput_needed);\t&#125;\treturn err;&#125;\n\n\nsockfd_lookup_light中，就是将fd去current-&gt;files-&gt;fdt[fd]拿到文件对象，文件对象与socket是互指的，所以可以直接从文件对象的private_data中获取到socket指针。\n/* 由 __sys_bind 调用 * 通过fd 查找到file，file的私有指针，就是其对应的socket */static struct socket *sockfd_lookup_light(int fd, int *err, int *fput_needed)&#123;\t/* 根据传入的fd，从进程管理的fdtable中找到对应的file，这里 fd结构体 中的一个字段为file */\tstruct fd f = fdget(fd);\tstruct socket *sock;\t*err = -EBADF;\tif (f.file) &#123;\t\t/* 从file的私有数据里拿到sock */\t\tsock = sock_from_file(f.file);\t\tif (likely(sock)) &#123;\t\t\t*fput_needed = f.flags &amp; FDPUT_FPUT;\t\t\treturn sock;\t\t&#125;\t\t*err = -ENOTSOCK;\t\tfdput(f);\t&#125;\treturn NULL;&#125;static inline struct fd fdget(unsigned int fd)&#123;\treturn __to_fd(__fdget(fd));&#125;unsigned long __fdget(unsigned int fd)&#123;\treturn __fget_light(fd, FMODE_PATH);&#125;EXPORT_SYMBOL(__fdget);static unsigned long __fget_light(unsigned int fd, fmode_t mask)&#123;\tstruct files_struct *files = current-&gt;files;\tstruct file *file;\t/*\t * If another thread is concurrently calling close_fd() followed\t * by put_files_struct(), we must not observe the old table\t * entry combined with the new refcount - otherwise we could\t * return a file that is concurrently being freed.\t *\t * atomic_read_acquire() pairs with atomic_dec_and_test() in\t * put_files_struct().\t */\tif (atomic_read_acquire(&amp;files-&gt;count) == 1) &#123;\t\tfile = files_lookup_fd_raw(files, fd);\t\tif (!file || unlikely(file-&gt;f_mode &amp; mask))\t\t\treturn 0;\t\treturn (unsigned long)file;\t&#125; else &#123;\t\tfile = __fget(fd, mask);\t\tif (!file)\t\t\treturn 0;\t\treturn FDPUT_FPUT | (unsigned long)file;\t&#125;&#125;static inline struct file *files_lookup_fd_raw(struct files_struct *files, unsigned int fd)&#123;\tstruct fdtable *fdt = rcu_dereference_raw(files-&gt;fdt);\tif (fd &lt; fdt-&gt;max_fds) &#123;\t\tfd = array_index_nospec(fd, fdt-&gt;max_fds);\t\treturn rcu_dereference_raw(fdt-&gt;fd[fd]);\t&#125;\treturn NULL;&#125;struct socket *sock_from_file(struct file *file)&#123;\t/* 得确认这个file真的关联的是一个socket，才能取它的private_data */\tif (file-&gt;f_op == &amp;socket_file_ops)\t\treturn file-&gt;private_data;\t/* set in sock_alloc_file */\treturn NULL;&#125;EXPORT_SYMBOL(sock_from_file);\n\n\nmove_addr_to_kernel就是调用了copy_from_user，将用户态的地址结构拷贝到内核态。常用的就是copy_from_user、copy_to_user之类的。\nint move_addr_to_kernel(void __user *uaddr, int ulen, struct sockaddr_storage *kaddr)&#123;\tif (ulen &lt; 0 || ulen &gt; sizeof(struct sockaddr_storage))\t\treturn -EINVAL;\tif (ulen == 0)\t\treturn 0;\tif (copy_from_user(kaddr, uaddr, ulen))\t\treturn -EFAULT;\treturn audit_sockaddr(ulen, kaddr);&#125;\n\n\ninet_bind从socket上取出对应的sock结构指针，然后调用inet_bind_sk。\n/* 由 __sys_bind 调用 */int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)&#123;\treturn inet_bind_sk(sock-&gt;sk, uaddr, addr_len);&#125;EXPORT_SYMBOL(inet_bind);\n\ninet_bind_sk中，判断bind是否为空，不为空则调用bind绑定的函数，tcp、udp都是没有bind实现的(他们的绑定是get_port)。进行了地址长度校验，bpf 钩子点，然后调用__inet_bind。\n/* 由 inet_bind 调用 */int inet_bind_sk(struct sock *sk, struct sockaddr *uaddr, int addr_len)&#123;\tu32 flags = BIND_WITH_LOCK;\tint err;\t/* If the socket has its own bind function then use it. (RAW) \t * tcp_prot 、 udp_prot 都没有 bind 实现，\t * ping_prot 、 raw_prot 有 bind 实现 */\tif (sk-&gt;sk_prot-&gt;bind) &#123;\t\t/* ping_bind 、 raw_bind */\t\treturn sk-&gt;sk_prot-&gt;bind(sk, uaddr, addr_len);\t&#125;\t/* 校验地址长度是否合法 */\tif (addr_len &lt; sizeof(struct sockaddr_in))\t\treturn -EINVAL;\t/* BPF prog is run before any checks are done so that if the prog\t * changes context in a wrong way it will be caught.\t * bpf\t */\terr = BPF_CGROUP_RUN_PROG_INET_BIND_LOCK(sk, uaddr,\t\t\t\t\t\t CGROUP_INET4_BIND, &amp;flags);\tif (err)\t\treturn err;\treturn __inet_bind(sk, uaddr, addr_len, flags);&#125;\n\n\n在__inet_bind中：\n\n首先对要绑定的地址的协议族进行检查。\n然后对要绑定的地址类型做判断，判断是否是本机地址、多播、广播等。\n接着检查是否允许 bind 非本地地址。\n特权端口检查、权限检查\n是否重复绑定端口检查\nno port标志位检查\n申请绑定port\n\n/* 由 inet_bind_sk 调用 */int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len, u32 flags)&#123;\tstruct sockaddr_in *addr = (struct sockaddr_in *)uaddr;\tstruct inet_sock *inet = inet_sk(sk);\tstruct net *net = sock_net(sk);\tunsigned short snum;\tint chk_addr_ret;\tu32 tb_id = RT_TABLE_LOCAL;\tint err;\t/* 地址协议族校验 */\tif (addr-&gt;sin_family != AF_INET) &#123;\t\t/* Compatibility games : accept AF_UNSPEC (mapped to AF_INET)\t\t * only if s_addr is INADDR_ANY.\t\t */\t\terr = -EAFNOSUPPORT;\t\t/* 允许 AF_UNSPEC + INADDR_ANY，这是历史兼容行为 */\t\tif (addr-&gt;sin_family != AF_UNSPEC ||\t\t    addr-&gt;sin_addr.s_addr != htonl(INADDR_ANY))\t\t\tgoto out;\t&#125;\t/* 地址类型判断(本地/多播/广播) \t * RTN_LOCAL\t\t本机地址\t * RTN_MULTICAST\t多播\t * RTN_BROADCAST\t广播\t * RTN_UNICAST\t\t单播\t * RTN_UNREACHABLE\t不可达 \t */\ttb_id = l3mdev_fib_table_by_index(net, sk-&gt;sk_bound_dev_if) ? : tb_id;\tchk_addr_ret = inet_addr_type_table(net, addr-&gt;sin_addr.s_addr, tb_id);\t/* Not specified by any standard per-se, however it breaks too\t * many applications when removed.  It is unfortunate since\t * allowing applications to make a non-local bind solves\t * several problems with systems using dynamic addressing.\t * (ie. your servers still start up even if your ISDN link\t *  is temporarily down)\t * 检查是否允许 bind 非本地地址，\t * 解决DHCP/动态地址/服务先启动的问题，否则服务器必须等IP配好才能启动，体验差\t */\terr = -EADDRNOTAVAIL;\tif (!inet_addr_valid_or_nonlocal(net, inet, addr-&gt;sin_addr.s_addr,\t                                 chk_addr_ret))\t\tgoto out;\t/* 将要绑定的端口转换成主机序 */\tsnum = ntohs(addr-&gt;sin_port);\t/* 特权端口检查，绑定特权端口，必须要有满足权限限制，否则go out */\terr = -EACCES;\tif (!(flags &amp; BIND_NO_CAP_NET_BIND_SERVICE) &amp;&amp;\t    snum &amp;&amp; inet_port_requires_bind_service(net, snum) &amp;&amp;\t    !ns_capable(net-&gt;user_ns, CAP_NET_BIND_SERVICE))\t\tgoto out;\t/*      We keep a pair of addresses. rcv_saddr is the one\t *      used by hash lookups, and saddr is used for transmit.\t *\t *      In the BSD API these are the same except where it\t *      would be illegal to use them (multicast/broadcast) in\t *      which case the sending device address is used.\t *      判断是否要加锁，如果是从 inet_bind_sk 调过来的，\t *      是需要加锁的，因为有赋值为 BIND_WITH_LOCK，\t */\tif (flags &amp; BIND_WITH_LOCK)\t\tlock_sock(sk);\t/* Check these errors (active socket, double bind). \t * bind 只发生在 TCP_CLOSE，如果已经bind过了，那inet_num不为0 */\terr = -EINVAL;\tif (sk-&gt;sk_state != TCP_CLOSE || inet-&gt;inet_num)\t\tgoto out_release_sock;\t/* 设置要绑定的地址 */\tinet-&gt;inet_rcv_saddr = inet-&gt;inet_saddr = addr-&gt;sin_addr.s_addr;\t/* 特别的，如果绑定的是多播或者广播地址，本地地址设置为0，\t * rcv_saddr：用于 hash 查找(收包)\t * saddr：用于 发包(选路)\t */\tif (chk_addr_ret == RTN_MULTICAST || chk_addr_ret == RTN_BROADCAST)\t\tinet-&gt;inet_saddr = 0;  /* Use device */\t/* Make sure we are allowed to bind here.\t * 端口非0，或者是没有设置no port 或 没有设置强制no port，那就去尝试去绑定一个端口，\t * 否则则不绑定端口 */\tif (snum || !(inet_test_bit(BIND_ADDRESS_NO_PORT, sk) ||\t\t      (flags &amp; BIND_FORCE_ADDRESS_NO_PORT))) &#123;\t\t/* inet_csk_get_port 、 udp_v4_get_port */\t\terr = sk-&gt;sk_prot-&gt;get_port(sk, snum);\t\tif (err) &#123;\t\t\t/* get_port 失败了 */\t\t\tinet-&gt;inet_saddr = inet-&gt;inet_rcv_saddr = 0;\t\t\tgoto out_release_sock;\t\t&#125;\t\tif (!(flags &amp; BIND_FROM_BPF)) &#123;\t\t\t/* bpf hook点 */\t\t\terr = BPF_CGROUP_RUN_PROG_INET4_POST_BIND(sk);\t\t\tif (err) &#123;\t\t\t\tinet-&gt;inet_saddr = inet-&gt;inet_rcv_saddr = 0;\t\t\t\t/* 释放port，inet_put_port、udp_lib_unhash */\t\t\t\tif (sk-&gt;sk_prot-&gt;put_port)\t\t\t\t\tsk-&gt;sk_prot-&gt;put_port(sk);\t\t\t\tgoto out_release_sock;\t\t\t&#125;\t\t&#125;\t&#125;\tif (inet-&gt;inet_rcv_saddr)\t\tsk-&gt;sk_userlocks |= SOCK_BINDADDR_LOCK;\tif (snum)\t\tsk-&gt;sk_userlocks |= SOCK_BINDPORT_LOCK;\tinet-&gt;inet_sport = htons(inet-&gt;inet_num);\tinet-&gt;inet_daddr = 0;\tinet-&gt;inet_dport = 0;\tsk_dst_reset(sk);\terr = 0;out_release_sock:\tif (flags &amp; BIND_WITH_LOCK)\t\trelease_sock(sk);out:\treturn err;&#125;\n\n\ninet_csk_get_port就是判断传入的端口是否为0，为了就走inet_csk_find_open_port，自动选取合适的端口。不为0就是指定要绑定的端口，直接计算hash，看是否已有该hash对应的桶，没有则创建，有则判断网络命名空间、port、l3mdev是否匹配。并且如果是指定的端口是需要进行冲突检测，随机端口因为选取时就已经做了冲突检测，所以这里不再需要额外做冲突检测。如果没有冲突，就将这个sk插入到bhash、bhash2哈希表的对应哈希桶的owners上，owners也是个哈希表。 \n/* * __inet_bind 、 inet_csk_listen_start  都会调用这个函数 * __inet_bind 是来 bind 绑定端口的 * inet_csk_listen_start 是 listen 来检查下端口是否绑定的 */int inet_csk_get_port(struct sock *sk, unsigned short snum)&#123;\t/* 获取该sk所在命名空间里，用来管理 各种 tcp 套接字 的哈希组合结构 */\tstruct inet_hashinfo *hinfo = tcp_or_dccp_get_hashinfo(sk);\tbool reuse = sk-&gt;sk_reuse &amp;&amp; sk-&gt;sk_state != TCP_LISTEN;\t/* 用来标识，随机分配端口时，是否找到了合适的端口 */\tbool found_port = false;\tbool check_bind_conflict = true;\t/* 用来标识是否在 bhash 、bhash2 上创建了新哈希桶 */\tbool bhash_created = false, bhash2_created = false;\tint ret = -EADDRINUSE;\tint port = snum;\tint l3mdev;\t/* 端口 在 bhash 、bhash2 上对应的 哈希槽 */\tstruct inet_bind_hashbucket *head, *head2;\t/* 端口 在 bhash 、bhash2 上对应的 哈希桶 */\tstruct inet_bind_bucket *tb = NULL;\tstruct inet_bind2_bucket *tb2 = NULL;\t/* 用来标识是否持有了bhash2上哈希槽的锁 */\tbool head2_lock_acquired = false;\tstruct net *net = sock_net(sk);\tl3mdev = inet_sk_bound_l3mdev(sk);\t/* 如果没有指定端口，就是想让内核给它随机绑定一个 */\tif (!port) &#123;\t\t/* 在内核限制的端口范围内，随机找端口，\t\t * 找到了合适端口，则能找到其对应的 bhash 上的哈希槽， \t\t * 没找到合适端口，则返回空 */\t\thead = inet_csk_find_open_port(sk, &amp;tb, &amp;tb2, &amp;head2, &amp;port);\t\tif (!head)\t\t\treturn ret;\t\thead2_lock_acquired = true;\t\t/* 如果port对应的tb、tb2哈希桶都存在，直接跳转到success */\t\tif (tb &amp;&amp; tb2)\t\t\tgoto success;\t\t\t/* 随机选出的端口，inet_csk_find_open_port已经做过冲突检测了，\t\t * 所以这里置true，后面会跳过很多冲突检测的逻辑 */\t\tfound_port = true;\t&#125; else &#123;\t\t/* 指定了端口，直接计算 bhash，拿到 bhash 哈希表上的对应哈希桶 */\t\thead = &amp;hinfo-&gt;bhash[inet_bhashfn(net, port, hinfo-&gt;bhash_size)];\t\tspin_lock_bh(&amp;head-&gt;lock);\t\t/* 遍历bhash哈希表上面对应的哈希槽，是否有 相同命名空间 且 端口相同的 且 l3mdev 相同的\t\t * 有则直接break，此时tb不为空，\t\t * 没有则会遍历完这个槽，此时tb为空 */\t\tinet_bind_bucket_for_each(tb, &amp;head-&gt;chain)\t\t\tif (inet_bind_bucket_match(tb, net, port, l3mdev))\t\t\t\tbreak;\t&#125;\tif (!tb) &#123;\t\t/* 在 bhash 哈希表上创建哈希桶，注意这里创建完就已经加到了bhash里 */\t\ttb = inet_bind_bucket_create(hinfo-&gt;bind_bucket_cachep, net,\t\t\t\t\t     head, port, l3mdev);\t\tif (!tb)\t\t\tgoto fail_unlock;\t\tbhash_created = true;\t&#125;\t/* 走到这里，只有是指定的端口，found_port才会是false */\tif (!found_port) &#123;\t\t/* 当前是否有其它socket持有tb这个哈希桶(是否使用了这个端口) */\t\tif (!hlist_empty(&amp;tb-&gt;owners)) &#123;\t\t\t/* 设置了reuse，那就不再检查冲突 */\t\t\tif (sk-&gt;sk_reuse == SK_FORCE_REUSE ||\t/* 强制重用 */\t\t\t    (tb-&gt;fastreuse &gt; 0 &amp;&amp; reuse) ||\t\t/* 快速重用且当前socket允许重用 */\t\t\t    sk_reuseport_match(tb, sk))\t\t\t/* 端口重用匹配 */\t\t\t\tcheck_bind_conflict = false;\t\t&#125;\t\t/* 检查冲突标志位开启，并且 sk_rcv_saddr 不是 ANY，才去检查冲突 */\t\tif (check_bind_conflict &amp;&amp; inet_use_bhash2_on_bind(sk)) &#123;\t\t\tif (inet_bhash2_addr_any_conflict(sk, port, l3mdev, true, true))\t\t\t\tgoto fail_unlock;\t\t&#125;\t\t/* 走到这里的，是没获取过head2、tb2的，去获取下,\t\t * 根据 sk_rcv_saddr 、port，直接计算 hash2，拿到 bhash 哈希表上的对应哈希桶 */\t\thead2 = inet_bhashfn_portaddr(hinfo, sk, net, port);\t\tspin_lock(&amp;head2-&gt;lock);\t\thead2_lock_acquired = true;\t\ttb2 = inet_bind2_bucket_find(head2, net, port, l3mdev, sk);\t&#125;\tif (!tb2) &#123;\t\t/* 在 bhash2 哈希表上创建哈希桶，注意这里创建完就已经加到了bhash2里 */\t\ttb2 = inet_bind2_bucket_create(hinfo-&gt;bind2_bucket_cachep,\t\t\t\t\t       net, head2, port, l3mdev, sk);\t\tif (!tb2)\t\t\tgoto fail_unlock;\t\tbhash2_created = true;\t&#125;\t/* 只有是指定的端口，found_port才会是false，并且没开reuse，再次检查冲突 */\tif (!found_port &amp;&amp; check_bind_conflict) &#123;\t\tif (inet_csk_bind_conflict(sk, tb, tb2, true, true))\t\t\tgoto fail_unlock;\t&#125;success:\tinet_csk_update_fastreuse(tb, sk);\t/* 真正的将sk插入到哈希表的哈希桶的owners上，owners也是个哈希表 */\tif (!inet_csk(sk)-&gt;icsk_bind_hash)\t\tinet_bind_hash(sk, tb, tb2, port);\tWARN_ON(inet_csk(sk)-&gt;icsk_bind_hash != tb);\tWARN_ON(inet_csk(sk)-&gt;icsk_bind2_hash != tb2);\tret = 0;fail_unlock:\tif (ret) &#123;\t\t/* 失败了，但是bhash、bhash2之前可能创建了新哈希桶，那就释放下 */\t\tif (bhash_created)\t\t\tinet_bind_bucket_destroy(hinfo-&gt;bind_bucket_cachep, tb);\t\tif (bhash2_created)\t\t\tinet_bind2_bucket_destroy(hinfo-&gt;bind2_bucket_cachep, tb2);\t&#125;\t/* 如果对head2已经加锁了，这里一定要解锁 */\tif (head2_lock_acquired)\t\tspin_unlock(&amp;head2-&gt;lock);\tspin_unlock_bh(&amp;head-&gt;lock);\treturn ret;&#125;EXPORT_SYMBOL_GPL(inet_csk_get_port);\n\n\ninet_csk_find_open_port在本地端口范围内随机挑选端口，同时在 bhash（端口维度）和 bhash2（端口+地址维度）上进行冲突检测，若检测通过，则 在持锁状态下返回对应的 hashbucket 和端口号，来保证后续 inet_csk_get_port() 绑定过程的原子性。\n/* * Find an open port number for the socket.  Returns with the * inet_bind_hashbucket locks held if successful. * 由 inet_csk_get_port 调用 */static struct inet_bind_hashbucket *inet_csk_find_open_port(const struct sock *sk, struct inet_bind_bucket **tb_ret,\t\t\tstruct inet_bind2_bucket **tb2_ret,\t\t\tstruct inet_bind_hashbucket **head2_ret, int *port_ret)&#123;\tstruct inet_hashinfo *hinfo = tcp_or_dccp_get_hashinfo(sk);\tint i, low, high, attempt_half, port, l3mdev;\tstruct inet_bind_hashbucket *head, *head2;\tstruct net *net = sock_net(sk);\tstruct inet_bind2_bucket *tb2;\tstruct inet_bind_bucket *tb;\tu32 remaining, offset;\tbool relax = false;\tl3mdev = inet_sk_bound_l3mdev(sk);ports_exhausted:\tattempt_half = (sk-&gt;sk_reuse == SK_CAN_REUSE) ? 1 : 0;other_half_scan:\tinet_sk_get_local_port_range(sk, &amp;low, &amp;high);\thigh++; /* [32768, 60999] -&gt; [32768, 61000[ */\tif (high - low &lt; 4)\t\tattempt_half = 0;\tif (attempt_half) &#123;\t\tint half = low + (((high - low) &gt;&gt; 2) &lt;&lt; 1);\t\tif (attempt_half == 1)\t\t\thigh = half;\t\telse\t\t\tlow = half;\t&#125;\tremaining = high - low;\tif (likely(remaining &gt; 1))\t\tremaining &amp;= ~1U;\toffset = get_random_u32_below(remaining);\t/* __inet_hash_connect() favors ports having @low parity\t * We do the opposite to not pollute connect() users.\t */\toffset |= 1U;other_parity_scan:\tport = low + offset;\tfor (i = 0; i &lt; remaining; i += 2, port += 2) &#123;\t\tif (unlikely(port &gt;= high))\t\t\tport -= remaining;\t\tif (inet_is_local_reserved_port(net, port))\t\t\tcontinue;\t\thead = &amp;hinfo-&gt;bhash[inet_bhashfn(net, port,\t\t\t\t\t\t  hinfo-&gt;bhash_size)];\t\tspin_lock_bh(&amp;head-&gt;lock);\t\tif (inet_use_bhash2_on_bind(sk)) &#123;\t\t\tif (inet_bhash2_addr_any_conflict(sk, port, l3mdev, relax, false))\t\t\t\tgoto next_port;\t\t&#125;\t\thead2 = inet_bhashfn_portaddr(hinfo, sk, net, port);\t\tspin_lock(&amp;head2-&gt;lock);\t\ttb2 = inet_bind2_bucket_find(head2, net, port, l3mdev, sk);\t\tinet_bind_bucket_for_each(tb, &amp;head-&gt;chain)\t\t\tif (inet_bind_bucket_match(tb, net, port, l3mdev)) &#123;\t\t\t\tif (!inet_csk_bind_conflict(sk, tb, tb2,\t\t\t\t\t\t\t    relax, false))\t\t\t\t\tgoto success;\t\t\t\tspin_unlock(&amp;head2-&gt;lock);\t\t\t\tgoto next_port;\t\t\t&#125;\t\ttb = NULL;\t\tgoto success;next_port:\t\tspin_unlock_bh(&amp;head-&gt;lock);\t\tcond_resched();\t&#125;\toffset--;\tif (!(offset &amp; 1))\t\tgoto other_parity_scan;\tif (attempt_half == 1) &#123;\t\t/* OK we now try the upper half of the range */\t\tattempt_half = 2;\t\tgoto other_half_scan;\t&#125;\tif (READ_ONCE(net-&gt;ipv4.sysctl_ip_autobind_reuse) &amp;&amp; !relax) &#123;\t\t/* We still have a chance to connect to different destinations */\t\trelax = true;\t\tgoto ports_exhausted;\t&#125;\treturn NULL;success:\t*port_ret = port;\t*tb_ret = tb;\t*tb2_ret = tb2;\t*head2_ret = head2;\treturn head;&#125;\n\n\n总结bind() 在内核中首先校验地址合法性与权限，然后根据 socket 状态决定是否立即分配端口。端口绑定通过 bhash（端口维度）和 bhash2（地址+端口维度）进行冲突检测，并结合 SO_REUSEADDR&#x2F;SO_REUSEPORT&#x2F;fastreuse等策略决定是否允许共用端口。最终，socket 被安全地插入绑定哈希表，完成本地地址与端口的占用。\n","categories":["linux6.6内核"],"tags":["socket","网络","bind"]},{"title":"accept系统调用","url":"/2025/12/18/accept%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","content":"glibc accept函数介绍我们使用的accept函数，原型如下。代码位置为：&#x2F;usr&#x2F;include&#x2F;x86_64-linux-gnu&#x2F;sys&#x2F;socket.h\nextern int accept (int __fd, __SOCKADDR_ARG __addr,                   socklen_t *__restrict __addr_len);\n\n\n\n\n参数\n介绍\n\n\n\n__fd\nsocket返回的fd\n\n\n__addr\n返回的client fd对应的对端的地址信息\n\n\n__addr_len\n返回的client fd对应的对端的地址信息结构的大小\n\n\n\n而accept函数是glibc中提供的函数，我们看下glibc中的accept函数实现。代码位置在：glibc-2.41&#x2F;sysdeps&#x2F;unix&#x2F;sysv&#x2F;linux&#x2F;accept.c\n#include &lt;sys/socket.h&gt;#include &lt;sysdep-cancel.h&gt;#include &lt;socketcall.h&gt;int__libc_accept (int fd, __SOCKADDR_ARG addr, socklen_t *len)&#123;#ifdef __ASSUME_ACCEPT_SYSCALL  return SYSCALL_CANCEL (accept, fd, addr.__sockaddr__, len);#elif defined __ASSUME_ACCEPT4_SYSCALL  return SYSCALL_CANCEL (accept4, fd, addr.__sockaddr__, len, 0);#else  return SOCKETCALL_CANCEL (accept, fd, addr.__sockaddr__, len);#endif&#125;weak_alias (__libc_accept, accept)libc_hidden_def (accept)\n\nglibc中的accept函数也几乎什么都没做，可以理解为仅仅是内核accept系统调用(__do_sys_accept)的一个封装。\naccept系统调用我们首先来看下accept系统调用的入口。可以看到__do_sys_accept，什么都没做，只是再次调用了__sys_accept4。__do_sys_accept4 与 __do_sys_accept 的区别在于 flags 参数，__do_sys_accept4 允许 对这个 accept 额外再设置 NONBLOCK 或者是 CLOEXEC。\n/* __do_sys_accept4， * __do_sys_accept4 与 __do_sys_accept 的区别在于 flags 参数， * __do_sys_accept4 允许 对这个 accept client fd 设置 NONBLOCK 或者是 CLOEXEC */SYSCALL_DEFINE4(accept4, int, fd, struct sockaddr __user *, upeer_sockaddr,\t\tint __user *, upeer_addrlen, int, flags)&#123;\treturn __sys_accept4(fd, upeer_sockaddr, upeer_addrlen, flags);&#125;/* __do_sys_accept */SYSCALL_DEFINE3(accept, int, fd, struct sockaddr __user *, upeer_sockaddr,\t\tint __user *, upeer_addrlen)&#123;\treturn __sys_accept4(fd, upeer_sockaddr, upeer_addrlen, 0);&#125;\n\n\n在__sys_accept4中，首先通过fd找到file，然后调用__sys_accept4_file，成功的话，ret就是newfd，否则就是错误码。因为调用的fdget，最后还有使用fdput减下引用计数。\n/*  由 __do_sys_accept 、 __do_sys_accept4 调用 */int __sys_accept4(int fd, struct sockaddr __user *upeer_sockaddr,\t\t  int __user *upeer_addrlen, int flags)&#123;\tint ret = -EBADF;\tstruct fd f;\t/* 根据传入的fd拿到fd结构体 */\tf = fdget(fd);\tif (f.file) &#123;\t\t/* 核心处理函数，成功的话，ret就是newfd，否则就是错误码 */\t\tret = __sys_accept4_file(f.file, upeer_sockaddr, upeer_addrlen, flags);\t\t/* 要记得减引用计数 */\t\tfdput(f);\t&#125;\treturn ret;&#125;\n\n\n__sys_accept4_file中，先检查传入的flags是否合法。然后做标志相关的兼容性检查转换。因为是要accept一个新fd，那当前要先选取一个最小未使用的fd。然后调用do_accept，成功的话，这将返回与client socket相关联的newfile。然后就可以将 new fd 与 new file 使用 fd_install 进行关联，这样以后收发数据，传入fd，就可以找到这个new file，而自然可以再找到对应的client socket结构。\n/* 由 __sys_accept4 调用 */static int __sys_accept4_file(struct file *file, struct sockaddr __user *upeer_sockaddr,\t\t\t      int __user *upeer_addrlen, int flags)&#123;\t/* 这个是 client fd 对应的 file 文件对象 */\tstruct file *newfile;\t/* 这个是 client fd */\tint newfd;\t/* 检查标志位是否合法，flags 只允许是 CLOEXEC 或 NONBLOCK，其它位不能置1 */\tif (flags &amp; ~(SOCK_CLOEXEC | SOCK_NONBLOCK))\t\treturn -EINVAL;\t/* 把 socket 层的非阻塞标志 统一转换成 文件描述符层的非阻塞标志 *\t * 将 SOCK_NONBLOCK 清位之后，再将 O_NONBLOCK 置位 */\tif (SOCK_NONBLOCK != O_NONBLOCK &amp;&amp; (flags &amp; SOCK_NONBLOCK))\t\tflags = (flags &amp; ~SOCK_NONBLOCK) | O_NONBLOCK;\t/* accept要返回给外围一个标识远端客户端的fd，\t * 选取一个最小未使用的fd */\tnewfd = get_unused_fd_flags(flags);\tif (unlikely(newfd &lt; 0))\t\treturn newfd;\t/* 真正的 accpet，这里返回了一个 file，这个是 client fd 对应的新创建的 file，\t * 传入的 file 为 listen fd 关联的 file */\tnewfile = do_accept(file, 0, upeer_sockaddr, upeer_addrlen,\t\t\t    flags);\tif (IS_ERR(newfile)) &#123;\t\t/* 失败了，那把之前占用的那个fd归还 */\t\tput_unused_fd(newfd);\t\treturn PTR_ERR(newfile);\t&#125;\t/* 走到这里，代表 新fd 、新file 都成功创建了，那将它们进行关联，\t * 这样以后收发数据，传入fd，我们才能找到是哪个file，才能找到是哪个socket */\tfd_install(newfd, newfile);\treturn newfd;&#125;\n\n\n在do_accept中，首先通过file，找到socket结构，这个是listen sk对应的socket结构。然后申请一个新的 client sk 关联用的 new socket_alloc结构。再调用sock_alloc_file申请一个new file文件对象，里面会完成new socket与new file的关联。之后就是最核心的，调用 inet_accept 获取到全连接队列中的new sock。再检查外围是否关心这个new sock的地址信息，需要的话，就调用 inet_getname 及 move_addr_to_user 拷给外围。\n/* 由 __sys_accept4_file 调用 */struct file *do_accept(struct file *file, unsigned file_flags,\t\t       struct sockaddr __user *upeer_sockaddr,\t\t       int __user *upeer_addrlen, int flags)&#123;\tstruct socket *sock, *newsock;\tstruct file *newfile;\tint err, len;\tstruct sockaddr_storage address;\tconst struct proto_ops *ops;\t/* 根据传入的listen fd对应的file结构，找到相应的sock */\tsock = sock_from_file(file);\tif (!sock)\t\treturn ERR_PTR(-ENOTSOCK);\t/* 申请一个 socket_alloc 结构，这将会是新client fd对应的内核中的socket结构 */\tnewsock = sock_alloc();\tif (!newsock)\t\treturn ERR_PTR(-ENFILE);\tops = READ_ONCE(sock-&gt;ops);\t/* 设置类型， SOCK_STREAM 或 SOCK_DGRAM 等 */\tnewsock-&gt;type = sock-&gt;type;\t/* 设置client socket的ops ,  socket_file_ops */\tnewsock-&gt;ops = ops;\t/*\t * We don&#x27;t need try_module_get here, as the listening socket (sock)\t * has the protocol module (sock-&gt;ops-&gt;owner) held.\t */\t__module_get(ops-&gt;owner);\t/* 创建一个file结构体(也就是把上面申请的socket的结构体挂到file的私有结构上) */\tnewfile = sock_alloc_file(newsock, flags, sock-&gt;sk-&gt;sk_prot_creator-&gt;name);\tif (IS_ERR(newfile))\t\treturn newfile;\t/* lsm socket_accept hook点 */\terr = security_socket_accept(sock, newsock);\tif (err)\t\tgoto out_fd;\t/* inet_accept 、 sock_no_accept */\terr = ops-&gt;accept(sock, newsock, sock-&gt;file-&gt;f_flags | file_flags,\t\t\t\t\tfalse);\tif (err &lt; 0)\t\tgoto out_fd;\t/* 外围传入的地址变量不为空，才给它赋值，否则不赋值\t * 也就是看服务端是否需要对端的地址信息，一般都得需要吧，要不然怎么接收数据呢？ */\tif (upeer_sockaddr) &#123;\t\t/* inet_getname ，将newsock对应的 对端地址、对端端口 信息，存到address里面 */\t\tlen = ops-&gt;getname(newsock, (struct sockaddr *)&amp;address, 2);\t\tif (len &lt; 0) &#123;\t\t\terr = -ECONNABORTED;\t\t\tgoto out_fd;\t\t&#125;\t\t/* copy_to_user ， 将 远端的地址信息 拷贝给 用户态传入的地址结构中 */\t\terr = move_addr_to_user(&amp;address,\t\t\t\t\tlen, upeer_sockaddr, upeer_addrlen);\t\tif (err &lt; 0)\t\t\tgoto out_fd;\t&#125;\t/* File flags are not inherited via accept() unlike another OSes. \t * 这里返回的是file，外面会关联 newfd 和 newfile */\treturn newfile;out_fd:\t/* 失败了，那就把新创建这个file释放掉 */\tfput(newfile);\treturn ERR_PTR(err);&#125;\n\n\nsock 为 监听socket，newsock 为 新accept的socket, newsock 为 新accept的socket 对应的sock。调用 inet_csk_accept，从 listen sock 的 全连接队列的首个req sk上，取出其client sock。然后调用 __inet_accept，完成 newsocket 与 new sock 的关联。\n/* *\tAccept a pending connection. The TCP layer now gives BSD semantics. *  由 do_accept 调用 *  sock 为 监听socket，newsock 为 新accept 的socket */int inet_accept(struct socket *sock, struct socket *newsock, int flags,\t\tbool kern)&#123;\t/* 从 listen sk 的 socket 上，取出其对应的 sock，赋值为sk1 */\tstruct sock *sk1 = sock-&gt;sk, *sk2;\tint err = -EINVAL;\t/* IPV6_ADDRFORM can change sk-&gt;sk_prot under us. \t * inet_csk_accept ，这里将返回 sk1 的全连接队列 中的首个req sk的client sk */\tsk2 = READ_ONCE(sk1-&gt;sk_prot)-&gt;accept(sk1, flags, &amp;err, kern);\tif (!sk2)\t\treturn err;\tlock_sock(sk2);\t/* 主要就是做 newsock 与 sk2 的关联 */\t__inet_accept(sock, newsock, sk2);\trelease_sock(sk2);\treturn 0;&#125;EXPORT_SYMBOL(inet_accept);\n\n\n主要负责从 sk 的全连接队列中，取出队列首部req sk的client sk，并返回。\n/* * This will accept the next outstanding connection. * 由 inet_accept 调用 * 主要负责从 sk 的全连接队列中，取出队列首部req sk的client sk，并返回 * sk：listen sk * flags: 一般就是 listen sk 的 flags，一般就是 SOCK_CLOEXEC 或者 SOCK_NONBLOCK  * err: 用来返回错误码的指针 */struct sock *inet_csk_accept(struct sock *sk, int flags, int *err, bool kern)&#123;\t/* 从 listen sk 切到 inet connection sk，其实只是类型转了下，值都没变 */\tstruct inet_connection_sock *icsk = inet_csk(sk);\t/* 拿到这个 listend sk 的管理 全连接队列 的结构 */\tstruct request_sock_queue *queue = &amp;icsk-&gt;icsk_accept_queue;\tstruct request_sock *req;\tstruct sock *newsk;\tint error;\tlock_sock(sk);\t/* We need to make sure that this socket is listening,\t * and that it has something pending.\t */\terror = -EINVAL;\t/* 只有调用过 listen，并且成功，sk_state 才是 TCP_LISTEN 状态\t * 没有调用过 listen 的，调用 accept 会立即失败，返回 -EINVAL */\tif (sk-&gt;sk_state != TCP_LISTEN)\t\tgoto out_err;\t/* Find already established connection \t * 如果listen sk 的全连接队列里是空的，那就是暂时没有客户端连接，\t * 那就要根据flag进入 阻塞等待 或 超时等待，如果是非阻塞套接字，会立即返回 */\tif (reqsk_queue_empty(queue)) &#123;\t\tlong timeo = sock_rcvtimeo(sk, flags &amp; O_NONBLOCK);\t\t/* If this is a non blocking socket don&#x27;t sleep \t\t * 如果是非阻塞，是不进入睡眠的，立即返回EAGAIN */\t\terror = -EAGAIN;\t\tif (!timeo)\t\t\tgoto out_err;\t\t/* 阻塞的，会进入睡眠等待，\t\t * 直到 超时了，或者是 全连接队列 有req sk了(也就是由客户端来，且三次握手成功了) */\t\terror = inet_csk_wait_for_connect(sk, timeo);\t\tif (error)\t\t\tgoto out_err;\t&#125;\t/* 到这里，代表listen sk 全连接队列不为空，那就从取出队列首部sk */\treq = reqsk_queue_remove(queue, sk);\t/* 从req sock上取出client sk */\tnewsk = req-&gt;sk;\tif (sk-&gt;sk_protocol == IPPROTO_TCP &amp;&amp;\t    tcp_rsk(req)-&gt;tfo_listener) &#123;\t\tspin_lock_bh(&amp;queue-&gt;fastopenq.lock);\t\tif (tcp_rsk(req)-&gt;tfo_listener) &#123;\t\t\t/* We are still waiting for the final ACK from 3WHS\t\t\t * so can&#x27;t free req now. Instead, we set req-&gt;sk to\t\t\t * NULL to signify that the child socket is taken\t\t\t * so reqsk_fastopen_remove() will free the req\t\t\t * when 3WHS finishes (or is aborted).\t\t\t */\t\t\treq-&gt;sk = NULL;\t\t\treq = NULL;\t\t&#125;\t\tspin_unlock_bh(&amp;queue-&gt;fastopenq.lock);\t&#125;out:\trelease_sock(sk);\tif (newsk &amp;&amp; mem_cgroup_sockets_enabled) &#123;\t\tint amt = 0;\t\t/* atomically get the memory usage, set and charge the\t\t * newsk-&gt;sk_memcg.\t\t */\t\tlock_sock(newsk);\t\tmem_cgroup_sk_alloc(newsk);\t\tif (newsk-&gt;sk_memcg) &#123;\t\t\t/* The socket has not been accepted yet, no need\t\t\t * to look at newsk-&gt;sk_wmem_queued.\t\t\t */\t\t\tamt = sk_mem_pages(newsk-&gt;sk_forward_alloc +\t\t\t\t\t   atomic_read(&amp;newsk-&gt;sk_rmem_alloc));\t\t&#125;\t\tif (amt)\t\t\tmem_cgroup_charge_skmem(newsk-&gt;sk_memcg, amt,\t\t\t\t\t\tGFP_KERNEL | __GFP_NOFAIL);\t\trelease_sock(newsk);\t&#125;\t/* request sock已经完成了它的使命，释放掉 */\tif (req)\t\treqsk_put(req);\treturn newsk;out_err:\tnewsk = NULL;\treq = NULL;\t*err = error;\tgoto out;&#125;EXPORT_SYMBOL(inet_csk_accept);\n\n\n进入睡眠等待，直到 超时 或 有新连接到来。\n/* * Wait for an incoming connection, avoid race conditions. This must be called * with the socket locked. * 由 inet_csk_accept 调用 * listen sk的全连接队列为空时，调用accept函数，会进入这里 */static int inet_csk_wait_for_connect(struct sock *sk, long timeo)&#123;\tstruct inet_connection_sock *icsk = inet_csk(sk);\tDEFINE_WAIT(wait);\tint err;\t/*\t * True wake-one mechanism for incoming connections: only\t * one process gets woken up, not the &#x27;whole herd&#x27;.\t * Since we do not &#x27;race &amp; poll&#x27; for established sockets\t * anymore, the common case will execute the loop only once.\t *\t * Subtle issue: &quot;add_wait_queue_exclusive()&quot; will be added\t * after any current non-exclusive waiters, and we know that\t * it will always _stay_ after any new non-exclusive waiters\t * because all non-exclusive waiters are added at the\t * beginning of the wait-queue. As such, it&#x27;s ok to &quot;drop&quot;\t * our exclusiveness temporarily when we get woken up without\t * having to remove and re-insert us on the wait queue.\t */\tfor (;;) &#123;\t\tprepare_to_wait_exclusive(sk_sleep(sk), &amp;wait,\t\t\t\t\t  TASK_INTERRUPTIBLE);\t\trelease_sock(sk);\t\t/* 全连接队列还是空的，继续睡眠等待 */\t\tif (reqsk_queue_empty(&amp;icsk-&gt;icsk_accept_queue))\t\t\ttimeo = schedule_timeout(timeo);\t\tsched_annotate_sleep();\t\tlock_sock(sk);\t\terr = 0;\t\t\t\t/* 全连接队列有数据了，直接break退出 */\t\tif (!reqsk_queue_empty(&amp;icsk-&gt;icsk_accept_queue))\t\t\tbreak;\t\terr = -EINVAL;\t\t/* 一般listen sk肯定处于TCP_LISTEN状态，不是的话有可能是close了，直接break退出 */\t\tif (sk-&gt;sk_state != TCP_LISTEN)\t\t\tbreak;\t\terr = sock_intr_errno(timeo);\t\t/* 是否是被信号打断 */\t\tif (signal_pending(current))\t\t\tbreak;\t\terr = -EAGAIN;\t\tif (!timeo)\t\t\tbreak;\t&#125;\tfinish_wait(sk_sleep(sk), &amp;wait);\treturn err;&#125;\n\n总结\naccept 是一个 从监听 socket 的全连接队列中取出已完成三次握手连接 的系统调用。\nglibc 的 accept 函数本身只是对内核系统调用的轻量封装，核心逻辑全部在内核中完成。\n内核在 accept 时，会为新连接分配新的 socket、file 和 fd，并通过 inet_csk_accept 从监听 socket 的 全连接队列 取出已经建立完成的 sock，将其与新 socket 关联。\n如果全连接队列为空，阻塞的 accept 会进入睡眠，直到有新连接完成或超时；非阻塞 accept 则立即返回 -EAGAIN。\n整个过程中，accept 不参与 TCP 三次握手本身，只是负责 取结果、建对象、返 fd 。\n\n","categories":["linux6.6内核"],"tags":["socket","网络","tcp建连","accept"]},{"title":"connect系统调用（一）","url":"/2025/12/21/connect%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%EF%BC%88%E4%B8%80%EF%BC%89/","content":"glibc connect函数介绍我们使用的connect函数，原型如下。代码位置为：&#x2F;usr&#x2F;include&#x2F;x86_64-linux-gnu&#x2F;sys&#x2F;socket.h\nextern int connect (int __fd, __CONST_SOCKADDR_ARG __addr, socklen_t __len);\n\n\n\n\n参数\n介绍\n\n\n\n__fd\nsocket返回的fd\n\n\n__addr\n要连接的服务端地址信息\n\n\n__len\naddr的大小\n\n\n\n而connect函数是glibc中提供的函数，我们看下glibc中的connect函数实现。代码位置在：glibc-2.41&#x2F;sysdeps&#x2F;unix&#x2F;sysv&#x2F;linux&#x2F;connect.c\n#include &lt;sys/socket.h&gt;#include &lt;sysdep-cancel.h&gt;#include &lt;socketcall.h&gt;int__libc_connect (int fd, __CONST_SOCKADDR_ARG addr, socklen_t len)&#123;#ifdef __ASSUME_CONNECT_SYSCALL  return SYSCALL_CANCEL (connect, fd, addr.__sockaddr__, len);#else  return SOCKETCALL_CANCEL (connect, fd, addr.__sockaddr__, len);#endif&#125;weak_alias (__libc_connect, connect)weak_alias (__libc_connect, __connect)libc_hidden_weak (__connect)\n\nglibc中的connect函数也几乎什么都没做，可以理解为仅仅是内核connect系统调用(__do_sys_connect)的一个封装。\nconnect系统调用我们首先来看下connect系统调用的入口。可以看到__do_sys_connect，什么都没做，只是再次调用了__sys_connect。\n/* __do_sys_connect */SYSCALL_DEFINE3(connect, int, fd, struct sockaddr __user *, uservaddr,\t\tint, addrlen)&#123;\treturn __sys_connect(fd, uservaddr, addrlen);&#125;\n\n\n在__sys_connect中，首先通过fd找到file，然后将用户态传入的对端地址使用move_addr_to_kernel拷贝到内核态的address里。拷贝成功则调用__sys_connect_file。最后记得fdput下，减下引用计数。\n/* 由 __do_sys_connect 调用 */int __sys_connect(int fd, struct sockaddr __user *uservaddr, int addrlen)&#123;\tint ret = -EBADF;\tstruct fd f;\t/* 根据fd找到file */\tf = fdget(fd);\tif (f.file) &#123;\t\tstruct sockaddr_storage address;\t\t/* copy_from_user */\t\tret = move_addr_to_kernel(uservaddr, addrlen, &amp;address);\t\tif (!ret)\t\t\tret = __sys_connect_file(f.file, &amp;address, addrlen, 0);\t\t\t\t/* 前面是fdget，因此这里要fdput下 */\t\tfdput(f);\t&#125;\treturn ret;&#125;\n\n\n在__sys_connect_file中，通过file的private_data找到socket，如果没找到，那就是传入的fd对应的根本就不是套接字相关的file，直接返回-ENOTSOCK。然后过lsm socket_connect hook点。再根据套接字的协议操作集合去调用connect函数。实际上对应的应该是 __inet_stream_connect 、 inet_dgram_connect。需要说明的就是dgram也是可以调用connect的，这样sendto就可以不再指定对端ip了，或者可以直接send发。\n/*  由 __sys_connect 调用 */int __sys_connect_file(struct file *file, struct sockaddr_storage *address,\t\t       int addrlen, int file_flags)&#123;\tstruct socket *sock;\tint err;\t/* 通过file的私有结构找到socket */\tsock = sock_from_file(file);\tif (!sock) &#123;\t\terr = -ENOTSOCK;\t\tgoto out;\t&#125;\t/* lsm socket_connect hook点 */\terr = security_socket_connect(sock, (struct sockaddr *)address, addrlen);\tif (err)\t\tgoto out;\t/* __inet_stream_connect 、 inet_dgram_connect,\t * dgram也可以connect，这样sendto就可以不再指定对端ip了，或者可以直接send发 */\terr = READ_ONCE(sock-&gt;ops)-&gt;connect(sock, (struct sockaddr *)address,\t\t\t\taddrlen, sock-&gt;file-&gt;f_flags | file_flags);out:\treturn err;&#125;\n\n\n在__inet_stream_connect中，如果指定了对端的地址uaddr，那就进行地址长度校验、协议族类型校验。然后根据当前套接字的状态去走不同的处理流程。大概率情况下，会走到SS_UNCONNECTED分支里。检查下sock的状态，必须得是 TCP_CLOSE。bpf相关的，调用tcp_v4_pre_connect。然后调用sk-&gt;sk_prot-&gt;connect，其实也就是tcp_v4_connect，这个函数里会发送第一次握手包。判断sock的状态，如果是SYN_SENT或者SYN_RECV，那就根据timeo，去调用 inet_wait_for_connect() 进入阻塞等待。等待对端回包后，这个等待会被唤醒。然后再次判断套接字的状态，看是不是CLOSE，因为有可能对端回rst。如果不是CLOSE状态，那就认为连接成功，即返回即可。\n/* *\tConnect to a remote host. There is regrettably still a little *\tTCP &#x27;magic&#x27; in here. *  由 __sys_connect_file 调用 */int __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr,\t\t\t  int addr_len, int flags, int is_sendmsg)&#123;\tstruct sock *sk = sock-&gt;sk;\tint err;\tlong timeo;\t/*\t * uaddr can be NULL and addr_len can be 0 if:\t * sk is a TCP fastopen active socket and\t * TCP_FASTOPEN_CONNECT sockopt is set and\t * we already have a valid cookie for this socket.\t * In this case, user can call write() after connect().\t * write() will invoke tcp_sendmsg_fastopen() which calls\t * __inet_stream_connect().\t * 看看指定了要connect的对端地址了吗，如果指定了，那就对地址长度、协议族类型做下判断\t */\tif (uaddr) &#123;\t\t/* 地址长度校验 */\t\tif (addr_len &lt; sizeof(uaddr-&gt;sa_family))\t\t\treturn -EINVAL;\t\t/* 协议族类型校验 */\t\tif (uaddr-&gt;sa_family == AF_UNSPEC) &#123;\t\t\tsk-&gt;sk_disconnects++;\t\t\terr = sk-&gt;sk_prot-&gt;disconnect(sk, flags);\t\t\tsock-&gt;state = err ? SS_DISCONNECTING : SS_UNCONNECTED;\t\t\tgoto out;\t\t&#125;\t&#125;\t/* 一般客户端才调用connect，socket的初始状态一般为 SS_UNCONNECTED */\tswitch (sock-&gt;state) &#123;\tdefault:\t\terr = -EINVAL;\t\tgoto out;\tcase SS_CONNECTED:\t\terr = -EISCONN;\t\tgoto out;\tcase SS_CONNECTING:\t\tif (inet_test_bit(DEFER_CONNECT, sk))\t\t\terr = is_sendmsg ? -EINPROGRESS : -EISCONN;\t\telse\t\t\terr = -EALREADY;\t\t/* Fall out of switch with err, set for this state */\t\tbreak;\t/* 大概率是走这里 */\tcase SS_UNCONNECTED:\t\terr = -EISCONN;\t\t/* 检查下sock的状态，必须得是 TCP_CLOSE */\t\tif (sk-&gt;sk_state != TCP_CLOSE)\t\t\tgoto out;\t\t/* bpf相关 */\t\tif (BPF_CGROUP_PRE_CONNECT_ENABLED(sk)) &#123;\t\t\t/* tcp_v4_pre_connect  */\t\t\terr = sk-&gt;sk_prot-&gt;pre_connect(sk, uaddr, addr_len);\t\t\tif (err)\t\t\t\tgoto out;\t\t&#125;\t\t/* tcp_v4_connect */\t\terr = sk-&gt;sk_prot-&gt;connect(sk, uaddr, addr_len);\t\tif (err &lt; 0)\t\t\tgoto out;\t\t\t\t/* 走到这里，代表第一次握手包(SYN包)已发送，sock state 置为 连接中 */\t\tsock-&gt;state = SS_CONNECTING;\t\t/* 检查延迟连接，查看是否fastopen设置了延迟connect，因为fastopen握手包要带数据，\t\t * 在 tcp_fastopen_defer_connect 中置位 */\t\tif (!err &amp;&amp; inet_test_bit(DEFER_CONNECT, sk))\t\t\tgoto out;\t\t/* Just entered SS_CONNECTING state; the only\t\t * difference is that return value in non-blocking\t\t * case is EINPROGRESS, rather than EALREADY.\t\t */\t\terr = -EINPROGRESS;\t\tbreak;\t&#125;\ttimeo = sock_sndtimeo(sk, flags &amp; O_NONBLOCK);\t/* sock的状态是SYN_SENT或者SYN_RECV才需要进去，进去其实主要就是为了等待的，\t * 有可能到这里的时候，三次握手早就完成了(但是这么短的时间，应该很少出现这种情况)，那就不用进去等了 */\tif ((1 &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_SYN_SENT | TCPF_SYN_RECV)) &#123;\t\tint writebias = (sk-&gt;sk_protocol == IPPROTO_TCP) &amp;&amp;\t\t\t\ttcp_sk(sk)-&gt;fastopen_req &amp;&amp;\t\t\t\ttcp_sk(sk)-&gt;fastopen_req-&gt;data ? 1 : 0;\t\tint dis = sk-&gt;sk_disconnects;\t\t/* Error code is set above，\t\t * 判断是否需要等，需要等就等待连接的完成(阻塞模式)，\t\t * 在收到第二次握手包(SYN+ACK)后，在 tcp_rcv_synsent_state_process 会发送第三次握手包(ACK)，\t\t * 然后调用 sk_state_change 来唤醒这里，\t\t * 但是第三次握手包丢不丢，这里不再关心了，对于客户端来说，已经认为进入 ESTABLISHED 状态了 */\t\tif (!timeo || !inet_wait_for_connect(sk, timeo, writebias))\t\t\tgoto out;\t\terr = sock_intr_errno(timeo);\t\t/* 判断是否是被信号中断了 */\t\tif (signal_pending(current))\t\t\tgoto out;\t\tif (dis != sk-&gt;sk_disconnects) &#123;\t\t\terr = -EPIPE;\t\t\tgoto out;\t\t&#125;\t&#125;\t/* Connection was closed by RST, timeout, ICMP error\t * or another process disconnected us.\t * 如果对端回的是rst，sock的状态应该就被改成 TCP_CLOSE 了\t */\tif (sk-&gt;sk_state == TCP_CLOSE)\t\tgoto sock_error;\t/* sk-&gt;sk_err may be not zero now, if RECVERR was ordered by user\t * and error was received after socket entered established state.\t * Hence, it is handled normally after connect() return successfully.\t * 到这里了，那才是连接成功了(也不一定，应该最起码第三次握手包发出去了)\t */\tsock-&gt;state = SS_CONNECTED;\terr = 0;out:\treturn err;sock_error:\terr = sock_error(sk) ? : -ECONNABORTED;\tsock-&gt;state = SS_UNCONNECTED;\tsk-&gt;sk_disconnects++;\tif (sk-&gt;sk_prot-&gt;disconnect(sk, flags))\t\tsock-&gt;state = SS_DISCONNECTING;\tgoto out;&#125;EXPORT_SYMBOL(__inet_stream_connect);\n","categories":["linux6.6内核"],"tags":["socket","网络","tcp建连","connect"]},{"title":"libnetfilter_queue","url":"/2025/12/07/libnetfilter_queue/","content":"libnetfilter_queue介绍在 Linux 防火墙中，iptables 本身并不处理数据包，它只是一个“规则描述工具”。真正的数据包裁决发生在内核 Netfilter 框架中。当我们通过iptables使用 -j NFQUEUE 参数下发规则时，本质上是告诉内核：匹配到该规则的 skb 不要立刻放行或拦截，而是进入NFQUEUE子系统，送往用户态程序，等待用户态来决定如何处理这个数据包。而libnetfilter_queue 就是 Linux 下 Netfilter 子系统提供的一个用户态开发库，专门用于用户态接收、分析、修改、处理，再决定是否放行&#x2F;拦截网络数据包，它是实现 NFQUEUE 功能的核心组件。\niptables 下发规则iptables规则下发到nfqueue，一般使用方法为：\niptables -I INPUT -j NFQUEUE --queue-num 0 \n\n简而言之：就是下发了一条规则，向内核 filter表(默认)，注册到了INPUT链，当有数据包到INPUT链，转交给NFQUEUE子系统进行处理，并且入0号队列\niptables用户态调用流程iptables() └── do_command()      └── do_command4()           └── iptc_commit()                └── setsockopt(fd, SOL_IP, IPT_SO_SET_REPLACE, ...)\n\n用户态主要做的就是： \n\n构造整张规则表的数据iptables 在用户态内部并不是“只构造一条规则”，而是会：解析当前系统中 已有的全部规则，然后将新规则插入到对应链（这里是 INPUT），再重新生成一整张完整的规则表数据结构，也就是说：iptables 在用户态做的是“整表重建”，不是“单条规则增量修改”。\n\n通过 setsockopt 下发整张规则表给内核把包含所有链（INPUT、OUTPUT、FORWARD）所有规则、所有 match、所有 target（包括 NFQUEUE）的一整块内存，一次性发送给内核。然后iptables使命就结束了，后续的所有规则匹配与数据包处理，全部发生在内核中，iptables进程是不会参与任何一个数据包的处理的。\n\n\niptables内核态调用流程__x64_sys_setsockopt() └── do_sys_setsockopt()      └── __sys_setsockopt()          └── raw_setsockopt()               └── ip_setsockopt()                    └── nf_setsockopt()                        └── do_ipt_set_ctl()                             └── do_replace()                                  └── __do_replace()\n\n内核态主要做的就是：\n\n为整张规则表分配内核内存\n\nnewinfo = xt_alloc_table_info(tmp.size);if (!newinfo)\treturn -ENOMEM;\n\n再将所有规则内容完整拷贝进内核\n\n/* 从用户态拷贝 规则表头 */if (copy_from_sockptr(&amp;tmp, arg, sizeof(tmp)) != 0)\treturn -EFAULT; /* 从用户态拷贝 真正的规则内容 进内核 */if (copy_from_sockptr_offset(loc_cpu_entry, arg, sizeof(tmp),\t\ttmp.size) != 0) &#123;\tret = -EFAULT;\tgoto free_newinfo;&#125;\n\n解析并绑定目标（NFQUEUE 关键点）\n\n /* 规则 翻译 和 校验 */ret = translate_table(net, newinfo, loc_cpu_entry, &amp;tmp);if (ret != 0)\tgoto free_newinfo; /* 绑定target */t = ipt_get_target(e);target = xt_request_find_target(NFPROTO_IPV4, t-&gt;u.user.name,\t\t\t\tt-&gt;u.user.revision);if (IS_ERR(target)) &#123;\tret = PTR_ERR(target);\tgoto cleanup_matches;&#125;t-&gt;u.kernel.target = target;\n\n替换旧规则表\n\n/* * Ensure contents of newinfo are visible before assigning to * private. */smp_wmb();table-&gt;private = newinfo;/* make sure all cpus see new -&gt;private value */smp_mb();\n\n疑问点\n为什么“哪怕只加一条规则”，也必须整体替换？iptables 的规则表不是链表，而是“连续内存 + 偏移跳转”的结构。\n\n为什么会整体替换呢？因为Netfilter 规则是在“数据包热路径”上被每秒几十万次并发读取的，规则表是“每个包都要读的共享结构”只能“无锁读取 + 整体原子切换”，不能“在线修改细节”，这样能最大程度提高性能。\n\n\nskb 如何在 INPUT 链命中 NFQUEUE一个数据包从网卡进入 Linux 内核后，首先进入的是软中断收包流程：\n网卡中断 └── napi_poll()     └── 驱动收包          └── __netif_receive_skb_core()              └── ip_rcv()                   └── dst_input()                       └── ip_local_deliver()                            └── LOCAL_IN NF_HOOK()                                └── nf_hook()                                     └── nf_hook_slow()                                          └── nf_hook_entry_hookfn()                                              └── ipt_do_table()                                                  └── nfqueue_tg()                 \n\nnfqueue_tg实现如下，其实就是置NF_QUEUE，并且把queuenum也返出去\n#define NF_QUEUE_NR(x) ((((x) &lt;&lt; 16) &amp; NF_VERDICT_QMASK) | NF_QUEUE)// Expands to((((tinfo-&gt;queuenum) &lt;&lt; 16) &amp; 0xffff0000) | 3)static unsigned intnfqueue_tg(struct sk_buff *skb, const struct xt_action_param *par)&#123;\tconst struct xt_NFQ_info *tinfo = par-&gt;targinfo;\treturn NF_QUEUE_NR(tinfo-&gt;queuenum);&#125;\n\n\n如果命中了NFQUEUE的规则，那返回的verdict，前两字节是命中规则的queuenum号，后两字节是标识NF_QUEUE标志，标识该数据包要送往NFQUEUE等待裁决，而非在这里直接放行或拦截\nint nf_hook_slow(struct sk_buff *skb, struct nf_hook_state *state,\t\t const struct nf_hook_entries *e, unsigned int s)&#123;\tunsigned int verdict;\tint ret;\tfor (; s &lt; e-&gt;num_hook_entries; s++) &#123;\t\tverdict = nf_hook_entry_hookfn(&amp;e-&gt;hooks[s], skb, state);\t\tswitch (verdict &amp; NF_VERDICT_MASK) &#123;\t\t/* 直接放行 */\t\tcase NF_ACCEPT:\t\t\tbreak;\t\t/* 直接丢弃 */\t\tcase NF_DROP:\t\t\tkfree_skb_reason(skb,\t\t\t\t\t SKB_DROP_REASON_NETFILTER_DROP);\t\t\tret = NF_DROP_GETERR(verdict);\t\t\tif (ret == 0)\t\t\t\tret = -EPERM;\t\t\treturn ret;\t\t/* 进入nfqueue，由用户态程序决定是否放行 */\t\tcase NF_QUEUE:\t\t\tret = nf_queue(skb, state, s, verdict);\t\t\tif (ret == 1)\t\t\t\tcontinue;\t\t\treturn ret;\t\tdefault:\t\t\t/* Implicit handling for NF_STOLEN, as well as any other\t\t\t * non conventional verdicts.\t\t\t */\t\t\treturn 0;\t\t&#125;\t&#125;\treturn 1;&#125;\n\n再看nf_queue的调用逻辑：\nnf_queue()└── __nf_queue()    └── nfqnl_enqueue_packet()\n\n入队其实就是根据传入的queuenum号，先找到对应的实例instance\n/* rcu_read_lock()ed by nf_hook_thresh */queue = instance_lookup(q, queuenum);if (!queue)\treturn -ESRCH;\n\n然后将包信息通过netlink发送给用户态进程，发送失败，直接返回；发送成功，则将这个entry加入到队列实例链表上，等待用户态裁决\n/* nfnetlink_unicast will either free the nskb or add it to a socket  * netlink 把信息发往用户态 */err = nfnetlink_unicast(nskb, net, queue-&gt;peer_portid);if (err &lt; 0) &#123;\tif (queue-&gt;flags &amp; NFQA_CFG_F_FAIL_OPEN) &#123;\t\tfailopen = 1;\t\terr = 0;\t&#125; else &#123;\t\tqueue-&gt;queue_user_dropped++;\t&#125;\tgoto err_out_unlock;&#125;/* 发往用户态成功了，将这个entry暂存到链表里去，到时候好找 */__enqueue_entry(queue, entry);\n\n\n用户态程序是如何裁决数据包的基本流程：\nnfq_open() └── nfq_bind_pf(AF_INET)     └── nfq_create_queue(queue_num, callback)         └── nfq_set_mode(NFQNL_COPY_PACKET)             └── recv(fd)                 └── nfq_handle_packet()                     └── 回调函数 callback()                          └── nfq_set_verdict()\n\n代码实现：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#include &lt;limits.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;/* 注意下这个头文件需要在arpa/inet.h之后包含，否则会报in_addr重定义 */#include &lt;linux/netfilter.h&gt;#include &lt;libnetfilter_queue/libnetfilter_queue.h&gt;/* 队列序号 */#define QUEUE_NUM   1/* 注意我们是hook input链，针对udp大包，需要 USHRT_MAX 才能完全存储 */#define MAX_BUF     USHRT_MAX#define QUEUE_MAXLEN 4096static int cb(struct nfq_q_handle *qh, struct nfgenmsg *nfmsg,              struct nfq_data *nfa, void *data)&#123;    unsigned char *payload = NULL;    int len = nfq_get_payload(nfa, &amp;payload);    printf(&quot;got packet, size = %d\\n&quot;, len);    struct nfqnl_msg_packet_hdr *ph = nfq_get_msg_packet_hdr(nfa);    if (!ph) &#123;        printf(&quot;nfq_get_msg_packet_hdr failed\\n&quot;);        return -1;    &#125;    /* 这里要注意，需要转成主机序 */    uint32_t id = ntohl(ph-&gt;packet_id);    return nfq_set_verdict(qh, id, NF_ACCEPT, 0, NULL);&#125;int main()&#123;    struct nfq_handle *h = NULL;    struct nfq_q_handle *qh = NULL;    int fd = -1;    int ret;    char buf[MAX_BUF] __attribute__ ((aligned));    h = nfq_open();    if (!h) &#123;        printf(&quot;nfq_open failed\\n&quot;);        goto out;    &#125;    if (nfq_unbind_pf(h, AF_INET) &lt; 0) &#123;        printf(&quot;nfq_unbind_pf failed\\n&quot;);        goto out;    &#125;    if (nfq_bind_pf(h, AF_INET) &lt; 0) &#123;        printf(&quot;nfq_bind_pf failed\\n&quot;);        goto out;    &#125;    qh = nfq_create_queue(h, QUEUE_NUM, &amp;cb, NULL);    if (!qh) &#123;        printf(&quot;nfq_create_queue failed\\n&quot;);        goto out;    &#125;    /* 拷贝整个数据包 */    ret = nfq_set_mode(qh, NFQNL_COPY_PACKET, 0xffff);    if (ret &lt; 0) &#123;        printf(&quot;nfq_set_mode failed\\n&quot;);        goto out;    &#125;    /* 调大内核 nfqueue 环形队列长度，     * 这表示内核最大能缓存多少个尚未被用户态处理的包 */    ret = nfq_set_queue_maxlen(qh, QUEUE_MAXLEN);    if (ret &lt; 0) &#123;        printf(&quot;nfq_set_queue_maxlen failed\\n&quot;);    &#125;    fd = nfq_fd(h);    if (fd &lt; 0) &#123;        printf(&quot;nfq_fd failed\\n&quot;);        goto out;    &#125;    printf(&quot;nfqueue started, queue=%d\\n&quot;, QUEUE_NUM);    while (1) &#123;        int n = recv(fd, buf, sizeof(buf), 0);        if (n &lt; 0) &#123;            if (errno == EINTR)                continue;            perror(&quot;recv&quot;);            break;        &#125;        if (n == 0) &#123;            printf(&quot;recv returned 0\\n&quot;);            break;        &#125;        ret = nfq_handle_packet(h, buf, n);        if (ret &lt; 0) &#123;            printf(&quot;nfq_handle_packet error: %d\\n&quot;, ret);        &#125;    &#125;out:    if (qh)        nfq_destroy_queue(qh);    if (h)        nfq_close(h);    return 0;&#125;\n\n裁决下发的函数：\nint nfq_set_verdict(struct nfq_q_handle *qh, uint32_t id,\t\t    uint32_t verdict, uint32_t data_len,\t\t    const unsigned char *buf)&#123;\treturn __set_verdict(qh, id, verdict, 0, 0, data_len, buf,\t\t\t\t\t\tNFQNL_MSG_VERDICT);&#125;\n\n对应内核处理函数：\nnfqnl_recv_verdict() └── nfqnl_reinject()      └── nf_reinject()\n\n这里将决定数据包最终的命运：放行 or 拦截 or 再次入队\nvoid nf_reinject(struct nf_queue_entry *entry, unsigned int verdict)&#123;  ......\tswitch (verdict &amp; NF_VERDICT_MASK) &#123;\tcase NF_ACCEPT:\tcase NF_STOP:\t\t/* 放行啦，继续执行其后续流程，送往协议栈上层处理函数，ip_local_deliver_finish */\t\tlocal_bh_disable();\t\tentry-&gt;state.okfn(entry-&gt;state.net, entry-&gt;state.sk, skb);\t\tlocal_bh_enable();\t\tbreak;\tcase NF_QUEUE:\t\t/* 太扯了，又让我再次入队 */\t\terr = nf_queue(skb, &amp;entry-&gt;state, i, verdict);\t\tif (err == 1)\t\t\tgoto next_hook;\t\tbreak;\tcase NF_STOLEN:\t\tbreak;\tdefault:\t\t/* 其它，比如 drop，那就直接释放数据包即可 */\t\tkfree_skb(skb);\t&#125;   ......&#125;\n\n基本处理流程大体如上。\n","categories":["linux6.6内核"],"tags":["网络","netfilter","nfqueue","iptables","hook"]},{"title":"listen系统调用","url":"/2025/12/17/listen%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","content":"glibc listen函数介绍我们使用的bind函数，原型如下。代码位置为：&#x2F;usr&#x2F;include&#x2F;x86_64-linux-gnu&#x2F;sys&#x2F;socket.h\nextern int listen (int __fd, int __n) __THROW;\n\n\n\n\n参数\n介绍\n\n\n\n__fd\nsocket返回的fd\n\n\n__n\n想要设置的全连接队列的大小\n\n\n而listen函数是glibc中提供的函数，我们看下glibc中的listen函数实现。代码位置在：glibc-2.41&#x2F;sysdeps&#x2F;unix&#x2F;sysv&#x2F;linux&#x2F;listen.c\n#include &lt;sys/socket.h&gt;#include &lt;socketcall.h&gt;intlisten (int fd, int backlog)&#123;#ifdef __ASSUME_LISTEN_SYSCALL  return INLINE_SYSCALL_CALL (listen, fd, backlog);#else  return SOCKETCALL (listen, fd, backlog);#endif&#125;weak_alias (listen, __listen);\n\nglibc中的listen函数也几乎什么都没做，可以理解为仅仅是内核listen系统调用(__do_sys_listen)的一个封装。中间的步骤在syscall调用流程分析中有做展开讲解，这里不再赘述。\nlisten系统调用我们首先来看下listen系统调用的入口。可以看到__do_sys_listen，什么都没做，只是再次调用了__sys_listen。\nSYSCALL_DEFINE2(listen, int, fd, int, backlog)&#123;\treturn __sys_listen(fd, backlog);&#125;\n\n\n__sys_listen中，首先调用sockfd_lookup_light，根据fd找到对应的socket结构，如果没找到，代表外围传了个垃圾fd，直接返回错误。如果找到了，将传入的backlog与内核参数somaxconn两者取较小值，然后作为该sk的最终的全连接队列的最大数量限制，也就是最多同时能有这么多个完成三次握手，而未被accept的连接。然后过lsm socket_listen hook点，然后去调用该socket真正对应的协议操作集合的listen函数。该函数只有对于流式套接字才有效，是inet_listen，对于非流式套接字，就是sock_no_listen。sock_no_listen什么都没做。因此我们主要看inet_listen。\n/* *  这里的backlog表示已经完成三次握手但是没有被accept的最大数量，也就是全连接队列最大数量 */int __sys_listen(int fd, int backlog)&#123;\tstruct socket *sock;\tint err, fput_needed;\tint somaxconn;\t/* 根据fd找到对应的sock */\tsock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);\tif (sock) &#123;\t\t/* 注意这里取得是 min(backlog, somaxconn) */\t\tsomaxconn = READ_ONCE(sock_net(sock-&gt;sk)-&gt;core.sysctl_somaxconn);\t\tif ((unsigned int)backlog &gt; somaxconn)\t\t\tbacklog = somaxconn;\t\t/* lsm socket_listen hook点 */\t\terr = security_socket_listen(sock, backlog);\t\tif (!err) &#123;\t\t\t/* inet_listen 、sock_no_listen\t\t\t * 只有流式套接字才有inet_listen，\t\t\t * 用户数据报、原始套接字都是sock_no_listen */\t\t\terr = READ_ONCE(sock-&gt;ops)-&gt;listen(sock, backlog);\t\t&#125;\t\t/* 递减引用计数 */\t\tfput_light(sock-&gt;file, fput_needed);\t&#125;\treturn err;&#125;\n\n\ninet_listen首先对sk上锁，然后判断socket的type和状态是否符合。符合则去调用__inet_listen_sk。\n/* *\tMove a socket into listening state. *  由 __sys_listen 调用 */int inet_listen(struct socket *sock, int backlog)&#123;\tstruct sock *sk = sock-&gt;sk;\tint err = -EINVAL;\tlock_sock(sk);\t/* 必须是流式套接字，并且是未连接状态的，才能调用 listen，否则 goto out */\tif (sock-&gt;state != SS_UNCONNECTED || sock-&gt;type != SOCK_STREAM)\t\tgoto out;\terr = __inet_listen_sk(sk, backlog);out:\trelease_sock(sk);\treturn err;&#125;EXPORT_SYMBOL(inet_listen);\n\n\n在__inet_listen_sk中，判断下套接字当前的状态，如果是不是处于 CLOSE 或者 LISTEN 状态，直接返回无效。如果是处于 CLOSE 或者 LISTEN 状态，则去更新该sk的全连接队列大小。如果套接字已经处于LISTEN状态了，那就什么都不需要再做了，直接返回，这通常是之前已经调过listen了。如果之前不是LISTEN状态，那肯定就是CLOSE状态，是首次调用listen。读取内核参数tcp_fastopen，这是 TFO 全局开关，因为调用了listen，所以我们肯定是要做服务端的。tcp_fastopen是2时，代表服务端支持fastopen。需要满足下面三个条件，才判断是否需要为服务端tfo做初始化：\n\nTFO_SERVER_ENABLE 就是允许服务端enable。\nTFO_SERVER_WO_SOCKOPT1 就是允许 不设置 TCP_FASTOPEN sockopt 的服务端使用 TFO。\nfastopenq 尚未初始化，这是为了避免重复初始化tfo。接下来就是调用inet_csk_listen_start。\n\n/* 由 inet_listen 调用 */int __inet_listen_sk(struct sock *sk, int backlog)&#123;\tunsigned char old_state = sk-&gt;sk_state;\tint err, tcp_fastopen;\t/* 如果套接字不是处于 CLOSE 或者 LISTEN 状态，直接返回无效 */\tif (!((1 &lt;&lt; old_state) &amp; (TCPF_CLOSE | TCPF_LISTEN)))\t\treturn -EINVAL;\t/* 更新全连接队列大小限制，backlog 是在 __sys_listen 中赋值的，\t * 用的是 listen第二参数 和 somaxconn 取得两者中的最小值 */\tWRITE_ONCE(sk-&gt;sk_max_ack_backlog, backlog);\t/* Really, if the socket is already in listen state\t * we can only allow the backlog to be adjusted.\t * 如果sk状态已经是 TCP_LISTEN 了，那就只更新全连接队列大小，其它什么都不做\t */\tif (old_state != TCP_LISTEN) &#123;\t\t/* Enable TFO w/o requiring TCP_FASTOPEN socket option.\t\t * Note that only TCP sockets (SOCK_STREAM) will reach here.\t\t * Also fastopen backlog may already been set via the option\t\t * because the socket was in TCP_LISTEN state previously but\t\t * was shutdown() rather than close().\t\t * 这里只判断是否有TFO_SERVER_ENABLE，因为这里是调用 listen，显然要作为一个server\t\t */\t\ttcp_fastopen = READ_ONCE(sock_net(sk)-&gt;ipv4.sysctl_tcp_fastopen);\t\tif ((tcp_fastopen &amp; TFO_SERVER_WO_SOCKOPT1) &amp;&amp;\t\t    (tcp_fastopen &amp; TFO_SERVER_ENABLE) &amp;&amp;\t\t    !inet_csk(sk)-&gt;icsk_accept_queue.fastopenq.max_qlen) &#123;\t\t\tfastopen_queue_tune(sk, backlog);\t\t\ttcp_fastopen_init_key_once(sock_net(sk));\t\t&#125;\t\terr = inet_csk_listen_start(sk);\t\tif (err)\t\t\treturn err;\t\ttcp_call_bpf(sk, BPF_SOCK_OPS_TCP_LISTEN_CB, 0, NULL);\t&#125;\treturn 0;&#125;\n\n\ninet_csk_listen_start() 就是 TCP 从 已 bind 的普通 socket 进入 真正可被 accept 的监听 socket 的核心一步。inet_csk_listen_start中，会先 初始化 request_sock_queue 相关，这是存储全连接队列、半连接队列数量信息的结构。然后将sk的全连接队列当前大小置0。并初始化延迟ACK相关状态。然后将sk的状态置为LISTEN，再调用get_port检查下端口是否绑定，如果没绑定，随机分配一个端口，如果绑定了，就直接调用inet_hash，将sk添加到lhash2哈希表上。\n/* 由 __inet_listen_sk 调用， * inet_csk_listen_start() 就是 TCP 从 已 bind 的普通 socket 进入 真正可被 accept 的监听 socket 的核心一步 */int inet_csk_listen_start(struct sock *sk)&#123;\tstruct inet_connection_sock *icsk = inet_csk(sk);\tstruct inet_sock *inet = inet_sk(sk);\tint err;\terr = inet_ulp_can_listen(sk);\tif (unlikely(err))\t\treturn err;\t/* 初始化 request_sock_queue 相关，\t * 这个里面会存储全连接队列，还会存储半连接队列的数量信息 */\treqsk_queue_alloc(&amp;icsk-&gt;icsk_accept_queue);\t/* 将sk的全连接队列当前大小清0 */\tsk-&gt;sk_ack_backlog = 0;\t/* 初始化 延迟 ACK 相关状态 */\tinet_csk_delack_init(sk);\t/* There is race window here: we announce ourselves listening,\t * but this transition is still not validated by get_port().\t * It is OK, because this socket enters to hash table only\t * after validation is complete.\t * 把 socket 状态写成 TCP_LISTEN\t */\tinet_sk_state_store(sk, TCP_LISTEN);\t/* inet_csk_get_port，检查下端口是否绑定了，防止没有bind，直接调了listen的情况 */\terr = sk-&gt;sk_prot-&gt;get_port(sk, inet-&gt;inet_num);\tif (!err) &#123;\t\tinet-&gt;inet_sport = htons(inet-&gt;inet_num);\t\t/* 清空该 socket 的目的路由缓存dst */\t\tsk_dst_reset(sk);\t\t/* inet_hash  \t\t * 这里面将这个 已置为监听状态的sk 插入到 lhash2哈希表 的 ilb2 哈希桶中 */\t\terr = sk-&gt;sk_prot-&gt;hash(sk);\t\tif (likely(!err))\t\t\treturn 0;\t&#125;\t/* 失败了，状态设置为 TCP_CLOSE */\tinet_sk_set_state(sk, TCP_CLOSE);\treturn err;&#125;EXPORT_SYMBOL_GPL(inet_csk_listen_start);\n\n\n再inet_hash中，会调用__inet_hash，而__inet_hash主要负责将该sk加入到lhash2哈希表上。只有这样，当有客户端想要连接时，才能在lhash2中找到对应的服务端sk。\n/* 由 inet_csk_listen_start 调用 */int inet_hash(struct sock *sk)&#123;\tint err = 0;\tif (sk-&gt;sk_state != TCP_CLOSE)\t\terr = __inet_hash(sk, NULL);\treturn err;&#125;EXPORT_SYMBOL_GPL(inet_hash);/* 由 inet_hash 调用 * 将监听状态的sk插入到lhash2哈希表的ilb2哈希桶中 */int __inet_hash(struct sock *sk, struct sock *osk)&#123;\tstruct inet_hashinfo *hashinfo = tcp_or_dccp_get_hashinfo(sk);\tstruct inet_listen_hashbucket *ilb2;\tint err = 0;\tif (sk-&gt;sk_state != TCP_LISTEN) &#123;\t\tlocal_bh_disable();\t\tinet_ehash_nolisten(sk, osk, NULL);\t\tlocal_bh_enable();\t\treturn 0;\t&#125;\tWARN_ON(!sk_unhashed(sk));\t/* 获取sk在lhash2上面对应的哈希桶 */\tilb2 = inet_lhash2_bucket_sk(hashinfo, sk);\tspin_lock(&amp;ilb2-&gt;lock);\tif (sk-&gt;sk_reuseport) &#123;\t\terr = inet_reuseport_add_sock(sk, ilb2);\t\tif (err)\t\t\tgoto unlock;\t&#125;\t/* 将监听状态的sk插入到lhash2哈希表的ilb2哈希桶中 */\tif (IS_ENABLED(CONFIG_IPV6) &amp;&amp; sk-&gt;sk_reuseport &amp;&amp;\t\tsk-&gt;sk_family == AF_INET6)\t\t__sk_nulls_add_node_tail_rcu(sk, &amp;ilb2-&gt;nulls_head);\telse\t\t__sk_nulls_add_node_rcu(sk, &amp;ilb2-&gt;nulls_head);\tsock_set_flag(sk, SOCK_RCU_FREE);\tsock_prot_inuse_add(sock_net(sk), sk-&gt;sk_prot, 1);unlock:\tspin_unlock(&amp;ilb2-&gt;lock);\treturn err;&#125;EXPORT_SYMBOL(__inet_hash);\n\n总结listen()的作用是把一个已具备端口资源的 TCP socket，转换成可接收连接请求的监听入口。内核会初始化连接请求与 accept 队列，将 socket 状态切换为 TCP_LISTEN，验或分配本地端口，并把该 socket 插入监听哈希表，使后续到来的 SYN 报文能够被正确路由到这个监听 socket 上。\n","categories":["linux6.6内核"],"tags":["socket","网络","listen"]},{"title":"connect系统调用（二）","url":"/2025/12/23/connect%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%EF%BC%88%E4%BA%8C%EF%BC%89/","content":"connect系统调用接上文connect系统调用（一）。\n\n我们来看下connect的核心，第一次握手包发送的具体实现函数：tcp_v4_connect。在这里，首先再次对地址长度、地址协议类型进行合法性检测。然后判断是否设置了源路由选项，有的话，就将用户指定的ip更新为下一跳地址，然后进行路由查找。如果目的地址是属于多播、广播的地址，那就直接返回，因为tcp是一对一的、面向连接的。将路由查找后得到的源ip设置到sock上。复位时间戳信息。将sk_state设置为 SYN_SEND，然后调用 inet_hash_connect ，如果绑定过 源port，那就检查下直接返回了，如果没有绑定过，那就在系统允许的随机端口范围内，随机选择一个端口。更新inet_id，它决定了iph-&gt;id。判断是否是 TFO 延迟connect。调用tcp_connect，发送第一次握手包，并启动重传定时器。\n/* This will initiate an outgoing connection.  * 由 __inet_stream_connect 调用， * 核心目的：发送第一次握手包，并启动重传定时器 * sk: 哪个sk想去connect * uaddr: 要connect的对端地址信息，注意这里已经是copy到内核态的地址了，可以直接访问 * addr_len: 这个其实还是connect()传入的第三参数，一般是sizeof(sockaddr_in) */int tcp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)&#123;\t/* usin也指向要connect的对端地址信息 */\tstruct sockaddr_in *usin = (struct sockaddr_in *)uaddr;\t/* 这个将要指向sk所属的ipv4命名空间的 tcp_death_row，\t * tcp管理所有sk的hashinfo哈希表集合 可以在这个里面找到 */\tstruct inet_timewait_death_row *tcp_death_row;\tstruct inet_sock *inet = inet_sk(sk);\tstruct tcp_sock *tp = tcp_sk(sk);\tstruct ip_options_rcu *inet_opt;\tstruct net *net = sock_net(sk);\t__be16 orig_sport, orig_dport;\t__be32 daddr, nexthop;\tstruct flowi4 *fl4;\tstruct rtable *rt;\tint err;\t/* 检查长度是否合法，这里一般应该是等于 */\tif (addr_len &lt; sizeof(struct sockaddr_in))\t\treturn -EINVAL;\t/* connect的地址不是AF_INET，直接返回不支持 */\tif (usin-&gt;sin_family != AF_INET)\t\treturn -EAFNOSUPPORT;\t/* 默认情况下，下一跳 和 目标地址 都是connect传入的对端的地址 */\tnexthop = daddr = usin-&gt;sin_addr.s_addr;\t/* 拿到ip opt */\tinet_opt = rcu_dereference_protected(inet-&gt;inet_opt, lockdep_sock_is_held(sk));\t/* 如果setsockopt设置了源路由选项，就把选项中的地址拿到，下面查路由的时候要用到 */\tif (inet_opt &amp;&amp; inet_opt-&gt;opt.srr) &#123;\t\tif (!daddr)\t\t\treturn -EINVAL;\t\t/* 更新下一跳地址 */\t\tnexthop = inet_opt-&gt;opt.faddr;\t&#125;\t/* 在listen之前，如果没有调用过bind的话，这里源端口是0，大概率这里是0 */\torig_sport = inet-&gt;inet_sport;\t/* 将目的端口设置为 connect带进来的对端端口 */\torig_dport = usin-&gt;sin_port;\t/* 这里调用查路由的接口 */\tfl4 = &amp;inet-&gt;cork.fl.u.ip4;\trt = ip_route_connect(fl4, nexthop, inet-&gt;inet_saddr,\t\t\t      sk-&gt;sk_bound_dev_if, IPPROTO_TCP, orig_sport,\t\t\t      orig_dport, sk);\tif (IS_ERR(rt)) &#123;\t\t/* 路由查询失败，返回不可达 */\t\terr = PTR_ERR(rt);\t\tif (err == -ENETUNREACH)\t\t\tIP_INC_STATS(net, IPSTATS_MIB_OUTNOROUTES);\t\treturn err;\t&#125;\t/* 目的地址属于多播、广播类型，那铁定不行，我们可是tcp，面向连接的，只能1对1 */\tif (rt-&gt;rt_flags &amp; (RTCF_MULTICAST | RTCF_BROADCAST)) &#123;\t\tip_rt_put(rt);\t\treturn -ENETUNREACH;\t&#125;\t/* 没有启用严格路由选项 */\tif (!inet_opt || !inet_opt-&gt;opt.srr)\t\tdaddr = fl4-&gt;daddr;\t/* 获取sk所属网络命名空间的 管理 tcp所有sk的各种哈希表的集合 */\ttcp_death_row = &amp;sock_net(sk)-&gt;ipv4.tcp_death_row;\t/* 如果用户没有指定源ip地址（也就是没有bind？），或者bind是ANY_ADDR？ */\tif (!inet-&gt;inet_saddr) &#123;\t\t/* 如果没有显示指定源ip地址，进入这里后把路由查找后得到的源ip设置到sock上 */\t\terr = inet_bhash2_update_saddr(sk,  &amp;fl4-&gt;saddr, AF_INET);\t\tif (err) &#123;\t\t\tip_rt_put(rt);\t\t\treturn err;\t\t&#125;\t&#125; else &#123;\t\t/* 就是将 inet-&gt;inet_saddr 赋值给 sk-&gt;sk_rcv_saddr */\t\tsk_rcv_saddr_set(sk, inet-&gt;inet_saddr);\t&#125;\t/* 如果有历史连接，这个时间戳就不为空吧，且两次地址不同？ */\tif (tp-&gt;rx_opt.ts_recent_stamp &amp;&amp; inet-&gt;inet_daddr != daddr) &#123;\t\t/* Reset inherited state \t\t * 复位时间戳信息，防老连接污染，\t\t * 防止 TIME_WAIT / 重用 socket 时 TCP timestamp 错乱 */\t\ttp-&gt;rx_opt.ts_recent\t   = 0;\t\ttp-&gt;rx_opt.ts_recent_stamp = 0;\t\tif (likely(!tp-&gt;repair))\t\t\tWRITE_ONCE(tp-&gt;write_seq, 0);\t&#125;\t/* 根据connect传入的对端地址信息设置dport */\tinet-&gt;inet_dport = usin-&gt;sin_port;\t/* 就是将 daddr 赋值给 sk-&gt;sk_daddr */\tsk_daddr_set(sk, daddr);\t/* 设置ip选项长度 */\tinet_csk(sk)-&gt;icsk_ext_hdr_len = 0;\tif (inet_opt)\t\tinet_csk(sk)-&gt;icsk_ext_hdr_len = inet_opt-&gt;opt.optlen;\t/* mss钳制到536 */\ttp-&gt;rx_opt.mss_clamp = TCP_MSS_DEFAULT;\t/* Socket identity is still unknown (sport may be zero).\t * However we set state to SYN-SENT and not releasing socket\t * lock select source port, enter ourselves into the hash tables and\t * complete initialization after this.\t * 即将发送第一次握手包，先将状态置为 SYN_SENT\t */\ttcp_set_state(sk, TCP_SYN_SENT);\t/* bind一个port并加入hash 表（查入ehash和bhash），因为有可能并没有bind过 */\terr = inet_hash_connect(tcp_death_row, sk);\tif (err)\t\tgoto failure;\t/* 设置txhash */\tsk_set_txhash(sk);\t/* 这里等于可能改变了新的port所以要在查一次路由 */\trt = ip_route_newports(fl4, rt, orig_sport, orig_dport,\t\t\t       inet-&gt;inet_sport, inet-&gt;inet_dport, sk);\tif (IS_ERR(rt)) &#123;\t\terr = PTR_ERR(rt);\t\trt = NULL;\t\tgoto failure;\t&#125;\t/* OK, now commit destination to socket.  */\tsk-&gt;sk_gso_type = SKB_GSO_TCPV4;\t/* 把 路由 dst_entry 上的能力 拷贝到 socket，TCP这里默认置位GSO */\tsk_setup_caps(sk, &amp;rt-&gt;dst);\trt = NULL;\t/* 不是热迁移场景，那就计算序列号和时间戳偏移，大概率不是 */\tif (likely(!tp-&gt;repair)) &#123;\t\tif (!tp-&gt;write_seq)\t\t\t/* 第一次握手前，计算下初始序列号，可以看到初始序号计算跟 四元组 和 net_secret 有关 */\t\t\tWRITE_ONCE(tp-&gt;write_seq,\t\t\t\t   secure_tcp_seq(inet-&gt;inet_saddr,\t\t\t\t\t\t  inet-&gt;inet_daddr,\t\t\t\t\t\t  inet-&gt;inet_sport,\t\t\t\t\t\t  usin-&gt;sin_port));\t\t\t\t/* 计算TCP时间戳偏移，防序列号预测攻击 */\t\tWRITE_ONCE(tp-&gt;tsoffset,\t\t\t   secure_tcp_ts_off(net, inet-&gt;inet_saddr,\t\t\t\t\t     inet-&gt;inet_daddr));\t&#125;\t/* 生成随机值，该值将用于iph的id */\tatomic_set(&amp;inet-&gt;inet_id, get_random_u16());\t/* TFO 延迟connect，返回true代表 延迟connect，那就没必要走底下了，直接返回 */\tif (tcp_fastopen_defer_connect(sk, &amp;err))\t\treturn err;\t/* 判断 TFO 是没开启，还是说开启了，但是失败了，\t * 如果是没开启，那err肯定还是0，走正常发第一次握手包流程即可，\t * 如果是err不为0，那就是 TFO 开启了，但是失败了(kzalloc失败，没内存了),\t * 或者是 TFO 开启了，但是这不是首次进来，也就是这次它要sendmsg了，也会走到这里 */\tif (err)\t\tgoto failure;\t/* 发送第一次握手包，并启动重传定时器(万一丢包了呢，重传第一次握手包啊) */\terr = tcp_connect(sk);\tif (err)\t\tgoto failure;\treturn 0;failure:\t/*\t * This unhashes the socket and releases the local port,\t * if necessary.\t * 失败了，进行回滚操作，将sk状态再置为close\t */\ttcp_set_state(sk, TCP_CLOSE);\tinet_bhash2_reset_saddr(sk);\tip_rt_put(rt);\tsk-&gt;sk_route_caps = 0;\t/* 上面设置了对端的目的端口，失败了，要置0 */\tinet-&gt;inet_dport = 0;\treturn err;&#125;EXPORT_SYMBOL(tcp_v4_connect);\n\n\ninet_hash_connect中，判断如果没有bind过，那inet_num是0，端口搞个搜索的起始偏移量，不能每次都从最头开始找，然后直接调用__inet_hash_connect。\n/* * Bind a port for a connect operation and hash it. * 由 tcp_v4_connect 调用 */int inet_hash_connect(struct inet_timewait_death_row *death_row,\t\t      struct sock *sk)&#123;\tu64 port_offset = 0;\t/* 如果没有bind过，那这里是0，端口搞个搜索的起始偏移量，不能每次都从最头开始找 */\tif (!inet_sk(sk)-&gt;inet_num)\t\tport_offset = inet_sk_port_offset(sk);\treturn __inet_hash_connect(death_row, sk, port_offset,\t\t\t\t   __inet_check_established);&#125;EXPORT_SYMBOL_GPL(inet_hash_connect);\n\n\n__inet_hash_connect 的作用是：为一个未 bind 的 TCP socket 在本地端口范围内选择一个不冲突的端口，同时完成 bhash 、bhash2 、ehash 的注册，必要时回收 TIME_WAIT，从而让这个 socket 在发 SYN 之前具备 “合法身份”。\n/* 由 inet_hash_connect 调用 */int __inet_hash_connect(struct inet_timewait_death_row *death_row,\t\tstruct sock *sk, u64 port_offset,\t\tint (*check_established)(struct inet_timewait_death_row *,\t\t\tstruct sock *, __u16, struct inet_timewait_sock **))&#123;\tstruct inet_hashinfo *hinfo = death_row-&gt;hashinfo;\tstruct inet_bind_hashbucket *head, *head2;\tstruct inet_timewait_sock *tw = NULL;\tint port = inet_sk(sk)-&gt;inet_num;\tstruct net *net = sock_net(sk);\tstruct inet_bind2_bucket *tb2;\tstruct inet_bind_bucket *tb;\tbool tb_created = false;\tu32 remaining, offset;\tint ret, i, low, high;\tint l3mdev;\tu32 index;\t/* 如果当前已经bind端口了，那就直接检查下 */\tif (port) &#123;\t\tlocal_bh_disable();\t\t/* __inet_check_established */\t\tret = check_established(death_row, sk, port, NULL);\t\tlocal_bh_enable();\t\treturn ret;\t&#125;\t/* sk没有绑定端口，那么去随机找个端口绑定 */\tl3mdev = inet_sk_bound_l3mdev(sk);\t/* 获取随机端口范围 */\tinet_sk_get_local_port_range(sk, &amp;low, &amp;high);\thigh++; /* [32768, 60999] -&gt; [32768, 61000] */\tremaining = high - low;\tif (likely(remaining &gt; 1))\t\tremaining &amp;= ~1U;\tget_random_sleepable_once(table_perturb,\t\t\t\t  INET_TABLE_PERTURB_SIZE * sizeof(*table_perturb));\tindex = port_offset &amp; (INET_TABLE_PERTURB_SIZE - 1);\toffset = READ_ONCE(table_perturb[index]) + (port_offset &gt;&gt; 32);\toffset %= remaining;\t/* In first pass we try ports of @low parity.\t * inet_csk_get_port() does the opposite choice.\t */\toffset &amp;= ~1U;other_parity_scan:\tport = low + offset;\tfor (i = 0; i &lt; remaining; i += 2, port += 2) &#123;\t\tif (unlikely(port &gt;= high))\t\t\tport -= remaining;\t\tif (inet_is_local_reserved_port(net, port))\t\t\tcontinue;\t\thead = &amp;hinfo-&gt;bhash[inet_bhashfn(net, port,\t\t\t\t\t\t  hinfo-&gt;bhash_size)];\t\tspin_lock_bh(&amp;head-&gt;lock);\t\t/* Does not bother with rcv_saddr checks, because\t\t * the established check is already unique enough.\t\t */\t\tinet_bind_bucket_for_each(tb, &amp;head-&gt;chain) &#123;\t\t\tif (inet_bind_bucket_match(tb, net, port, l3mdev)) &#123;\t\t\t\tif (tb-&gt;fastreuse &gt;= 0 ||\t\t\t\t    tb-&gt;fastreuseport &gt;= 0)\t\t\t\t\tgoto next_port;\t\t\t\tWARN_ON(hlist_empty(&amp;tb-&gt;owners));\t\t\t\t/* __inet_check_established */\t\t\t\tif (!check_established(death_row, sk,\t\t\t\t\t\t       port, &amp;tw))\t\t\t\t\tgoto ok;\t\t\t\tgoto next_port;\t\t\t&#125;\t\t&#125;\t\ttb = inet_bind_bucket_create(hinfo-&gt;bind_bucket_cachep,\t\t\t\t\t     net, head, port, l3mdev);\t\tif (!tb) &#123;\t\t\tspin_unlock_bh(&amp;head-&gt;lock);\t\t\treturn -ENOMEM;\t\t&#125;\t\ttb_created = true;\t\ttb-&gt;fastreuse = -1;\t\ttb-&gt;fastreuseport = -1;\t\tgoto ok;next_port:\t\tspin_unlock_bh(&amp;head-&gt;lock);\t\tcond_resched();\t&#125;\toffset++;\tif ((offset &amp; 1) &amp;&amp; remaining &gt; 1)\t\tgoto other_parity_scan;\treturn -EADDRNOTAVAIL;ok:\t/* Find the corresponding tb2 bucket since we need to\t * add the socket to the bhash2 table as well\t */\thead2 = inet_bhashfn_portaddr(hinfo, sk, net, port);\tspin_lock(&amp;head2-&gt;lock);\ttb2 = inet_bind2_bucket_find(head2, net, port, l3mdev, sk);\tif (!tb2) &#123;\t\ttb2 = inet_bind2_bucket_create(hinfo-&gt;bind2_bucket_cachep, net,\t\t\t\t\t       head2, port, l3mdev, sk);\t\tif (!tb2)\t\t\tgoto error;\t&#125;\t/* Here we want to add a little bit of randomness to the next source\t * port that will be chosen. We use a max() with a random here so that\t * on low contention the randomness is maximal and on high contention\t * it may be inexistent.\t */\ti = max_t(int, i, get_random_u32_below(8) * 2);\tWRITE_ONCE(table_perturb[index], READ_ONCE(table_perturb[index]) + i + 2);\t/* Head lock still held and bh&#x27;s disabled */\tinet_bind_hash(sk, tb, tb2, port);\tif (sk_unhashed(sk)) &#123;\t\tinet_sk(sk)-&gt;inet_sport = htons(port);\t\tinet_ehash_nolisten(sk, (struct sock *)tw, NULL);\t&#125;\tif (tw)\t\tinet_twsk_bind_unhash(tw, hinfo);\tspin_unlock(&amp;head2-&gt;lock);\tspin_unlock(&amp;head-&gt;lock);\tif (tw)\t\tinet_twsk_deschedule_put(tw);\tlocal_bh_enable();\treturn 0;error:\tspin_unlock(&amp;head2-&gt;lock);\tif (tb_created)\t\tinet_bind_bucket_destroy(hinfo-&gt;bind_bucket_cachep, tb);\tspin_unlock_bh(&amp;head-&gt;lock);\treturn -ENOMEM;&#125;\n\n\n__inet_check_established的作用是: 判断某个本地端口 lport 在当前五元组下是否 唯一可用，如果无冲突就把 socket 插入 ehash。如果只撞上 TIME_WAIT 且允许复用，则回收 TIME_WAIT；否则返回端口不可用。\n/* called with local bh disabled  * 由 __inet_hash_connect 调用 */static int __inet_check_established(struct inet_timewait_death_row *death_row,\t\t\t\t    struct sock *sk, __u16 lport,\t\t\t\t    struct inet_timewait_sock **twp)&#123;\tstruct inet_hashinfo *hinfo = death_row-&gt;hashinfo;\tstruct inet_sock *inet = inet_sk(sk);\t__be32 daddr = inet-&gt;inet_rcv_saddr;\t__be32 saddr = inet-&gt;inet_daddr;\tint dif = sk-&gt;sk_bound_dev_if;\tstruct net *net = sock_net(sk);\tint sdif = l3mdev_master_ifindex_by_index(net, dif);\tINET_ADDR_COOKIE(acookie, saddr, daddr);\tconst __portpair ports = INET_COMBINED_PORTS(inet-&gt;inet_dport, lport);\tunsigned int hash = inet_ehashfn(net, daddr, lport,\t\t\t\t\t saddr, inet-&gt;inet_dport);\tstruct inet_ehash_bucket *head = inet_ehash_bucket(hinfo, hash);\tspinlock_t *lock = inet_ehash_lockp(hinfo, hash);\tstruct sock *sk2;\tconst struct hlist_nulls_node *node;\tstruct inet_timewait_sock *tw = NULL;\tspin_lock(lock);\t/* 遍历ehash 上head对应的哈希桶上的所有entry */\tsk_nulls_for_each(sk2, node, &amp;head-&gt;chain) &#123;\t\t/* hash 不相同，只是跟哈希表大小 &amp; 之后，落在了一个桶上，那不是我们关注的，直接continue */\t\tif (sk2-&gt;sk_hash != hash)\t\t\tcontinue;\t\t/* hash完全相同，检查各个字段是否匹配 */\t\tif (likely(inet_match(net, sk2, acookie, ports, dif, sdif))) &#123;\t\t\t/* 如果有匹配的，且是 timewait */\t\t\tif (sk2-&gt;sk_state == TCP_TIME_WAIT) &#123;\t\t\t\ttw = inet_twsk(sk2);\t\t\t\t/* 重用 TIME_WAIT socket */\t\t\t\tif (twsk_unique(sk, sk2, twp))\t\t\t\t\tbreak;\t\t\t&#125;\t\t\tgoto not_unique;\t\t&#125;\t&#125;\t/* Must record num and sport now. Otherwise we will see\t * in hash table socket with a funny identity.\t * 走到这里代表可以使用/重用这个lport\t */\tinet-&gt;inet_num = lport;\tinet-&gt;inet_sport = htons(lport);\tsk-&gt;sk_hash = hash;\tWARN_ON(!sk_unhashed(sk));\t/* 新sk插入到ehash */\t__sk_nulls_add_node_rcu(sk, &amp;head-&gt;chain);\tif (tw) &#123;\t\t/* 如果是重用的，把timewait的那个sk从ehash中删除 */\t\tsk_nulls_del_node_init_rcu((struct sock *)tw);\t\t__NET_INC_STATS(net, LINUX_MIB_TIMEWAITRECYCLED);\t&#125;\tspin_unlock(lock);\tsock_prot_inuse_add(sock_net(sk), sk-&gt;sk_prot, 1);\tif (twp) &#123;\t\t*twp = tw;\t&#125; else if (tw) &#123;\t\t/* Silly. Should hash-dance instead... \t\t * 释放tw的资源 */\t\tinet_twsk_deschedule_put(tw);\t&#125;\treturn 0;not_unique:\tspin_unlock(lock);\treturn -EADDRNOTAVAIL;&#125;\n\n\n判断是否是开启了TFO，开启的话，判断是否由可用的 TFO cookie，如果 没有 cookie（也就是第一次连这个 server），则不能立即构造完整的 TFO SYN，需要先发普通 SYN，从 SYN+ACK 中学到 cookie。如果有 cookie 的情况，可直接发 TFO SYN。\n/* This function checks if we want to defer sending SYN until the first * write().  We defer under the following conditions: * 1. fastopen_connect sockopt is set * 2. we have a valid cookie * Return value: return true if we want to defer until application writes data *               return false if we want to send out SYN immediately * 由 tcp_v4_connect 调用 */bool tcp_fastopen_defer_connect(struct sock *sk, int *err)&#123;\tstruct tcp_fastopen_cookie cookie = &#123; .len = 0 &#125;;\tstruct tcp_sock *tp = tcp_sk(sk);\tu16 mss;\t/* TFO 想要开启，必须 setsockopt 将 fastopen_connect 置位，否则认为没开启 TFO，\t * 开启 TFO 首次进来时，fastopen_connect 应该置位了，fastopen_req 应该为空 */\tif (tp-&gt;fastopen_connect &amp;&amp; !tp-&gt;fastopen_req) &#123;\t\t/* 判断是否由可用的 TFO cookie，如果 没有 cookie（第一次连这个 server），\t\t * 不能立即构造完整的 TFO SYN，需要先发普通 SYN，从 SYN+ACK 中学到 cookie */\t\tif (tcp_fastopen_cookie_check(sk, &amp;mss, &amp;cookie)) &#123;\t\t\tinet_set_bit(DEFER_CONNECT, sk);\t\t\treturn true;\t\t&#125;\t\t/* Alloc fastopen_req in order for FO option to be included in SYN\t\t * 有 cookie 的情况，可直接发 TFO SYN */\t\ttp-&gt;fastopen_req = kzalloc(sizeof(*tp-&gt;fastopen_req),\t\t\t\t\t   sk-&gt;sk_allocation);\t\tif (tp-&gt;fastopen_req)\t\t\ttp-&gt;fastopen_req-&gt;cookie = cookie;\t\telse\t\t\t*err = -ENOBUFS;\t&#125;\t/* 走到这里，三种情况：\t * 1. 没开启 TFO\t * 2. 开启 TFO 了，但是kzalloc失败了\t * 3. 开启 TFO 了，但是非首次进来（因为首次进来会赋值fastopen_req） */\treturn false;&#125;EXPORT_SYMBOL(tcp_fastopen_defer_connect);\n\n\n在 tcp_connect 中，构建syn握手包，发送前将其插入到sk的重传队列中(红黑树管理)。然后判断是否是TFO，是TFO，则调用 tcp_send_syn_data 发包。不是TFO则直接调用 tcp_transmit_skb 发包。更新序列号信息，并调用 inet_csk_reset_xmit_timer，启动 icsk_retransmit_timer 重传定时器。\n/* Build a SYN and send it off.  * 只由 tcp_v4_connect、 tcp_sendmsg_fastopen 、 tcp_v6_connect 调用  * 发送第一次握手SYN包 */int tcp_connect(struct sock *sk)&#123;\tstruct tcp_sock *tp = tcp_sk(sk);\tstruct sk_buff *buff;\tint err;\ttcp_call_bpf(sk, BPF_SOCK_OPS_TCP_CONNECT_CB, 0, NULL);\tif (inet_csk(sk)-&gt;icsk_af_ops-&gt;rebuild_header(sk))\t\treturn -EHOSTUNREACH; /* Routing failure or similar. */\t/* 初始化相关结构 */\ttcp_connect_init(sk);\tif (unlikely(tp-&gt;repair)) &#123;\t\ttcp_finish_connect(sk, NULL);\t\treturn 0;\t&#125;\t/* 申请一个skb */\tbuff = tcp_stream_alloc_skb(sk, sk-&gt;sk_allocation, true);\tif (unlikely(!buff))\t\treturn -ENOBUFS;\t/* 初始化一个没有数据的syn标志置位的包 */\ttcp_init_nondata_skb(buff, tp-&gt;write_seq++, TCPHDR_SYN);\ttcp_mstamp_refresh(tp);\ttp-&gt;retrans_stamp = tcp_time_stamp(tp);\ttcp_connect_queue_skb(sk, buff);\ttcp_ecn_send_syn(sk, buff);\t/* 将 第一次要发送的数据包buff ，在发送前插入到sk的重传队列中(红黑树管理),\t * 应该是怕数据包丢失后，重传使用的 */\ttcp_rbtree_insert(&amp;sk-&gt;tcp_rtx_queue, buff);\t/* Send off SYN; include data in Fast Open. \t * 发送第一次握手 SYN 包 */\terr = tp-&gt;fastopen_req ? tcp_send_syn_data(sk, buff) :\t      tcp_transmit_skb(sk, buff, 1, sk-&gt;sk_allocation);\tif (err == -ECONNREFUSED)\t\treturn err;\t/* We change tp-&gt;snd_nxt after the tcp_transmit_skb() call\t * in order to make this packet get counted in tcpOutSegs.\t */\tWRITE_ONCE(tp-&gt;snd_nxt, tp-&gt;write_seq);\ttp-&gt;pushed_seq = tp-&gt;write_seq;\tbuff = tcp_send_head(sk);\tif (unlikely(buff)) &#123;\t\tWRITE_ONCE(tp-&gt;snd_nxt, TCP_SKB_CB(buff)-&gt;seq);\t\ttp-&gt;pushed_seq\t= TCP_SKB_CB(buff)-&gt;seq;\t&#125;\tTCP_INC_STATS(sock_net(sk), TCP_MIB_ACTIVEOPENS);\t/* Timer for repeating the SYN until an answer. \t * 启动重传定时器 */\tinet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,\t\t\t\t  inet_csk(sk)-&gt;icsk_rto, TCP_RTO_MAX);\treturn 0;&#125;EXPORT_SYMBOL(tcp_connect);\n\n\n发完包返回后，会计算sndtmo，进入阻塞等待 或 非阻塞直接返回，阻塞等待就会进入睡眠，等待唤醒，直到来包了 或 被信号中断了 或 超时了。\n/* 由 __inet_stream_connect 调用 */static long inet_wait_for_connect(struct sock *sk, long timeo, int writebias)&#123;\tDEFINE_WAIT_FUNC(wait, woken_wake_function);\t/* 挂到 sk 所属 socket 的等待队列上 */\tadd_wait_queue(sk_sleep(sk), &amp;wait);\tsk-&gt;sk_write_pending += writebias;\t/* Basic assumption: if someone sets sk-&gt;sk_err, he _must_\t * change state of the socket from TCP_SYN_*.\t * Connect() does not allow to get error notifications\t * without closing the socket.\t * 只有 当前 sk 的 sk_state 处于 SYN_SENT 或 SYN_RECV，才去阻塞等待，\t * 因此这两个状态才表示处于三次握手中\t */\twhile ((1 &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_SYN_SENT | TCPF_SYN_RECV)) &#123;\t\trelease_sock(sk);\t\ttimeo = wait_woken(&amp;wait, TASK_INTERRUPTIBLE, timeo);\t\tlock_sock(sk);\t\t/* 被信号打断，或者是超时了，那就退出去 */\t\tif (signal_pending(current) || !timeo)\t\t\tbreak;\t&#125;\tremove_wait_queue(sk_sleep(sk), &amp;wait);\tsk-&gt;sk_write_pending -= writebias;\treturn timeo;&#125;\n\n总结connect 的本质是：为 socket 确定本地四元组（源 IP + 源端口），注册进 TCP 管理使用的的各种哈希表，然后发送第一个 SYN包，并启动重传定时器，等待服务端应答。服务端回复第二次握手包后，客户端内核会自动回复ack。connect阻塞处会被唤醒，就返回了。客户端就认为连接建立成功了(其实第三次握手包可能丢失)，客户端容忍第三次握手包丢失，针对第三次握手包丢失客户端不主动做处理，而是服务端检测到一直不回复第三次握手包，会再次重传第二次握手包，然后客户端会再次响应，发送第三次握手ack包。\n","categories":["linux6.6内核"],"tags":["socket","网络","tcp建连","connect"]},{"title":"preload与poor_inline_hook","url":"/2026/01/28/preload%E4%B8%8Epoor_inline_hook/","content":"一、背景介绍部门每年都有培训与分享的计划，这次在强哥的建议下，让我组织一次内部分享。我选取了一个在自动化探针（硬件监测）项目中真实遇到的问题，作为本次分享主题，主要围绕 LD_PRELOAD 与 inline hook 介绍。\n首先介绍下自动化探针，它的核心目标，是对服务器硬件与系统状态进行自动采集、分析与上报，包括：\n\nCPU &#x2F; 内存 &#x2F; 网络 &#x2F; 磁盘 &#x2F; RAID &#x2F; 风扇 &#x2F; 电源 等多类指标\n数据采集 → 写入环形缓冲区 → 消费线程读取 → 格式化 → 上报平台\n\n二、问题介绍在自动化探针项目中，我们需要单元自测来验证指标采集逻辑是否正确。\n有些指标很好构造，比如：\n\n僵尸进程数量\n文件句柄数\nCPU 使用率\n内存占用这些都可以通过写小程序、人为制造负载，很容易构造测试环境。\n\n有些指标几乎没法“真实构造”，比如：\n\n硬盘异常 \n风扇转速过低\n温度传感器异常\n\n在测试环境中，不可能为了测试去真的搞坏硬盘或风扇。  我们希望的是不更改源码、不重新编译、不修改默认的配置文件来模拟各种异常场景，所以我们使用了preload来做测试。\n三、什么是 LD_PRELOADLD_PRELOAD 是 Linux 动态链接器（ld.so）提供的一个机制：允许在程序启动时，优先加载用户指定的共享库，并优先使用其中的符号实现。\n比如下面的例子：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;strings.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdbool.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;/* 为了验证preload是否能hook 自身elf的函数， * 该函数返回raid卡状态是否正常 */void func_myelf_get_raid_status(bool *exception)&#123;    printf(&quot;this is myelf get raid status func\\n&quot;);    /* Set exception to false */    *exception = false;&#125;/* 为了验证preload是否能hook glibc的函数 */static void func_glibc_write_data(void)&#123;    int fd;    const char msg[] = &quot;This is glibc write&#x27;s data message.\\n&quot;;    fd = open(&quot;./testfile.txt&quot;, O_RDWR | O_CREAT | O_APPEND, S_IRUSR | S_IWUSR);    if (fd == -1) &#123;        perror(&quot;open&quot;);        return;    &#125;    if (write(fd, msg, strlen(msg)) &lt; 0) &#123;        perror(&quot;write&quot;);        close(fd);        return;    &#125;    close(fd);    printf(&quot;File operations completed successfully.\\n&quot;);&#125;int main(int argc, char **argv)&#123;    bool exception;    printf(&quot;%s starting ...\\n&quot;, argv[0]);    printf(&quot;-------------------------\\n&quot;);    printf(&quot;test func glibc write data\\n&quot;);    func_glibc_write_data();    printf(&quot;-------------------------\\n&quot;);    printf(&quot;test func myelf get raid status\\n&quot;);    func_myelf_get_raid_status(&amp;exception);    printf(&quot;raid status is %s\\n&quot;, exception ? &quot;abnormal&quot; : &quot;normal&quot;);    printf(&quot;-------------------------\\n&quot;);    printf(&quot;%s ending ...\\n&quot;, argv[0]);    getchar();    return 0;&#125;\n\n这个程序里，主要做了两件事：\n\n调用 func_glibc_write_data 来往当前目录下的testfile.txt文件中，写入消息”This is glibc write’s data message.\\n”。\n调用 func_myelf_get_raid_status 来获取raid卡状态。\n\n我们写了一个供preload用的so，主要用来 hook write，及 func_myelf_get_raid_status ，代码如下：\n#include &lt;dlfcn.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdbool.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;/* ========== write hook ========== */typedef ssize_t (*fn_write_t)(int, const void *, size_t);static fn_write_t g_real_write = NULL;ssize_t write(int fd, const void *buf, size_t count)&#123;    const char msg[] = &quot;This is hook glibc write&#x27;s data message.\\n&quot;;    const char hook_msg[] = &quot;[hook write]\\n&quot;;    if (!g_real_write) &#123;        g_real_write = (fn_write_t)dlsym(RTLD_NEXT, &quot;write&quot;);    &#125;    /* 避免递归：不要在这里 printf */    g_real_write(STDOUT_FILENO, hook_msg, sizeof(hook_msg) - 1);    return g_real_write(fd, msg, strlen(msg));&#125;/* ========== hook ELF 的函数 ========== *//* 和 main 里函数签名必须完全一致，会发现该函数根本不能hook成功，因为要hook的那个函数是elf里的全局函数 */void func_myelf_get_raid_status(bool *exception)&#123;    const char hook_msg[] = &quot;[hook func_myelf_get_raid_status]\\n&quot;;    if (!g_real_write) &#123;        g_real_write = (fn_write_t)dlsym(RTLD_NEXT, &quot;write&quot;);    &#125;    /* 提示下 hook 成功了*/    g_real_write(STDOUT_FILENO, hook_msg, sizeof(hook_msg) - 1);    /* 模拟异常 */    *exception = true;&#125;\n\n如果hook成功，则预期会打印 [hook write] 、[hook func_myelf_get_raid_status]。我们看下结果：\n$ LD_PRELOAD=./preload.so ./main                                            ./main starting ...-------------------------test func glibc write data[hook write]File operations completed successfully.-------------------------test func myelf get raid statusthis is myelf get raid status funcraid status is normal-------------------------./main ending ...\n\n从结果可以看出来：\n\n对 write 函数 hook 成功了，打印了 [hook write]。\nfunc_myelf_get_raid_status hook 失败了。这就是我在自动化探针中遇到的问题。想使用preload模拟异常，但是hook不生效。\n\n这两个函数的区别在于：一个是glibc中的函数、一个是elf里的普通函数。\n四、为什么elf里的普通函数无法hook4.1 write 为什么能 hook 成功？因为 write 是：\n\nglibc 提供的外部符号  \n调用时通过 PLT&#x2F;GOT  \n在运行时由动态链接器(ld.so)解析\n\n而 LD_PRELOAD 正是插在动态符号解析阶段，优先提供符号实现。所以：write → PLT → GOT → 动态链接器 → preload.so\n动态链接器优先选中了我们 preload 里的 write。\n4.2 func_myelf_get_raid_status 为什么 hook 失败？因为它是：\n\n主程序 ELF 自己定义的普通函数  \n链接时地址已经确定  \n调用时往往是直接 call 固定地址  \n不经过 GOT&#x2F;PLT  \n不经过动态符号解析\n\n所以：\n\n动态链接器根本“插不上手” \nLD_PRELOAD 对这种函数天然无效\n\n4.3 从汇编角度看我们可以从汇编代码查看到调用普通函数及调用glibc函数的区别，就会更加理解上面的说的结论。\n我们看下 main 、func_glibc_write_data 、func_myelf_get_raid_status函数的汇编代码，可以看到elf里写的普通函数，如 func_glibc_write_data 、func_myelf_get_raid_status，都是直接调用的，call的都是具体的函数的地址。但是 glibc中的函数，比如 write，调用的是plt表中函数。\n(gdb) disassemble mainDump of assembler code for function main:   0x0000555555555295 &lt;+0&gt;:     push   %rbp   0x0000555555555296 &lt;+1&gt;:     mov    %rsp,%rbp   0x0000555555555299 &lt;+4&gt;:     sub    $0x20,%rsp   0x000055555555529d &lt;+8&gt;:     mov    %edi,-0x14(%rbp)   0x00005555555552a0 &lt;+11&gt;:    mov    %rsi,-0x20(%rbp)=&gt; 0x00005555555552a4 &lt;+15&gt;:    mov    -0x20(%rbp),%rax   0x00005555555552a8 &lt;+19&gt;:    mov    (%rax),%rax   0x00005555555552ab &lt;+22&gt;:    mov    %rax,%rsi   0x00005555555552ae &lt;+25&gt;:    lea    0xdbb(%rip),%rax        # 0x555555556070   0x00005555555552b5 &lt;+32&gt;:    mov    %rax,%rdi   0x00005555555552b8 &lt;+35&gt;:    mov    $0x0,%eax   0x00005555555552bd &lt;+40&gt;:    call   0x555555555050 &lt;printf@plt&gt;   0x00005555555552c2 &lt;+45&gt;:    lea    0xdb8(%rip),%rax        # 0x555555556081   0x00005555555552c9 &lt;+52&gt;:    mov    %rax,%rdi   0x00005555555552cc &lt;+55&gt;:    call   0x555555555030 &lt;puts@plt&gt;   0x00005555555552d1 &lt;+60&gt;:    lea    0xdc3(%rip),%rax        # 0x55555555609b   0x00005555555552d8 &lt;+67&gt;:    mov    %rax,%rdi   0x00005555555552db &lt;+70&gt;:    call   0x555555555030 &lt;puts@plt&gt;   0x00005555555552e0 &lt;+75&gt;:    call   0x5555555551be &lt;func_glibc_write_data&gt;   0x00005555555552e5 &lt;+80&gt;:    lea    0xd95(%rip),%rax        # 0x555555556081   0x00005555555552ec &lt;+87&gt;:    mov    %rax,%rdi   0x00005555555552ef &lt;+90&gt;:    call   0x555555555030 &lt;puts@plt&gt;   0x00005555555552f4 &lt;+95&gt;:    lea    0xdbd(%rip),%rax        # 0x5555555560b8   0x00005555555552fb &lt;+102&gt;:   mov    %rax,%rdi   0x00005555555552fe &lt;+105&gt;:   call   0x555555555030 &lt;puts@plt&gt;   0x0000555555555303 &lt;+110&gt;:   lea    -0x1(%rbp),%rax   0x0000555555555307 &lt;+114&gt;:   mov    %rax,%rdi   0x000055555555530a &lt;+117&gt;:   call   0x555555555199 &lt;func_myelf_get_raid_status&gt;   0x000055555555530f &lt;+122&gt;:   movzbl -0x1(%rbp),%eax   0x0000555555555313 &lt;+126&gt;:   test   %al,%al   ...\n\n可以看到，func_myelf_get_raid_status 的代码段其实地址就是 0x555555555199，与main函数中的call地址符合。这也就是我们刚才4.2中说的，调用 func_myelf_get_raid_status ，不经过动态符号解析，不经过 GOT&#x2F;PLT ，动态链接器根本“插不上手” 。\n(gdb) disassemble func_myelf_get_raid_statusDump of assembler code for function func_myelf_get_raid_status:   0x0000555555555199 &lt;+0&gt;:     movabs $0x7ffff7fbb2cc,%rax   0x00005555555551a3 &lt;+10&gt;:    jmp    *%rax   0x00005555555551a5 &lt;+12&gt;:    lea    0xe5c(%rip),%rax        # 0x555555556008   0x00005555555551ac &lt;+19&gt;:    mov    %rax,%rdi   0x00005555555551af &lt;+22&gt;:    call   0x555555555030 &lt;puts@plt&gt;   0x00005555555551b4 &lt;+27&gt;:    mov    -0x8(%rbp),%rax   0x00005555555551b8 &lt;+31&gt;:    movb   $0x0,(%rax)   0x00005555555551bb &lt;+34&gt;:    nop   0x00005555555551bc &lt;+35&gt;:    leave   0x00005555555551bd &lt;+36&gt;:    retEnd of assembler dump.\n\n可以看到，func_glibc_write_data 的代码段其实地址就是 0x5555555551be，与main函数中的call地址符合。但是可以注意到，这里面write的调用，显示的是plt表中的write。\n(gdb) disassemble func_glibc_write_data   0x5555555551be &lt;func_glibc_write_data&gt;          push   %rbp                                                 0x5555555551bf &lt;func_glibc_write_data+1&gt;        mov    %rsp,%rbp                                            0x5555555551c2 &lt;func_glibc_write_data+4&gt;        sub    $0x30,%rsp                                           0x5555555551c6 &lt;func_glibc_write_data+8&gt;        movabs $0x2073692073696854,%rax                             ...                0x555555555255 &lt;func_glibc_write_data+151&gt;      call   0x555555555040 &lt;write@plt&gt;                           0x55555555525a &lt;func_glibc_write_data+156&gt;      test   %rax,%rax                                            ...\n\n\n上面从汇编角度解释了为什么普通函数无法hook生效，我们接下来gdb调试看下write究竟是如何解析的。准备工作：编译出glibc2.41产物，下面说的build目录下即为glibc安装后的所有产物。使用patchelf修改main程序的解释器。否则系统中的ld默认是不带符号的。\n$ldd main                                                                                                      linux-vdso.so.1 (0x00007ffce8d33000)        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f084a0a5000)        /lib64/ld-linux-x86-64.so.2 (0x00007f084a2bc000)$patchelf --set-interpreter ./build/elf/ld.so ./main$ldd main                                                                                                     linux-vdso.so.1 (0x00007ffeae9fb000)        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f5ad2d5f000)        ./build/elf/ld.so =&gt; /lib64/ld-linux-x86-64.so.2 (0x00007f5ad2f77000)\n\n准备开始调试main程序。\ngdb main首先设备环境变量，LD_PRELOAD 及 LD_LIBRARY_PATH$set environment LD_LIBRARY_PATH=./build$set environment LD_PRELOAD=./preload.so $b func_glibc_write_data$r\n\n这是c代码，跳到了即将调入write前：\n这是汇编代码，我们单步进去。\n进来后，可以看到plt表里面的write部分的代码如下：准备先jmp write@got.plt表里的存储的地址去执行。\n我们可以看到，此时的 0x555555558008存储的是0x555555555046，也就是说，上面的汇编代码是要去 0x555555555046去执行，也就是上面的 plt表里jmp的下一行代码。看起来感觉是啥也没干，跳了个寂寞。但是假设一下，如果 0x555555558008存储的是另外一个函数的代码段的地址呢？那就直接跳转过去执行了。\n那么跳回plt表的write的第二行，会push一个索引(是重定位表中需要重定位的符号的序号)，然后跳转到0x555555555020去执行。0x555555555020其实就是plt表项的首个结构，主要负责地址解析，跳转到ld的解析函数的。\n这里会先将0x555555557ff0的值push到栈，之前已经push过序号了，这里的这个值是它对应的link_map，然后跳转到0x7ffff7fd9610，这个代码地址在pmap中可以看到，其实是属于ld.so里的函数代码。\njmp后，可以看到，已经跳到ld.so的_dl_runtime_resolve_xsavec函数，这个在glibc中/glibc-2.41/sysdeps/x86_64/dl-trampoline.h是汇编代码实现的，主要逻辑如下所示。可以看出主要是调用了_dl_fixup，它传入了两个参数，%rdi: link_map, %rsi: reloc_index，正是我们调用过来是push栈上的两个值。而这个函数最后有个jmp，这里就是跳转到真实的函数地址处去执行。\n#define _dl_runtime_resolve\t_dl_runtime_resolve_xsavec\t.globl _dl_runtime_resolve\t.hidden _dl_runtime_resolve\t.type _dl_runtime_resolve, @function\t.align 16\tcfi_startproc_dl_runtime_resolve:\t...\t# %rdi: link_map, %rsi: reloc_index\tmov (LOCAL_STORAGE_AREA + 8)(%BASE), %RSI_LP\tmov LOCAL_STORAGE_AREA(%BASE), %RDI_LP\tcall _dl_fixup\t\t# Call resolver.\t...    jmp *%r11       # Jump to function address.\tcfi_endproc\t.size _dl_runtime_resolve, .-_dl_runtime_resolve\n\n\n_dl_fixup 是用来做“延迟绑定（lazy binding）”的核心函数。函数代码太多，这里不再一一展开，只介绍下具体做了哪些事情：\n\n根据重定位表，及传入的重定位序号，拿到要查找哪个符号，及需要重定位回填的地址。\n遍历 link_map 里查符号（真正 dlsym 那套），_dl_lookup_symbol_x函数中做的，每个elf&#x2F;so文件都会有一个link map结构，LD_PRELOAD的so是在其所有依赖的so(比如libc.so)之前加载的，所以它的link map在libc的link map前面，因此查符号时它里面的符号会被优先查找匹配到，从而直接返回了preload so里面的write函数的地址\n计算最终写入地址\n把结果写回 GOT表中(需要重定位回填的地址处)，elf_machine_fixup_plt函数中做的\n返回函数地址，跳过去执行\n函数返回到上层_dl_runtime_resolve_xsavec，去跳转到真正的目标函数处执行\n\nDL_FIXUP_VALUE_TYPEattribute_hidden __attribute((noinline)) DL_ARCH_FIXUP_ATTRIBUTE _dl_fixup(#ifdef ELF_MACHINE_RUNTIME_FIXUP_ARGS    ELF_MACHINE_RUNTIME_FIXUP_ARGS,#endif    struct link_map *l, ElfW(Word) reloc_arg)&#123;    const ElfW(Sym) *const symtab = (const void *)D_PTR(l, l_info[DT_SYMTAB]);    const char *strtab = (const void *)D_PTR(l, l_info[DT_STRTAB]);    const uintptr_t pltgot = (uintptr_t)D_PTR(l, l_info[DT_PLTGOT]);    const PLTREL *const reloc =        (const void *)(D_PTR(l, l_info[DT_JMPREL]) + reloc_offset(pltgot, reloc_arg));    const ElfW(Sym) *sym = &amp;symtab[ELFW(R_SYM)(reloc-&gt;r_info)];    const ElfW(Sym) *refsym = sym;    void *const rel_addr = (void *)(l-&gt;l_addr + reloc-&gt;r_offset);    lookup_t result;    DL_FIXUP_VALUE_TYPE value;    /* Sanity check that we&#x27;re really looking at a PLT relocation.  */    assert(ELFW(R_TYPE)(reloc-&gt;r_info) == ELF_MACHINE_JMP_SLOT);    /* Look up the target symbol.  If the normal lookup rules are not       used don&#x27;t look in the global scope.  */    if (__builtin_expect(ELFW(ST_VISIBILITY)(sym-&gt;st_other), 0) == 0) &#123;        const struct r_found_version *version = NULL;        if (l-&gt;l_info[VERSYMIDX(DT_VERSYM)] != NULL) &#123;            const ElfW(Half) *vernum =                (const void *)D_PTR(l, l_info[VERSYMIDX(DT_VERSYM)]);            ElfW(Half) ndx = vernum[ELFW(R_SYM)(reloc-&gt;r_info)] &amp; 0x7fff;            version = &amp;l-&gt;l_versions[ndx];            if (version-&gt;hash == 0)                version = NULL;        &#125;        /* We need to keep the scope around so do some locking.  This is           not necessary for objects which cannot be unloaded or when           we are not using any threads (yet).  */        int flags = DL_LOOKUP_ADD_DEPENDENCY;        if (!RTLD_SINGLE_THREAD_P) &#123;            THREAD_GSCOPE_SET_FLAG();            flags |= DL_LOOKUP_GSCOPE_LOCK;        &#125;#ifdef RTLD_ENABLE_FOREIGN_CALL        RTLD_ENABLE_FOREIGN_CALL;#endif        result = _dl_lookup_symbol_x(strtab + sym-&gt;st_name, l, &amp;sym, l-&gt;l_scope, version,                                     ELF_RTYPE_CLASS_PLT, flags, NULL);        /* We are done with the global scope.  */        if (!RTLD_SINGLE_THREAD_P)            THREAD_GSCOPE_RESET_FLAG();#ifdef RTLD_FINALIZE_FOREIGN_CALL        RTLD_FINALIZE_FOREIGN_CALL;#endif        /* Currently result contains the base load address (or link map)           of the object that defines sym.  Now add in the symbol           offset.  */        value = DL_FIXUP_MAKE_VALUE(result, SYMBOL_ADDRESS(result, sym, false));    &#125; else &#123;        /* We already found the symbol.  The module (and therefore its load           address) is also known.  */        value = DL_FIXUP_MAKE_VALUE(l, SYMBOL_ADDRESS(l, sym, true));        result = l;    &#125;    /* And now perhaps the relocation addend.  */    value = elf_machine_plt_value(l, reloc, value);    if (sym != NULL &amp;&amp; __builtin_expect(ELFW(ST_TYPE)(sym-&gt;st_info) == STT_GNU_IFUNC, 0))        value = elf_ifunc_invoke(DL_FIXUP_VALUE_ADDR(value));#ifdef SHARED    /* Auditing checkpoint: we have a new binding.  Provide the auditing       libraries the possibility to change the value and tell us whether further       auditing is wanted.       The l_reloc_result is only allocated if there is an audit module which       provides a la_symbind.  */    if (l-&gt;l_reloc_result != NULL) &#123;        /* This is the address in the array where we store the result of previous           relocations.  */        struct reloc_result *reloc_result =            &amp;l-&gt;l_reloc_result[reloc_index(pltgot, reloc_arg, sizeof(PLTREL))];        unsigned int init = atomic_load_acquire(&amp;reloc_result-&gt;init);        if (init == 0) &#123;            _dl_audit_symbind(l, reloc_result, reloc, sym, &amp;value, result, true);            /* Store the result for later runs.  */            if (__glibc_likely(!GLRO(dl_bind_not))) &#123;                reloc_result-&gt;addr = value;                /* Guarantee all previous writes complete before init is                   updated.  See CONCURRENCY NOTES below.  */                atomic_store_release(&amp;reloc_result-&gt;init, 1);            &#125;        &#125; else            value = reloc_result-&gt;addr;    &#125;#endif    /* Finally, fix up the plt itself.  */    if (__glibc_unlikely(GLRO(dl_bind_not)))        return value;    return elf_machine_fixup_plt(l, result, refsym, sym, reloc, rel_addr, value);&#125;\n\n我们在call _dl_fixup之后，再看下write的got.plt表里面的数据，已经被_dl_fixup了修改了，原来是0x555555555046(plt表write的第二条指令的地址)。现在是0x7ffff7fbb109，这个就是我们preload so里面的write函数的地址，因此以后再次调用write时，就不用再次跳到ld去解析，而是直接都跳转到preload so里面的write函数处了。\n五、my poor inline hook在第四节中，我们已经介绍了elf中普通函数失效的原因，以及preload能hook libc.so中函数的原因。那我们还有什么方法去实现hook elf中普通函数吗？目前能想到的，就是直接使用inline hook(我们这里实现的很简陋，什么异常情况都没考虑，只实现了跳转，实际工程上的可能更复杂)。\n我们在preload.so基础上，再写一个preload_inline_hook.so，代码如下。主要的实现思路时：\n\n增加__attribute__((constructor)) static void preload_init(void)，在里面获取 func_myelf_get_raid_status函数的地址\n更改目标函数地址内存页面属性为rwx(一般为r-x，没有w属性)。 \n将目标函数的二进制代码改为 jmp 到 我们的hook函数。\n\n#define _GNU_SOURCE#include &lt;dlfcn.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdbool.h&gt;#include &lt;string.h&gt;#include &lt;stdint.h&gt;#include &lt;errno.h&gt;#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;link.h&gt;/* 保存主程序 load bias */static Elf64_Addr g_main_base = 0;typedef ssize_t (*fn_write_t)(int, const void *, size_t);static fn_write_t g_real_write = NULL;/* ========== write hook ========== */ssize_t write(int fd, const void *buf, size_t count)&#123;    const char msg[] = &quot;This is hook glibc write&#x27;s data message.\\n&quot;;    const char hook_msg[] = &quot;[hook write]\\n&quot;;    if (!g_real_write)        g_real_write = (fn_write_t)dlsym(RTLD_NEXT, &quot;write&quot;);    /* 避免递归：不要在这里 printf */    g_real_write(STDOUT_FILENO, hook_msg, sizeof(hook_msg) - 1);    return g_real_write(fd, msg, strlen(msg));&#125;/* ========== hook ELF 的函数 ========== *//* 注意参数类型和返回值必须一致 */void func_hook_myelf_get_raid_status(bool *exception)&#123;    const char hook_msg[] = &quot;[hook func_myelf_get_raid_status]\\n&quot;;    if (!g_real_write)        g_real_write = (fn_write_t)dlsym(RTLD_NEXT, &quot;write&quot;);    /* 提示下 hook 成功了*/    g_real_write(STDOUT_FILENO, hook_msg, sizeof(hook_msg) - 1);    /* 模拟异常 */    *exception = true;&#125;static void make_page_rwx(void *addr)&#123;    long pagesize = sysconf(_SC_PAGESIZE);    void *page_start = (void *)((uintptr_t)addr &amp; ~(pagesize - 1));    if (mprotect(page_start, pagesize, PROT_READ | PROT_WRITE | PROT_EXEC) != 0)        perror(&quot;mprotect&quot;);&#125;/* 只做简单inline hook，未考虑指令越界、跳回原函数功能 */static void install_hook(void *target_func, void *hook_func)&#123;    if (!target_func || !hook_func)        return;#if defined(__x86_64__) || defined(__amd64__)    #warning &quot;Building for x86_64&quot;    unsigned char jump_code[12] = &#123;0&#125;;    jump_code[0] = 0x48;    jump_code[1] = 0xB8;    *(uint64_t *)&amp;jump_code[2] = (uint64_t)hook_func;    jump_code[10] = 0xFF;    jump_code[11] = 0xE0;#elif defined(__aarch64__)    #warning &quot;Building for arm64&quot;    unsigned char jump_code[16] = &#123;0&#125;;    jump_code[0] = 0x50;    jump_code[1] = 0x00;    jump_code[2] = 0x00;    jump_code[3] = 0x58;    jump_code[4] = 0x00;    jump_code[5] = 0x02;    jump_code[6] = 0x1F;    jump_code[7] = 0xD6;    *(uint64_t *)&amp;jump_code[8] = (uint64_t)hook_func;#else    #warning &quot;unsupported arch&quot;    return;#endif    make_page_rwx(target_func);    memcpy(target_func, jump_code, sizeof(jump_code));&#125;static int phdr_cb(struct dl_phdr_info *info, size_t size, void *data)&#123;    // g_real_write(STDOUT_FILENO, info-&gt;dlpi_name, strlen(info-&gt;dlpi_name));    // g_real_write(STDOUT_FILENO, &quot;\\n&quot;, 1);    /* 这是 ELF/ld.so 约定的一部分，对于 主程序本身，它不是通过 dlopen 打开的，     * 也没有一个 依赖路径名 意义上的 so 名字，因此表现为空串 */    if (info-&gt;dlpi_name == NULL || info-&gt;dlpi_name[0] == &#x27;\\0&#x27;) &#123;        g_main_base = info-&gt;dlpi_addr;    &#125;    return 0;&#125;/* 普通的，在 .dynsym 里找符号 */void *find_symbol_addr(const char *symname)&#123;    return dlsym(NULL, symname);&#125;/* 在 /proc/self/exe 的 .symtab 里找符号 */void *find_symbol_addr2(const char *symname)&#123;    int fd;    struct stat st;    Elf64_Ehdr *eh;    Elf64_Shdr *sh;    const char *shstr;    Elf64_Sym *symtab = NULL;    const char *strtab = NULL;    size_t nsyms = 0;    const char *section_name;    const char *symbol_name;    dl_iterate_phdr(phdr_cb, NULL);    fd = open(&quot;/proc/self/exe&quot;, O_RDONLY);    if (fd &lt; 0) &#123;        g_real_write(STDOUT_FILENO, &quot;open exe failed\\n&quot;, strlen(&quot;open exe failed\\n&quot;));        return NULL;    &#125;    fstat(fd, &amp;st);    void *map = mmap(NULL, st.st_size, PROT_READ, MAP_PRIVATE, fd, 0);    close(fd);    if (map == MAP_FAILED) &#123;        g_real_write(STDOUT_FILENO, &quot;mmap failed\\n&quot;, strlen(&quot;mmap failed\\n&quot;));        return NULL;    &#125;    eh = (Elf64_Ehdr *)map;    sh = (Elf64_Shdr *)((char *)map + eh-&gt;e_shoff);    shstr = (char *)map + sh[eh-&gt;e_shstrndx].sh_offset;    /* 遍历节 */    for (int i = 0; i &lt; eh-&gt;e_shnum; i++) &#123;        section_name = shstr + sh[i].sh_name;        if (!strcmp(section_name, &quot;.symtab&quot;)) &#123;            symtab = (Elf64_Sym *)((char *)map + sh[i].sh_offset);            nsyms = sh[i].sh_size / sizeof(Elf64_Sym);        &#125; else if (!strcmp(section_name, &quot;.strtab&quot;)) &#123;            strtab = (char *)map + sh[i].sh_offset;        &#125;    &#125;    if (!symtab || !strtab) &#123;        munmap(map, st.st_size);        return NULL;    &#125;    /* 遍历symtab上的所有符号信息 */    for (size_t i = 0; i &lt; nsyms; i++) &#123;        /* 不是函数信息时，直接跳过*/        if (ELF64_ST_TYPE(symtab[i].st_info) != STT_FUNC)            continue;        /* .strtab 是 .symtab 的名字的集合 */        symbol_name = strtab + symtab[i].st_name;        if (!strcmp(symbol_name, symname)) &#123;            Elf64_Addr addr = g_main_base + symtab[i].st_value;            munmap(map, st.st_size);            return (void *)addr;        &#125;    &#125;    munmap(map, st.st_size);    return NULL;&#125;/* strip后，不带 .symtab 的情况 */void *find_symbol_addr3(const char *symname)&#123;    /* 暂不考虑 */    return NULL;&#125;/* clang-format off *//* 一般低版本gcc，很多普通全局符号会带进 .dynsym，但是高版本gcc普通全局符号不再带进 .dynsym， * 因此使用 dlsym 查不到，需要自己解析elf查地址， * 但是如果elf 在Makefile中 显式使用了 -rdynamic，那全局符号也会进 .dynsym，那可以直接dlsym找到 * 但是我们做preload so不能假定elf是否指定了该参数， * 如果要查找的符号不能使用dlsym找到，那就有两种方式： * 1. 未strip过的，可以直接解析elf文件，在 .symtab 里查找符号地址，然后加上load_bias 就可以定位到其地址 * 2. strip过的，没有 .symtab 节， *//* clang-format on */static void *supper_get_addr(const char *symname)&#123;    void *addr;    const char *msg;    msg = &quot;find_symbol_addr find sym\\n&quot;;    addr = find_symbol_addr(symname);    if (addr) &#123;        g_real_write(STDOUT_FILENO, msg,                     strlen(msg));        return addr;    &#125;    msg = &quot;find_symbol_addr2 find sym\\n&quot;;    addr = find_symbol_addr2(symname);    if (addr) &#123;        g_real_write(STDOUT_FILENO, msg,                     strlen(msg));        return addr;    &#125;    msg = &quot;find_symbol_addr3 find sym\\n&quot;;    addr = find_symbol_addr3(symname);    if (addr) &#123;        g_real_write(STDOUT_FILENO, msg,                     strlen(msg));        return addr;    &#125;    return NULL;&#125;__attribute__((constructor)) static void preload_init(void)&#123;    const char dlerr_msg[] = &quot;[preload] dlsym func_myelf_get_raid_status failed\\n&quot;;    if (!g_real_write)        g_real_write = (fn_write_t)dlsym(RTLD_NEXT, &quot;write&quot;);    void *addr = supper_get_addr(&quot;func_myelf_get_raid_status&quot;);    if (addr)        install_hook(addr, func_hook_myelf_get_raid_status);    else        g_real_write(STDOUT_FILENO, dlerr_msg, sizeof(dlerr_msg) - 1);&#125;__attribute__((destructor)) static void preload_fini(void) &#123;&#125;\n\n\n我们首先gdb main，设置环境变量如下：\nset environment LD_PRELOAD=./preload_inline_hook.so\n\n因为我们这里的install_hook是在 constructor 中调用的，而它是在main函数执行之前就已经执行完了，所以如果我们直接挂main函数，这时去看，指令早就替换完，看不到实际的替换效果。\n__attribute__((constructor)) static void preload_init(void)&#123;    const char dlerr_msg[] = &quot;[preload] dlsym func_myelf_get_raid_status failed\\n&quot;;    if (!g_real_write)        g_real_write = (fn_write_t)dlsym(RTLD_NEXT, &quot;write&quot;);    void *addr = supper_get_addr(&quot;func_myelf_get_raid_status&quot;);    if (addr)        install_hook(addr, func_hook_myelf_get_raid_status);    else        g_real_write(STDOUT_FILENO, dlerr_msg, sizeof(dlerr_msg) - 1);&#125;\n\n所以我们在gdb中下断点： \nb preload_initb mainr\n\n此时程序会执行到 preload_init 这里， 此时查看 func_myelf_get_raid_status 的汇编代码。可以看到，主要包括函数开栈过程、调用printf函数、给传入的rdi参数赋值为0。\n(gdb) disassemble /r func_myelf_get_raid_statusDump of assembler code for function func_myelf_get_raid_status:   0x00005555555551a9 &lt;+0&gt;:     55                      push   %rbp   0x00005555555551aa &lt;+1&gt;:     48 89 e5                mov    %rsp,%rbp   0x00005555555551ad &lt;+4&gt;:     48 83 ec 10             sub    $0x10,%rsp   0x00005555555551b1 &lt;+8&gt;:     48 89 7d f8             mov    %rdi,-0x8(%rbp)   0x00005555555551b5 &lt;+12&gt;:    48 8d 05 4c 0e 00 00    lea    0xe4c(%rip),%rax        # 0x555555556008   0x00005555555551bc &lt;+19&gt;:    48 89 c7                mov    %rax,%rdi   0x00005555555551bf &lt;+22&gt;:    e8 6c fe ff ff          call   0x555555555030 &lt;puts@plt&gt;   0x00005555555551c4 &lt;+27&gt;:    48 8b 45 f8             mov    -0x8(%rbp),%rax   0x00005555555551c8 &lt;+31&gt;:    c6 00 00                movb   $0x0,(%rax)   0x00005555555551cb &lt;+34&gt;:    90                      nop   0x00005555555551cc &lt;+35&gt;:    c9                      leave   0x00005555555551cd &lt;+36&gt;:    c3                      retEnd of assembler dump.\n\n\n然后我们在gdb中，再次执行c，此时程序会执行到main函数处，然后再次查看 func_myelf_get_raid_status 的汇编代码，可以发现，我们已经将原始函数的前12字节的机器码 55 48 89 e5 48 83 ec 10 48 89 7d f8 替换为了 48 b8 cc b2 fb f7 ff 7f 00 00 ff e0，也就是 将hook函数的地址，存到rax里，然后使用jmp跳转到hook函数执行，从而实现了简易版的 hook elf中的普通函数。 \n(gdb) disassemble /r func_myelf_get_raid_statusDump of assembler code for function func_myelf_get_raid_status:   0x00005555555551a9 &lt;+0&gt;:     48 b8 cc b2 fb f7 ff 7f 00 00   movabs $0x7ffff7fbb2cc,%rax   0x00005555555551b3 &lt;+10&gt;:    ff e0                   jmp    *%rax   0x00005555555551b5 &lt;+12&gt;:    48 8d 05 4c 0e 00 00    lea    0xe4c(%rip),%rax        # 0x555555556008   0x00005555555551bc &lt;+19&gt;:    48 89 c7                mov    %rax,%rdi   0x00005555555551bf &lt;+22&gt;:    e8 6c fe ff ff          call   0x555555555030 &lt;puts@plt&gt;   0x00005555555551c4 &lt;+27&gt;:    48 8b 45 f8             mov    -0x8(%rbp),%rax   0x00005555555551c8 &lt;+31&gt;:    c6 00 00                movb   $0x0,(%rax)   0x00005555555551cb &lt;+34&gt;:    90                      nop   0x00005555555551cc &lt;+35&gt;:    c9                      leave   0x00005555555551cd &lt;+36&gt;:    c3                      retEnd of assembler dump.\n\n我们可以看到 0x7ffff7fbb2cc 其实就是我们的hook函数的代码段的地址，从而实现hook。\n(gdb) disassemble /r func_hook_myelf_get_raid_statusDump of assembler code for function func_hook_myelf_get_raid_status:   0x00007ffff7fbb2cc &lt;+0&gt;:     55                      push   %rbp   0x00007ffff7fbb2cd &lt;+1&gt;:     48 89 e5                mov    %rsp,%rbp   0x00007ffff7fbb2d0 &lt;+4&gt;:     48 83 ec 40             sub    $0x40,%rsp   0x00007ffff7fbb2d4 &lt;+8&gt;:     48 89 7d c8             mov    %rdi,-0x38(%rbp)   0x00007ffff7fbb2d8 &lt;+12&gt;:    48 b8 5b 68 6f 6f 6b 20 66 75   movabs $0x7566206b6f6f685b,%rax   0x00007ffff7fbb2e2 &lt;+22&gt;:    48 ba 6e 63 5f 6d 79 65 6c 66   movabs $0x666c65796d5f636e,%rdx   0x00007ffff7fbb2ec &lt;+32&gt;:    48 89 45 d0             mov    %rax,-0x30(%rbp)   0x00007ffff7fbb2f0 &lt;+36&gt;:    48 89 55 d8             mov    %rdx,-0x28(%rbp)   0x00007ffff7fbb2f4 &lt;+40&gt;:    48 b8 5f 67 65 74 5f 72 61 69   movabs $0x6961725f7465675f,%rax   0x00007ffff7fbb2fe &lt;+50&gt;:    48 ba 64 5f 73 74 61 74 75 73   movabs $0x7375746174735f64,%rdx   0x00007ffff7fbb308 &lt;+60&gt;:    48 89 45 e0             mov    %rax,-0x20(%rbp)   0x00007ffff7fbb30c &lt;+64&gt;:    48 89 55 e8             mov    %rdx,-0x18(%rbp)   0x00007ffff7fbb310 &lt;+68&gt;:    c7 45 ef 73 5d 0a 00    movl   $0xa5d73,-0x11(%rbp)   0x00007ffff7fbb317 &lt;+75&gt;:    48 8b 05 72 2d 00 00    mov    0x2d72(%rip),%rax        # 0x7ffff7fbe090 &lt;g_real_write&gt;   0x00007ffff7fbb31e &lt;+82&gt;:    48 85 c0                test   %rax,%rax   0x00007ffff7fbb321 &lt;+85&gt;:    75 1d                   jne    0x7ffff7fbb340 &lt;func_hook_myelf_get_raid_status+116&gt;   0x00007ffff7fbb323 &lt;+87&gt;:    48 8d 05 d6 0c 00 00    lea    0xcd6(%rip),%rax        # 0x7ffff7fbc000   0x00007ffff7fbb32a &lt;+94&gt;:    48 89 c6                mov    %rax,%rsi   0x00007ffff7fbb32d &lt;+97&gt;:    48 c7 c7 ff ff ff ff    mov    $0xffffffffffffffff,%rdi   0x00007ffff7fbb334 &lt;+104&gt;:   e8 c7 fd ff ff          call   0x7ffff7fbb100 &lt;dlsym@plt&gt;   0x00007ffff7fbb339 &lt;+109&gt;:   48 89 05 50 2d 00 00    mov    %rax,0x2d50(%rip)        # 0x7ffff7fbe090 &lt;g_real_write&gt;   0x00007ffff7fbb340 &lt;+116&gt;:   48 8b 0d 49 2d 00 00    mov    0x2d49(%rip),%rcx        # 0x7ffff7fbe090 &lt;g_real_write&gt;   ...\n\n\n效果基本就是上面所示，我们看下在 preload_init 里是怎么做的。首先是调用了 supper_get_addr，该函数主要就是获取 func_myelf_get_raid_status 的所在代码段的具体地址。\n__attribute__((constructor)) static void preload_init(void)&#123;    const char dlerr_msg[] = &quot;[preload] dlsym func_myelf_get_raid_status failed\\n&quot;;    if (!g_real_write)        g_real_write = (fn_write_t)dlsym(RTLD_NEXT, &quot;write&quot;);    void *addr = supper_get_addr(&quot;func_myelf_get_raid_status&quot;);    ...&#125;\n\n/* clang-format off *//* 一般低版本gcc，很多普通全局符号会带进 .dynsym，但是高版本gcc普通全局符号不再带进 .dynsym， * 因此使用 dlsym 查不到，需要自己解析elf查地址， * 但是如果elf 在Makefile中 显式使用了 -rdynamic，那全局符号也会进 .dynsym，那可以直接dlsym找到 * 但是我们做preload so不能假定elf是否指定了该参数， * 如果要查找的符号不能使用dlsym找到，那就有两种方式： * 1. 未strip过的，可以直接解析elf文件，在 .symtab 里查找符号地址，然后加上load_bias 就可以定位到其地址 * 2. strip过的，没有 .symtab 节， *//* clang-format on */static void *supper_get_addr(const char *symname)&#123;    void *addr;    const char *msg;    msg = &quot;find_symbol_addr find sym\\n&quot;;    addr = find_symbol_addr(symname);    if (addr) &#123;        g_real_write(STDOUT_FILENO, msg,                     strlen(msg));        return addr;    &#125;    msg = &quot;find_symbol_addr2 find sym\\n&quot;;    addr = find_symbol_addr2(symname);    if (addr) &#123;        g_real_write(STDOUT_FILENO, msg,                     strlen(msg));        return addr;    &#125;    msg = &quot;find_symbol_addr3 find sym\\n&quot;;    addr = find_symbol_addr3(symname);    if (addr) &#123;        g_real_write(STDOUT_FILENO, msg,                     strlen(msg));        return addr;    &#125;    return NULL;&#125;\n\nfind_symbol_addr 就是直接使用 dlsym，它会在 .dynsym 节里找符号信息。\n/* 普通的，在 .dynsym 里找符号 */void *find_symbol_addr(const char *symname)&#123;    return dlsym(NULL, symname);&#125;\n\n但是高版本编译时，普通非导出的全局符号不放进 .dynsym 里，所以直接使用 dlsym 可能找不到函数的地址。因此可以尝试从elf文件的 .symtab 里找符号(前提是程序没有strip，还保留着 .symtab 节)。可以看到，在 find_symbol_addr2 里：\n\n首先是通过dl_iterate_phdr，来传入一个回调函数 phdr_cb，在phdr_cb中，确定elf文件映射到进程虚拟地址空间的基地址。\n然后是打开当前进程对应的程序文件，mmap到内存里，根据elf头，确定节头的偏移。然后遍历节头，查找symtab 和 strtab的偏移。\n遍历symtab上的所有符号信息，与我们传入的符号信息做匹配。匹配成功后，它就是这个符号相对于程序基址的偏移。我们再让其加上真正的在进程虚拟地址空间的基址，就拿到了该符号在进程虚拟地址空间地址。\n\n/* 在 /proc/self/exe 的 .symtab 里找符号 */void *find_symbol_addr2(const char *symname)&#123;    int fd;    struct stat st;    Elf64_Ehdr *eh;    Elf64_Shdr *sh;    const char *shstr;    Elf64_Sym *symtab = NULL;    const char *strtab = NULL;    size_t nsyms = 0;    const char *section_name;    const char *symbol_name;    dl_iterate_phdr(phdr_cb, NULL);    fd = open(&quot;/proc/self/exe&quot;, O_RDONLY);    if (fd &lt; 0) &#123;        g_real_write(STDOUT_FILENO, &quot;open exe failed\\n&quot;, strlen(&quot;open exe failed\\n&quot;));        return NULL;    &#125;    fstat(fd, &amp;st);    void *map = mmap(NULL, st.st_size, PROT_READ, MAP_PRIVATE, fd, 0);    close(fd);    if (map == MAP_FAILED) &#123;        g_real_write(STDOUT_FILENO, &quot;mmap failed\\n&quot;, strlen(&quot;mmap failed\\n&quot;));        return NULL;    &#125;    eh = (Elf64_Ehdr *)map;    sh = (Elf64_Shdr *)((char *)map + eh-&gt;e_shoff);    shstr = (char *)map + sh[eh-&gt;e_shstrndx].sh_offset;    /* 遍历节 */    for (int i = 0; i &lt; eh-&gt;e_shnum; i++) &#123;        section_name = shstr + sh[i].sh_name;        if (!strcmp(section_name, &quot;.symtab&quot;)) &#123;            symtab = (Elf64_Sym *)((char *)map + sh[i].sh_offset);            nsyms = sh[i].sh_size / sizeof(Elf64_Sym);        &#125; else if (!strcmp(section_name, &quot;.strtab&quot;)) &#123;            strtab = (char *)map + sh[i].sh_offset;        &#125;    &#125;    if (!symtab || !strtab) &#123;        munmap(map, st.st_size);        return NULL;    &#125;    /* 遍历symtab上的所有符号信息 */    for (size_t i = 0; i &lt; nsyms; i++) &#123;        /* 不是函数信息时，直接跳过*/        if (ELF64_ST_TYPE(symtab[i].st_info) != STT_FUNC)            continue;        /* .strtab 是 .symtab 的名字的集合 */        symbol_name = strtab + symtab[i].st_name;        if (!strcmp(symbol_name, symname)) &#123;            Elf64_Addr addr = g_main_base + symtab[i].st_value;            munmap(map, st.st_size);            return (void *)addr;        &#125;    &#125;    munmap(map, st.st_size);    return NULL;&#125;\n\n使用phdr_cb，确定elf文件的基地址，一般就是pmap -x pid，看到的首个地址。\nstatic int phdr_cb(struct dl_phdr_info *info, size_t size, void *data)&#123;    // g_real_write(STDOUT_FILENO, info-&gt;dlpi_name, strlen(info-&gt;dlpi_name));    // g_real_write(STDOUT_FILENO, &quot;\\n&quot;, 1);    /* 这是 ELF/ld.so 约定的一部分，对于 主程序本身，它不是通过 dlopen 打开的，     * 也没有一个 依赖路径名 意义上的 so 名字，因此表现为空串 */    if (info-&gt;dlpi_name == NULL || info-&gt;dlpi_name[0] == &#x27;\\0&#x27;) &#123;        g_main_base = info-&gt;dlpi_addr;    &#125;    return 0;&#125;\n\nstrip后，不带 .symtab 的情况，这种情况比较复杂，暂未考虑。\n/* strip后，不带 .symtab 的情况 */void *find_symbol_addr3(const char *symname)&#123;    /* 暂不考虑 */    return NULL;&#125;\n\n\n查找到目标函数的地址后，就可以调用 install_hook，完成函数地址入口点修改。\n__attribute__((constructor)) static void preload_init(void)&#123;    const char dlerr_msg[] = &quot;[preload] dlsym func_myelf_get_raid_status failed\\n&quot;;    if (!g_real_write)        g_real_write = (fn_write_t)dlsym(RTLD_NEXT, &quot;write&quot;);    void *addr = supper_get_addr(&quot;func_myelf_get_raid_status&quot;);    if (addr)        install_hook(addr, func_hook_myelf_get_raid_status);    else        g_real_write(STDOUT_FILENO, dlerr_msg, sizeof(dlerr_msg) - 1);&#125;\n\n在 install_hook中，只做了跳走的逻辑，没有做是否跳回原函数的逻辑。目前只考虑了 x86_64 和 arm64 的情况处理。主要做的就是：\n\n确定当前架构，根据hook函数地址，构造jump_code\n调用 make_page_rwx，将代码段地址改为rwx，因为默认代码段是不可写的。\n将jump_code，写入到目标函数入口点。\n\n/* 只做简单inline hook，未考虑指令越界、跳回原函数功能 */static void install_hook(void *target_func, void *hook_func)&#123;    if (!target_func || !hook_func)        return;#if defined(__x86_64__) || defined(__amd64__)    #warning &quot;Building for x86_64&quot;    unsigned char jump_code[12] = &#123;0&#125;;    jump_code[0] = 0x48;    jump_code[1] = 0xB8;    *(uint64_t *)&amp;jump_code[2] = (uint64_t)hook_func;    jump_code[10] = 0xFF;    jump_code[11] = 0xE0;#elif defined(__aarch64__)    #warning &quot;Building for arm64&quot;    unsigned char jump_code[16] = &#123;0&#125;;    jump_code[0] = 0x50;    jump_code[1] = 0x00;    jump_code[2] = 0x00;    jump_code[3] = 0x58;    jump_code[4] = 0x00;    jump_code[5] = 0x02;    jump_code[6] = 0x1F;    jump_code[7] = 0xD6;    *(uint64_t *)&amp;jump_code[8] = (uint64_t)hook_func;#else    #warning &quot;unsupported arch&quot;    return;#endif    make_page_rwx(target_func);    memcpy(target_func, jump_code, sizeof(jump_code));&#125;\n\nmake_page_rwx 主要是获取addr所在页的起始地址，调用 mprotect 改变该页的属性为可读可写可执行。\nstatic void make_page_rwx(void *addr)&#123;    long pagesize = sysconf(_SC_PAGESIZE);    void *page_start = (void *)((uintptr_t)addr &amp; ~(pagesize - 1));    if (mprotect(page_start, pagesize, PROT_READ | PROT_WRITE | PROT_EXEC) != 0)        perror(&quot;mprotect&quot;);&#125;\n\n这样就实现了hook普通函数，可以我们的hook函数中，决定返回raid卡状态是否异常，而避免了去真正的制造异常的raid卡。\n\n效果如下：\n\n未preload\npreload 普通版本\npreload poor inline hook版本\n\n","categories":["linux6.6内核"],"tags":["hook","preload(LD_PRELOAD)","poor_inline_hook"]},{"title":"socket系统调用","url":"/2025/12/13/socket%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","content":"glibc socket函数介绍我们使用的socket函数，原型如下。头文件位置为：&#x2F;usr&#x2F;include&#x2F;x86_64-linux-gnu&#x2F;sys&#x2F;socket.h\nextern int socket (int __domain, int __type, int __protocol) __THROW;\n\n\n\n\n参数\n介绍\n\n\n\n__domain\n指定一个通讯域名；选择的协议将会用于通讯。如 AF_INET、AF_NETLINK、AF_PACKET、AF_UNIX\n\n\n__type\n套接字通过 type, 参数来确定通信语义。如：SOCK_STREAM、SOCK_DGRAM、SOCK_RAW\n\n\n__protocol\n指定一个协议用于套接字。如 IPPROTO_TCP、IPPROTO_UDP、IPPROTO_ICMP、IPPROTO_IP\n\n\n\n而socket函数是glibc中提供的函数，我们看下glibc中的socket函数实现。代码位置在：glibc-2.41&#x2F;sysdeps&#x2F;unix&#x2F;sysv&#x2F;linux&#x2F;socket.c\n#include &lt;sys/socket.h&gt;#include &lt;socketcall.h&gt;int__socket (int fd, int type, int domain)&#123;#ifdef __ASSUME_SOCKET_SYSCALL  return INLINE_SYSCALL_CALL (socket, fd, type, domain);#else  return SOCKETCALL (socket, fd, type, domain);#endif&#125;libc_hidden_def (__socket)weak_alias (__socket, socket)\n\n可以看到，glibc中的socket函数几乎什么都没做，可以理解为仅仅是内核socket系统调用(__do_sys_socket)的一个封装，中间的步骤在syscall调用流程分析中有做展开讲解，这里不再赘述。\nsocket系统调用我们首先来看下socket系统调用的入口。可以看到__do_sys_socket，什么都没做，只是再次调用了__sys_socket。\n/* __do_sys_socket */SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n从__sys_socket中可以看到，主要调用了__sys_socket_create与sock_map_fd函数。有一些额外的NONBLOCK兼容处理。__sys_socket_create就是申请了一个socket_alloc结构，返回其中的socket结构。然后调用sock_map_fd将socket映射出一个fd。\n/* 只由 __x64_sys_socket 、 __x64_sys_socketcall 调用  * 负责根据传入的三个参数，创建出 socket_alloc 结构，并映射出fd返给外围 */int __sys_socket(int family, int type, int protocol)&#123;\t/* 用于指向申请的socket_alloc中的socket */\tstruct socket *sock;\tint flags;\t/* 申请 socket_alloc 结构，并初始化，但是注意这里返回的只是其中的socket */\tsock = __sys_socket_create(family, type,\t\t\t\t   update_socket_protocol(family, type, protocol));\tif (IS_ERR(sock))\t\treturn PTR_ERR(sock);\t/* 不关心 低4bit sock的type，取出其高位数据，\t * 高位看起来应该只能是 SOCK_NONBLOCK 或 SOCK_CLOEXEC */\tflags = type &amp; ~SOCK_TYPE_MASK;\tif (SOCK_NONBLOCK != O_NONBLOCK &amp;&amp; (flags &amp; SOCK_NONBLOCK)) &#123;\t\t/* 把 socket 层的非阻塞标志 统一转换成 文件描述符层的非阻塞标志 *\t\t * 将 SOCK_NONBLOCK 清位之后，再将 O_NONBLOCK 置位 */\t\tflags = (flags &amp; ~SOCK_NONBLOCK) | O_NONBLOCK;\t&#125;\t/* 将 socket 映射出一个对应的文件描述符fd，返给上层应用 */\treturn sock_map_fd(sock, flags &amp; (O_CLOEXEC | O_NONBLOCK));&#125;\n\n\n我们先看__sys_socket_create做了什么。可以看到，只是做了下编译器一致性检查，及标志位校验等，从type中提取出真正的类型(高位有可能有其它标志置位了)，然后调用sock_create。\n/* 由 __sys_socket 调用  * 负责创建出 socket_alloc 结构 */static struct socket *__sys_socket_create(int family, int type, int protocol)&#123;\tstruct socket *sock;\tint retval;\t/* Check the SOCK_* constants for consistency.  \t * 编译器一致性检查 */\tBUILD_BUG_ON(SOCK_CLOEXEC != O_CLOEXEC);\tBUILD_BUG_ON((SOCK_MAX | SOCK_TYPE_MASK) != SOCK_TYPE_MASK);\tBUILD_BUG_ON(SOCK_CLOEXEC &amp; SOCK_TYPE_MASK);\tBUILD_BUG_ON(SOCK_NONBLOCK &amp; SOCK_TYPE_MASK);\t/* 标志位校验 */\tif ((type &amp; ~SOCK_TYPE_MASK) &amp; ~(SOCK_CLOEXEC | SOCK_NONBLOCK))\t\treturn ERR_PTR(-EINVAL);\t/* 提取真正的类型，我们只关心它的低位的4bit */\ttype &amp;= SOCK_TYPE_MASK;\tretval = sock_create(family, type, protocol, &amp;sock);\tif (retval &lt; 0)\t\treturn ERR_PTR(retval);\treturn sock;&#125;\n\n\n这里sock_create仅是封装了下__sock_create。__sock_create中有对family和type的合法性检查，有对过时的 PF_INET + SOCK_PACKET 参数组合 转换为 现代支持的 PF_PACKET 协议族。有过lsm相关的钩子点。核心的是sock_alloc、及pf-&gt;create(对于AF_INET，就是inet_create)。这里面将申请socket_alloc结构，并且初始化。还会根据family、type申请对应的核心的sock结构，比如tcp_sock、udp_sock。\nint sock_create(int family, int type, int protocol, struct socket **res)&#123;\treturn __sock_create(current-&gt;nsproxy-&gt;net_ns, family, type, protocol, res, 0);&#125;int __sock_create(struct net *net, int family, int type, int protocol,\t\t\t struct socket **res, int kern)&#123;\tint err;\tstruct socket *sock;\tconst struct net_proto_family *pf;\t/*\t *      Check protocol is in range\t *      合法性检查\t */\tif (family &lt; 0 || family &gt;= NPROTO)\t\treturn -EAFNOSUPPORT;\tif (type &lt; 0 || type &gt;= SOCK_MAX)\t\treturn -EINVAL;\t/* Compatibility.\t   This uglymoron is moved from INET layer to here to avoid deadlock in module load.\t   过时的 PF_INET + SOCK_PACKET 参数组合 转换为 现代支持的 PF_PACKET 协议族\t */\tif (family == PF_INET &amp;&amp; type == SOCK_PACKET) &#123;\t\tpr_info_once(&quot;%s uses obsolete (PF_INET,SOCK_PACKET)\\n&quot;,\t\t\t     current-&gt;comm);\t\tfamily = PF_PACKET;\t&#125;\t/* lsm socket_create hook点 */\terr = security_socket_create(family, type, protocol, kern);\tif (err)\t\treturn err;\t/*\t *\tAllocate the socket and allow the family to set things up. if\t *\tthe protocol is 0, the family is instructed to select an appropriate\t *\tdefault.\t *  申请 socket_alloc 结构，返回的是其中的 socket 成员地址，\t *  这里 socket-&gt;sk 还没初始化，是在底下的 pf-&gt;create 里面创建的\t */\tsock = sock_alloc();\tif (!sock) &#123;\t\tnet_warn_ratelimited(&quot;socket: no more sockets\\n&quot;);\t\treturn -ENFILE;\t/* Not exactly a match, but its the\t\t\t\t   closest posix thing */\t&#125;\t/* 这里的type是用户创建socket传入的第二参数的type */\tsock-&gt;type = type;#ifdef CONFIG_MODULES\t/* Attempt to load a protocol module if the find failed.\t *\t * 12/09/1996 Marcin: But! this makes REALLY only sense, if the user\t * requested real, full-featured networking support upon configuration.\t * Otherwise module support will break!\t * net_families 存储的是 AF_INET 对应的 net_proto_family\t * 是在 inet_init 中，通过 sock_register 注册的 inet_family_ops\t */\tif (rcu_access_pointer(net_families[family]) == NULL)\t\trequest_module(&quot;net-pf-%d&quot;, family);#endif\trcu_read_lock();\t/* 从sock_register数组中找到一个元素pf，这个pf中有一个create()回调函数，\t * 这个回调函数就是family类型(such as AF_INET)需要的create函数。 */\tpf = rcu_dereference(net_families[family]);\terr = -EAFNOSUPPORT;\tif (!pf)\t\tgoto out_release;\t/*\t * We will call the -&gt;create function, that possibly is in a loadable\t * module, so we have to bump that loadable module refcnt first.\t * 增加引用计数，有些family可能是以模块方式加载的，比如 nf_conntrack\t */\tif (!try_module_get(pf-&gt;owner))\t\tgoto out_release;\t/* Now protected by module ref count */\trcu_read_unlock();\t/* inet_create 、 inet6_create \t * 如果用户指定的family类型是AF_INET, 那这个函数就是调用的inet_create，\t * 这里面将真正的创建 socket-&gt;sk，并且给 socket 的部分成员初始化 */\terr = pf-&gt;create(net, sock, protocol, kern);\tif (err &lt; 0)\t\tgoto out_module_put;\t/*\t * Now to bump the refcnt of the [loadable] module that owns this\t * socket at sock_release time we decrement its refcnt.\t */\tif (!try_module_get(sock-&gt;ops-&gt;owner))\t\tgoto out_module_busy;\t/*\t * Now that we&#x27;re done with the -&gt;create function, the [loadable]\t * module can have its refcnt decremented\t * 减引用计数\t */\tmodule_put(pf-&gt;owner);\t/* lsm socket_post_create hook点 */\terr = security_socket_post_create(sock, family, type, protocol, kern);\tif (err)\t\tgoto out_sock_release;\t*res = sock;\treturn 0;out_module_busy:\terr = -EAFNOSUPPORT;out_module_put:\tsock-&gt;ops = NULL;\tmodule_put(pf-&gt;owner);out_sock_release:\tsock_release(sock);\treturn err;out_release:\trcu_read_unlock();\tgoto out_sock_release;&#125;\n\n\nsock_alloc函数就是申请了一个socket_alloc的结构，只是返回的是其中的socket地址。socket和inode是相邻的，可以通过SOCKET_I、SOCK_INODE之类的函数互相找到彼此。\nstruct socket *sock_alloc(void)&#123;\tstruct inode *inode;\tstruct socket *sock;\t/* 调用socket文件系统的超级块的ops申请一个inode，申请的其实是 socket_alloc 结构 */\tinode = new_inode_pseudo(sock_mnt-&gt;mnt_sb);\tif (!inode)\t\treturn NULL;\t/* 通过 container_of 取与 inode 相邻的 socket 地址 */\tsock = SOCKET_I(inode);\tinode-&gt;i_ino = get_next_ino(); /* 分配唯一的inode编号 */\tinode-&gt;i_mode = S_IFSOCK | S_IRWXUGO; /* 文件类型 */\tinode-&gt;i_uid = current_fsuid();\tinode-&gt;i_gid = current_fsgid();\tinode-&gt;i_op = &amp;sockfs_inode_ops; /* 绑定ops */\treturn sock;&#125;struct inode *new_inode_pseudo(struct super_block *sb)&#123;\tstruct inode *inode = alloc_inode(sb);\tif (inode) &#123;\t\tspin_lock(&amp;inode-&gt;i_lock);\t\tinode-&gt;i_state = 0;\t\tspin_unlock(&amp;inode-&gt;i_lock);\t&#125;\treturn inode;&#125;/* 由 new_inode_pseudo 调用 */static struct inode *alloc_inode(struct super_block *sb)&#123;\tconst struct super_operations *ops = sb-&gt;s_op;\tstruct inode *inode;\t/* 对于socket来说，调用的是 sockfs_ops 的 sock_alloc_inode\t * sock_alloc_inode 会创建真正的 socket_alloc 结构 */\tif (ops-&gt;alloc_inode)\t\tinode = ops-&gt;alloc_inode(sb);\telse\t\tinode = alloc_inode_sb(sb, inode_cachep, GFP_KERNEL);\tif (!inode)\t\treturn NULL;\tif (unlikely(inode_init_always(sb, inode))) &#123;\t\tif (ops-&gt;destroy_inode) &#123;\t\t\tops-&gt;destroy_inode(inode);\t\t\tif (!ops-&gt;free_inode)\t\t\t\treturn NULL;\t\t&#125;\t\tinode-&gt;free_inode = ops-&gt;free_inode;\t\ti_callback(&amp;inode-&gt;i_rcu);\t\treturn NULL;\t&#125;\treturn inode;&#125;/* 由 alloc_inode 调用  * 申请socket_alloc结构，并初始化成员 */static struct inode *sock_alloc_inode(struct super_block *sb)&#123;\tstruct socket_alloc *ei;\tei = alloc_inode_sb(sb, sock_inode_cachep, GFP_KERNEL);\tif (!ei)\t\treturn NULL;\t/* 初始化等待队列 */\tinit_waitqueue_head(&amp;ei-&gt;socket.wq.wait);\tei-&gt;socket.wq.fasync_list = NULL;\tei-&gt;socket.wq.flags = 0;\tei-&gt;socket.state = SS_UNCONNECTED;\tei-&gt;socket.flags = 0;\tei-&gt;socket.ops = NULL;\tei-&gt;socket.sk = NULL;\tei-&gt;socket.file = NULL;\treturn &amp;ei-&gt;vfs_inode;&#125;\n\n\nsocket_alloc结构、SOCKET_I、SOCK_INODE 如下所示。使用container_of来找到彼此。\n/* sock_alloc_inode 申请并初始化 */struct socket_alloc &#123;\tstruct socket socket;\tstruct inode vfs_inode;&#125;;static inline struct socket *SOCKET_I(struct inode *inode)&#123;\treturn &amp;container_of(inode, struct socket_alloc, vfs_inode)-&gt;socket;&#125;static inline struct inode *SOCK_INODE(struct socket *socket)&#123;\treturn &amp;container_of(socket, struct socket_alloc, socket)-&gt;vfs_inode;&#125;\n\n\nsocket结构如下所示。其中最为核心的是sock结构。对于tcp来说，它其实指向的是tcp_sock，对于udp来说，指向的是udp_sock。pf-&gt;create就是根据type和protocol，来创建对应的sock结构。\nstruct socket &#123;\t/* such as SS_UNCONNECTED  、 SS_CONNECTED */\tsocket_state\t\tstate;\t\t/* socket()的第二个参数， __sock_create 中赋值， SOCK_STREAM 、 SOCK_DGRAM 、 SOCK_RAW 等*/\tshort\t\t\ttype;\t\t\tunsigned long\t\tflags;\t/* sock_alloc_file 中申请、初始化，并赋值 */\tstruct file\t\t*file;\t\t\t/* inet_create 中申请，申请的大小为 prot-&gt;obj_size\t * sock_init_data_uid 中赋值，指向type对应申请出来的sock结构 */\tstruct sock\t\t*sk;\t\t\t/* Might change with IPV6_ADDRFORM or MPTCP. \t * 套接口层操作集合, such as inet_stream_ops 、 inet_dgram_ops、 inet_sockraw_ops */\tconst struct proto_ops\t*ops;\tstruct socket_wq\twq;&#125;;\n\n\ninet_create是socket系统调用中的核心函数，它将创建并初始化socket结构中的最核心的、最关键的sock结构。是根据传入的type，从inetsw链表数组上，选取type对应的链表，再匹配最合适的协议，找到它对应的prot结构。通过prot-&gt;obj_size 来决定申请 sock 的内存大小。\n/* *\tCreate an inet socket. *  由 __sock_create 调用， *  这里主要是做 socket-&gt;sk 的创建，及 socket 的部分成员的初始化 */static int inet_create(struct net *net, struct socket *sock, int protocol,\t\t       int kern)&#123;\tstruct sock *sk;\tstruct inet_protosw *answer;\tstruct inet_sock *inet;\tstruct proto *answer_prot;\tunsigned char answer_flags;\tint try_loading_module = 0;\tint err;\t/* 协议有效性校验 */\tif (protocol &lt; 0 || protocol &gt;= IPPROTO_MAX)\t\treturn -EINVAL;\t/* 正在创建socket，因此此时状态还是未连接 */\tsock-&gt;state = SS_UNCONNECTED;\t/* Look for the requested type/protocol pair. */lookup_protocol:\terr = -ESOCKTNOSUPPORT;\trcu_read_lock();\t/* 其实就是把 inetsw_array 中的成员，根据 type 挂在了 inetsw 的链表上 */\tlist_for_each_entry_rcu(answer, &amp;inetsw[sock-&gt;type], list) &#123;\t\terr = 0;\t\t/* Check the non-wild match. */\t\tif (protocol == answer-&gt;protocol) &#123;\t\t\tif (protocol != IPPROTO_IP)\t\t\t\tbreak;\t\t&#125; else &#123;\t\t\t/* Check for the two wild cases. */\t\t\tif (IPPROTO_IP == protocol) &#123;\t\t\t\tprotocol = answer-&gt;protocol;\t\t\t\tbreak;\t\t\t&#125;\t\t\tif (IPPROTO_IP == answer-&gt;protocol)\t\t\t\tbreak;\t\t&#125;\t\terr = -EPROTONOSUPPORT;\t&#125;\tif (unlikely(err)) &#123;\t\tif (try_loading_module &lt; 2) &#123;\t\t\trcu_read_unlock();\t\t\t/*\t\t\t * Be more specific, e.g. net-pf-2-proto-132-type-1\t\t\t * (net-pf-PF_INET-proto-IPPROTO_SCTP-type-SOCK_STREAM)\t\t\t */\t\t\tif (++try_loading_module == 1)\t\t\t\trequest_module(&quot;net-pf-%d-proto-%d-type-%d&quot;,\t\t\t\t\t       PF_INET, protocol, sock-&gt;type);\t\t\t/*\t\t\t * Fall back to generic, e.g. net-pf-2-proto-132\t\t\t * (net-pf-PF_INET-proto-IPPROTO_SCTP)\t\t\t */\t\t\telse\t\t\t\trequest_module(&quot;net-pf-%d-proto-%d&quot;,\t\t\t\t\t       PF_INET, protocol);\t\t\tgoto lookup_protocol;\t\t&#125; else\t\t\tgoto out_rcu_unlock;\t&#125;\terr = -EPERM;\t/* 如果是用户态来创建的，并且是SOCK_RAW，额外检查下权限 */\tif (sock-&gt;type == SOCK_RAW &amp;&amp; !kern &amp;&amp;\t    !ns_capable(net-&gt;user_ns, CAP_NET_RAW))\t\tgoto out_rcu_unlock;\t/* such as inet_stream_ops 、 inet_dgram_ops、 inet_sockraw_ops */\tsock-&gt;ops = answer-&gt;ops;\t/* such as tcp_prot 、 udp_prot 、ping_prot 、raw_prot */\tanswer_prot = answer-&gt;prot;\t/* see inetsw_array */\tanswer_flags = answer-&gt;flags;\trcu_read_unlock();\tWARN_ON(!answer_prot-&gt;slab);\terr = -ENOMEM;\t/* 根据 prot-&gt;obj_size 来申请 sock 的内存, sk 其实就是 tcp_sock 、 udp_sock\t * tcp_sock\t\ttcp_prot\tsizeof(tcp_sock) 约2264字节\t * udp_sock\t\tudp_prot  \tsizeof(udp_sock) 约1152字节 */\tsk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot, kern);\tif (!sk)\t\tgoto out;\terr = 0;\t/* icmp_prot 、 raw_prot 才有标志里才有这个 */\tif (INET_PROTOSW_REUSE &amp; answer_flags)\t\tsk-&gt;sk_reuse = SK_CAN_REUSE;\tinet = inet_sk(sk);\tinet_assign_bit(IS_ICSK, sk, INET_PROTOSW_ICSK &amp; answer_flags);\tinet_clear_bit(NODEFRAG, sk);\tif (SOCK_RAW == sock-&gt;type) &#123;\t\tinet-&gt;inet_num = protocol;\t\tif (IPPROTO_RAW == protocol)\t\t\tinet_set_bit(HDRINCL, sk);\t&#125;\tif (READ_ONCE(net-&gt;ipv4.sysctl_ip_no_pmtu_disc))\t\tinet-&gt;pmtudisc = IP_PMTUDISC_DONT;\telse\t\tinet-&gt;pmtudisc = IP_PMTUDISC_WANT;\tatomic_set(&amp;inet-&gt;inet_id, 0);\tsock_init_data(sock, sk);\tsk-&gt;sk_destruct\t   = inet_sock_destruct;\tsk-&gt;sk_protocol\t   = protocol;\tsk-&gt;sk_backlog_rcv = sk-&gt;sk_prot-&gt;backlog_rcv;\tsk-&gt;sk_txrehash = READ_ONCE(net-&gt;core.sysctl_txrehash);\tinet-&gt;uc_ttl\t= -1;\tinet_set_bit(MC_LOOP, sk);\tinet-&gt;mc_ttl\t= 1;\tinet_set_bit(MC_ALL, sk);\tinet-&gt;mc_index\t= 0;\tinet-&gt;mc_list\t= NULL;\tinet-&gt;rcv_tos\t= 0;\t/* SOCK_RAW 才会走进这里，因为前面只有 SOCK_RAW 才给 inet_num 赋值了啊 */\tif (inet-&gt;inet_num) &#123;\t\t/* It assumes that any protocol which allows\t\t * the user to assign a number at socket\t\t * creation time automatically shares.\t\t */\t\tinet-&gt;inet_sport = htons(inet-&gt;inet_num);\t\t/* Add to protocol hash chains.\t\t * raw_hash_sk */\t\terr = sk-&gt;sk_prot-&gt;hash(sk);\t\tif (err) &#123;\t\t\tsk_common_release(sk);\t\t\tgoto out;\t\t&#125;\t&#125;\t/* tcp_v4_init_sock 、 udp_init_sock \t * 负责对应套接字初始化相关 */\tif (sk-&gt;sk_prot-&gt;init) &#123;\t\terr = sk-&gt;sk_prot-&gt;init(sk);\t\tif (err) &#123;\t\t\tsk_common_release(sk);\t\t\tgoto out;\t\t&#125;\t&#125;\t/* 用户态socket()调过来，kern是0, 可以看 sock_create \t * 如果是内核创建套接字，kern是1，就不再走bpf相关钩子了 */\tif (!kern) &#123;\t\terr = BPF_CGROUP_RUN_PROG_INET_SOCK(sk);\t\tif (err) &#123;\t\t\tsk_common_release(sk);\t\t\tgoto out;\t\t&#125;\t&#125;out:\treturn err;out_rcu_unlock:\trcu_read_unlock();\tgoto out;&#125;\n\n\ntcp_v4_init_sock是对tcp_sock的成员做初始化。\n/* NOTE: A lot of things set to zero explicitly by call to *       sk_alloc() so need not be done here. * 由 inet_create 调用 * 这是tcp socket初始化必经之路 */static int tcp_v4_init_sock(struct sock *sk)&#123;\tstruct inet_connection_sock *icsk = inet_csk(sk);\ttcp_init_sock(sk);\ticsk-&gt;icsk_af_ops = &amp;ipv4_specific;#ifdef CONFIG_TCP_MD5SIG\ttcp_sk(sk)-&gt;af_specific = &amp;tcp_sock_ipv4_specific;#endif\treturn 0;&#125;/* Address-family independent initialization for a tcp_sock. * * NOTE: A lot of things set to zero explicitly by call to *       sk_alloc() so need not be done here. * 由 tcp_v4_init_sock 、 tcp_v6_init_sock 调用 */void tcp_init_sock(struct sock *sk)&#123;\tstruct inet_connection_sock *icsk = inet_csk(sk);\tstruct tcp_sock *tp = tcp_sk(sk);\ttp-&gt;out_of_order_queue = RB_ROOT;\tsk-&gt;tcp_rtx_queue = RB_ROOT;\t/* 初始化定时器相关 */\ttcp_init_xmit_timers(sk);\t\tINIT_LIST_HEAD(&amp;tp-&gt;tsq_node);\tINIT_LIST_HEAD(&amp;tp-&gt;tsorted_sent_queue);\ticsk-&gt;icsk_rto = TCP_TIMEOUT_INIT;\ticsk-&gt;icsk_rto_min = TCP_RTO_MIN;\ticsk-&gt;icsk_delack_max = TCP_DELACK_MAX;\ttp-&gt;mdev_us = jiffies_to_usecs(TCP_TIMEOUT_INIT);\tminmax_reset(&amp;tp-&gt;rtt_min, tcp_jiffies32, ~0U);\t/* So many TCP implementations out there (incorrectly) count the\t * initial SYN frame in their delayed-ACK and congestion control\t * algorithms that we must have the following bandaid to talk\t * efficiently to them.  -DaveM\t */\ttcp_snd_cwnd_set(tp, TCP_INIT_CWND);\t/* There&#x27;s a bubble in the pipe until at least the first ACK. */\ttp-&gt;app_limited = ~0U;\ttp-&gt;rate_app_limited = 1;\t/* See draft-stevens-tcpca-spec-01 for discussion of the\t * initialization of these values.\t */\ttp-&gt;snd_ssthresh = TCP_INFINITE_SSTHRESH;\ttp-&gt;snd_cwnd_clamp = ~0;\ttp-&gt;mss_cache = TCP_MSS_DEFAULT;\ttp-&gt;reordering = READ_ONCE(sock_net(sk)-&gt;ipv4.sysctl_tcp_reordering);\ttcp_assign_congestion_control(sk);\ttp-&gt;tsoffset = 0;\ttp-&gt;rack.reo_wnd_steps = 1;\tsk-&gt;sk_write_space = sk_stream_write_space;\tsock_set_flag(sk, SOCK_USE_WRITE_QUEUE);\ticsk-&gt;icsk_sync_mss = tcp_sync_mss;\t/* 默认 tcp_sock 发送缓冲区大小:16384(16K) \t接收缓冲区大小:131072(128K)\t * net.ipv4.tcp_wmem = 4096        16384   4194304 \t * net.ipv4.tcp_rmem = 4096        131072  6291456 */\tWRITE_ONCE(sk-&gt;sk_sndbuf, READ_ONCE(sock_net(sk)-&gt;ipv4.sysctl_tcp_wmem[1]));\tWRITE_ONCE(sk-&gt;sk_rcvbuf, READ_ONCE(sock_net(sk)-&gt;ipv4.sysctl_tcp_rmem[1]));\t/* 初始化用于调整TCP接收窗口大小的缩放比例因子 */\ttcp_scaling_ratio_init(sk);\t/* 表示该sk支持零拷贝操作，通常用于优化网络数据传输\t * 减少数据在内核和用户空间之间的拷贝次数 */\tset_bit(SOCK_SUPPORT_ZC, &amp;sk-&gt;sk_socket-&gt;flags);\t/* 增加 tcp_sock 的引用计数，确保其在使用期间不会被释放\t * 在 tcp_v4_destroy_sock 中关闭tcp_sock时，会减引用计数 */\tsk_sockets_allocated_inc(sk);&#125;EXPORT_SYMBOL(tcp_init_sock);\n\n\n我们已经申请好了socket结构，而socket结构对于用户态是无感的，用户态是通过文件描述符fd来管理对应的socket结构的。因此就需要将socket映射出一个与之对应的文件描述符fd，返回给上层应用，sock_map_fd就是做这件事情的。它首先通过get_unused_fd_flags获取当前进程的最小的未使用的文件描述符fd，然后调用sock_alloc_file创建一个文件对象，再通过fd_install，完成fd 和 文件对象的关联。而文件对象也是跟socket相互关联的。\n/* 由 __sys_socket 调用 */static int sock_map_fd(struct socket *sock, int flags)&#123;\tstruct file *newfile;\tint fd;\t/* 获取当前进程的一个未使用的文件描述符fd */\tfd = get_unused_fd_flags(flags);\tif (unlikely(fd &lt; 0)) &#123;\t\tsock_release(sock);\t\treturn fd;\t&#125;\t/* 创建一个文件对象，将 socket 和 file 关联起来 */\tnewfile = sock_alloc_file(sock, flags, NULL);\tif (!IS_ERR(newfile)) &#123;\t\t/* 关联 fd 和 file，这样找到了 file，也就找到了 socket */\t\tfd_install(fd, newfile);\t\treturn fd;\t&#125;\t/* 有错误，将fd标记为未使用 */\tput_unused_fd(fd);\treturn PTR_ERR(newfile);&#125;\n\n\nget_unused_fd_flags就是通过current(进程pcb结构)，拿到其中的files，这个files就是来管理这个进程所有的文件描述符的结构。files内部有一个fdt，fdt内部有一个二维指针fd，这个二维指针指向了fd array。用户态的fd其实就是这个fd array的数组索引。\n/* 由 sock_map_fd 调用 */int get_unused_fd_flags(unsigned flags)&#123;\treturn __get_unused_fd_flags(flags, rlimit(RLIMIT_NOFILE));&#125;EXPORT_SYMBOL(get_unused_fd_flags);int __get_unused_fd_flags(unsigned flags, unsigned long nofile)&#123;\treturn alloc_fd(0, nofile, flags);&#125;/* * allocate a file descriptor, mark it busy. */static int alloc_fd(unsigned start, unsigned end, unsigned flags)&#123;\tstruct files_struct *files = current-&gt;files;\tunsigned int fd;\tint error;\tstruct fdtable *fdt;\tspin_lock(&amp;files-&gt;file_lock);repeat:\tfdt = files_fdtable(files);\tfd = start;\tif (fd &lt; files-&gt;next_fd)\t\tfd = files-&gt;next_fd;\tif (fd &lt; fdt-&gt;max_fds)\t\tfd = find_next_fd(fdt, fd);\t/*\t * N.B. For clone tasks sharing a files structure, this test\t * will limit the total number of files that can be opened.\t */\terror = -EMFILE;\tif (fd &gt;= end)\t\tgoto out;\terror = expand_files(files, fd);\tif (error &lt; 0)\t\tgoto out;\t/*\t * If we needed to expand the fs array we\t * might have blocked - try again.\t */\tif (error)\t\tgoto repeat;\tif (start &lt;= files-&gt;next_fd)\t\tfiles-&gt;next_fd = fd + 1;\t__set_open_fd(fd, fdt);\tif (flags &amp; O_CLOEXEC)\t\t__set_close_on_exec(fd, fdt);\telse\t\t__clear_close_on_exec(fd, fdt);\terror = fd;#if 1\t/* Sanity check */\tif (rcu_access_pointer(fdt-&gt;fd[fd]) != NULL) &#123;\t\tprintk(KERN_WARNING &quot;alloc_fd: slot %d not NULL!\\n&quot;, fd);\t\trcu_assign_pointer(fdt-&gt;fd[fd], NULL);\t&#125;#endifout:\tspin_unlock(&amp;files-&gt;file_lock);\treturn error;&#125;/* * Open file table structure */struct files_struct &#123;  /*   * read mostly part   */\tatomic_t count;\tbool resize_in_progress;\twait_queue_head_t resize_wait;\t/* 所有的文件描述符都在fdt的fd数组里存着 */\tstruct fdtable __rcu *fdt;\tstruct fdtable fdtab;  /*   * written part on a separate cache line in SMP   */\tspinlock_t file_lock ____cacheline_aligned_in_smp;\tunsigned int next_fd;\tunsigned long close_on_exec_init[1];\tunsigned long open_fds_init[1];\tunsigned long full_fds_bits_init[1];\tstruct file __rcu * fd_array[NR_OPEN_DEFAULT];&#125;;struct fdtable &#123;\tunsigned int max_fds;\tstruct file __rcu **fd;      /* current fd array */\tunsigned long *close_on_exec;\tunsigned long *open_fds;\tunsigned long *full_fds_bits;\tstruct rcu_head rcu;&#125;;\n\n\nsock_alloc_file会申请一个file对象，并且它将与socket互相指向对方，这就意味着找到其中一个，就可以找到另外一个。\nstruct file *sock_alloc_file(struct socket *sock, int flags, const char *dname)&#123;\tstruct file *file;\tif (!dname)\t\tdname = sock-&gt;sk ? sock-&gt;sk-&gt;sk_prot_creator-&gt;name : &quot;&quot;;\t/* alloc 一个file 绑定了 socket_file_ops 回调函数集合，sock_mnt为一个挂载点 */\tfile = alloc_file_pseudo(SOCK_INODE(sock), sock_mnt, dname,\t\t\t\tO_RDWR | (flags &amp; O_NONBLOCK),\t\t\t\t&amp;socket_file_ops);\tif (IS_ERR(file)) &#123;\t\tsock_release(sock);\t\treturn file;\t&#125;\tfile-&gt;f_mode |= FMODE_NOWAIT;\t/* socket、file 互相指向对方 */\tsock-&gt;file = file;\tfile-&gt;private_data = sock;\t/* 标记为流式文件，不支持lseek(随机访问)？*/\tstream_open(SOCK_INODE(sock), file);\treturn file;&#125;\n\n\nfd_install就是将申请的file对象，按照获取到的fd，将file放到fdt的fd数组的fd索引位置处。这样后续用户态传入fd，就可以在这个fdt的fd数组中索引到file，而通过file就可以找到与之关联的socket结构。从而内核可以再对socket结构去做对应的操作。\n/* * 由 sock_map_fd 、 __sys_accept4_file 调用 * 目标就是把 file 放进 fdt-&gt;fd 里面，完成 fd 与 file 的关联 */void fd_install(unsigned int fd, struct file *file)&#123;\tstruct files_struct *files = current-&gt;files;\tstruct fdtable *fdt;\trcu_read_lock_sched();\tif (unlikely(files-&gt;resize_in_progress)) &#123;\t\trcu_read_unlock_sched();\t\tspin_lock(&amp;files-&gt;file_lock);\t\tfdt = files_fdtable(files);\t\tBUG_ON(fdt-&gt;fd[fd] != NULL);\t\trcu_assign_pointer(fdt-&gt;fd[fd], file);\t\tspin_unlock(&amp;files-&gt;file_lock);\t\treturn;\t&#125;\t/* coupled with smp_wmb() in expand_fdtable() */\tsmp_rmb();\tfdt = rcu_dereference_sched(files-&gt;fdt);\t/* 正常应该为这个里面应该为空，如果不为空，触发BUG */\tBUG_ON(fdt-&gt;fd[fd] != NULL);\t/* 将file放进fd二维指针指向的数组的fd位置，完成 fd 与 file 的关联 */\trcu_assign_pointer(fdt-&gt;fd[fd], file);\trcu_read_unlock_sched();&#125;\n\n\n总结socket函数就是在内核中创建了一个socket_alloc结构，并且会根据传入的type、protocol来创建对应的sock结构。之后再创建一个文件对象，使之与socket相互关联。再选出一个最小未使用的fd，将文件对象存储到文件描述符列表fd位置处，将fd返给用户态。\n","categories":["linux6.6内核"],"tags":["socket","网络"]},{"title":"syscall调用流程分析","url":"/2025/12/09/syscall%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/","content":"syscall是什么在linux系统中，系统调用是用户态程序进入内核态的唯一合法入口。用户态程序本身工作在ring3层，而内核运行在ring0层。用户态不能直接访问内核数据结构、不能直接操作硬件、不能直接调用内核函数，所有这些操作都需要通过操作系统提提供的系统调用来实现，系统调用就相当于用户态到内核态的入口。\nposixposix本身不是内核，也不是库，它只是一个“操作系统接口标准规范”，它规定了：应该有哪些 API、API 的行为应该是什么、参数含义、返回值语义应该如何比如：socket、open、read ……\nglibc当用户态程序调用socket函数，其实它会调用到glibc的socket函数。\nint socket(int domain, int type, int protocol);\n\nglibc socket 内部实现：\n#include &lt;sys/socket.h&gt;#include &lt;socketcall.h&gt;int__socket (int fd, int type, int domain)&#123;#ifdef __ASSUME_SOCKET_SYSCALL  return INLINE_SYSCALL_CALL (socket, fd, type, domain);#else  return SOCKETCALL (socket, fd, type, domain);#endif&#125;libc_hidden_def (__socket)weak_alias (__socket, socket)\n\n\n__ASSUME_SOCKET_SYSCALL 宏默认是已定义的，是用来判断是否支持单独的系统调用号的，目前基本上都是支持的。\n我们将 INLINE_SYSCALL_CALL 展开：\n因为：#define INLINE_SYSCALL_CALL(...) __INLINE_SYSCALL_DISP (__INLINE_SYSCALL, __VA_ARGS__)可推导：INLINE_SYSCALL_CALL (socket, fd, type, domain);-&gt;__INLINE_SYSCALL_DISP (__INLINE_SYSCALL, socket, fd, type, domain);因为：#define __INLINE_SYSCALL_DISP(b,...)  __SYSCALL_CONCAT (b,__INLINE_SYSCALL_NARGS(__VA_ARGS__))(__VA_ARGS__)可推导：__INLINE_SYSCALL_DISP (__INLINE_SYSCALL, socket, fd, type, domain);-&gt;__SYSCALL_CONCAT (__INLINE_SYSCALL, __INLINE_SYSCALL_NARGS(socket, fd, type, domain)(socket, fd, type, domain));因为：#define __INLINE_SYSCALL_NARGS_X(a,b,c,d,e,f,g,h,n,...) n#define __INLINE_SYSCALL_NARGS(...) __INLINE_SYSCALL_NARGS_X (__VA_ARGS__,7,6,5,4,3,2,1,0,)可推导：__SYSCALL_CONCAT (__INLINE_SYSCALL, __INLINE_SYSCALL_NARGS(socket, fd, type, domain)(socket, fd, type, domain));-&gt;__SYSCALL_CONCAT (__INLINE_SYSCALL, __INLINE_SYSCALL_NARGS_X(socket, fd, type, domain, 7,6,5,4,3,2,1,0,)(socket, fd, type, domain));-&gt;__SYSCALL_CONCAT (__INLINE_SYSCALL, 3(socket, fd, type, domain));因为：#define __SYSCALL_CONCAT_X(a,b)     a##b#define __SYSCALL_CONCAT(a,b)       __SYSCALL_CONCAT_X (a, b)可推导：__SYSCALL_CONCAT (__INLINE_SYSCALL, 3(socket, fd, type, domain));-&gt;__SYSCALL_CONCAT_X (__INLINE_SYSCALL, 3(socket, fd, type, domain));-&gt;__INLINE_SYSCALL3(socket, fd, type, domain);因为：#define __INLINE_SYSCALL3(name, a1, a2, a3) INLINE_SYSCALL (name, 3, a1, a2, a3)可推导：__INLINE_SYSCALL3(socket, fd, type, domain);-&gt;INLINE_SYSCALL(socket, 3, fd, type, domain);因为：#define INLINE_SYSCALL(name, nr, args...)\t\t\t\t\\  (&#123;\t\t\t\t\t\t\t\t\t\\    long int sc_ret = INTERNAL_SYSCALL (name, nr, args);\t\t\\    __glibc_unlikely (INTERNAL_SYSCALL_ERROR_P (sc_ret))\t\t\\    ? SYSCALL_ERROR_LABEL (INTERNAL_SYSCALL_ERRNO (sc_ret))\t\t\\    : sc_ret;\t\t\t\t\t\t\t\t\\  &#125;)可推导：INLINE_SYSCALL(socket, 3, fd, type, domain);-&gt;(&#123;\t\t\t\t\t\t\t\t\tlong int sc_ret = INTERNAL_SYSCALL (socket, 3,  fd, type, domain);\t\t__glibc_unlikely (INTERNAL_SYSCALL_ERROR_P (sc_ret))\t\t? SYSCALL_ERROR_LABEL (INTERNAL_SYSCALL_ERRNO (sc_ret))\t\t: sc_ret;\t\t\t\t\t\t\t\t&#125;)因为：#define INTERNAL_SYSCALL(name, nr, args...)\t\t\t\t\\\tinternal_syscall##nr (SYS_ify (name), args)#define SYS_ify(syscall_name)\t__NR_##syscall_name#define INTERNAL_SYSCALL_ERROR_P(val) \\  ((unsigned long int) (val) &gt; -4096UL)#define INTERNAL_SYSCALL_ERRNO(val)     (-(val))可推导：(&#123;\t\t\t\t\t\t\t\t\tlong int sc_ret = INTERNAL_SYSCALL (socket, 3,  fd, type, domain);\t\t__glibc_unlikely (((unsigned long int) (sc_ret) &gt; -4096UL)))\t\t? SYSCALL_ERROR_LABEL (INTERNAL_SYSCALL_ERRNO (sc_ret))\t\t: sc_ret;\t\t\t\t\t\t\t&#125;)-&gt;(&#123;\t\t\t\t\t\t\t\tlong int sc_ret = internal_syscall3 (__NR_socket, fd, type, domain);\t\t__glibc_unlikely (INTERNAL_SYSCALL_ERROR_P (sc_ret))\t\t? SYSCALL_ERROR_LABEL (-(sc_ret))\t\t: sc_ret;\t\t\t\t\t\t\t\t&#125;)因为：#define __NR_socket 41#define SYSCALL_ERROR_LABEL(sc_err)\t\t\t\t\t\\  (&#123;\t\t\t\t\t\t\t\t\t\\    __set_errno (sc_err);\t\t\t\t\t\t\\    -1L;\t\t\t\t\t\t\t\t\\  &#125;)# define __glibc_unlikely(cond)\t__builtin_expect ((cond), 0)#define internal_syscall3(number, arg1, arg2, arg3)\t\t\t\\(&#123;\t\t\t\t\t\t\t\t\t\\    unsigned long int resultvar;\t\t\t\t\t\\    TYPEFY (arg3, __arg3) = ARGIFY (arg3);\t\t\t \t\\    TYPEFY (arg2, __arg2) = ARGIFY (arg2);\t\t\t \t\\    TYPEFY (arg1, __arg1) = ARGIFY (arg1);\t\t\t \t\\    register TYPEFY (arg3, _a3) asm (&quot;rdx&quot;) = __arg3;\t\t\t\\    register TYPEFY (arg2, _a2) asm (&quot;rsi&quot;) = __arg2;\t\t\t\\    register TYPEFY (arg1, _a1) asm (&quot;rdi&quot;) = __arg1;\t\t\t\\    asm volatile (\t\t\t\t\t\t\t\\    &quot;syscall\\n\\t&quot;\t\t\t\t\t\t\t\\    : &quot;=a&quot; (resultvar)\t\t\t\t\t\t\t\\    : &quot;0&quot; (number), &quot;r&quot; (_a1), &quot;r&quot; (_a2), &quot;r&quot; (_a3)\t\t\t\\    : &quot;memory&quot;, REGISTERS_CLOBBERED_BY_SYSCALL);\t\t\t\\    (long int) resultvar;\t\t\t\t\t\t\\&#125;)#define TYPEFY1(X) __typeof__ ((X) - (X))#define ARGIFY(X) ((TYPEFY1 (X)) (X))#define TYPEFY(X, name) __typeof__ (ARGIFY (X)) name# define REGISTERS_CLOBBERED_BY_SYSCALL &quot;cc&quot;, &quot;r11&quot;, &quot;cx&quot;可推导：(&#123;\t\t\t\t\t\t\t\t\tlong int sc_ret = internal_syscall3 (__NR_socket, fd, type, domain);\t\t__glibc_unlikely (INTERNAL_SYSCALL_ERROR_P (sc_ret))\t\t? SYSCALL_ERROR_LABEL (-(sc_ret))\t\t: sc_ret;\t\t\t\t\t\t\t\t&#125;)-&gt;(&#123;  long int sc_ret = (&#123;    unsigned long int resultvar;    __typeof__ (((__typeof__ ((domain) - (domain))) (domain))) __arg3         = ((__typeof__ ((domain) - (domain))) (domain));    __typeof__ (((__typeof__ ((type) - (type))) (type))) __arg2        = ((__typeof__ ((type) - (type))) (type));    __typeof__ (((__typeof__ ((fd) - (fd))) (fd))) __arg1        = ((__typeof__ ((fd) - (fd))) (fd));        register __typeof__ (((__typeof__ ((domain) - (domain))) (domain))) _a3 asm (&quot;rdx&quot;) = __arg3;    register __typeof__ (((__typeof__ ((type) - (type))) (type))) _a2 asm (&quot;rsi&quot;) = __arg2;    register __typeof__ (((__typeof__ ((fd) - (fd))) (fd))) _a1 asm (&quot;rdi&quot;) = __arg1;        asm volatile (&quot;syscall\\n\\t&quot;          : &quot;=a&quot;(resultvar)          : &quot;0&quot;(41), &quot;r&quot;(_a1), &quot;r&quot;(_a2), &quot;r&quot;(_a3)          : &quot;memory&quot;, &quot;cc&quot;, &quot;r11&quot;, &quot;cx&quot;);    (long int) resultvar;  &#125;);  __builtin_expect ((((unsigned long int) (sc_ret) &gt; -4096UL)), 0) ? (&#123;    (__libc_errno = ((-(sc_ret))));    -1L;  &#125;)    : sc_ret;&#125;)\n\n这段代码的核心之处，在于汇编内部的调用。\nsyscall表示：执行syscall指令\n: “&#x3D;a”(resultvar)表示：把返回值放到 resultvar中\n: “0”(41)表示：把 41 放进 rax 寄存器，41是socket的系统调用号，\n“r”(_a1), “r”(_a2), “r”(_a3)表示：把_a1放到rdi，把_a2放到rsi，把_a3放到rdx\nx86_64 syscall 调用约定传参的寄存器为：\n\n\n\n参数\n寄存器\n\n\n\n返回值\nRAX\n\n\nsyscall编号\nRAX\n\n\n参数1\nRDI\n\n\n参数2\nRSI\n\n\n参数3\nRDX\n\n\n参数4\nR10\n\n\n参数5\nR8\n\n\n参数6\nR9\n\n\ni386 syscall 调用约定传参的寄存器为：\n\n\n\n参数\n寄存器\n\n\n\n返回值\nEAX\n\n\nsyscall编号\nEAX\n\n\n参数1\nEBX\n\n\n参数2\nECX\n\n\n参数3\nEDX\n\n\n参数4\nESI\n\n\n参数5\nEDI\n\n\n参数6\nEBP\n\n\nSystem V AMD64 ABI 普通函数 调用约定传参 格式 为：\n\n\n\n参数\n寄存器\n\n\n\n参数1\nRDI\n\n\n参数2\nRSI\n\n\n参数3\nRDX\n\n\n参数4\nRCX\n\n\n参数5\nR8\n\n\n参数6\nR9\n\n\n参数x\n栈\n\n\nSystem V AMD64 ABI 普通函数 返回值 比较特殊 为：\n\n\n\n返回类型\n寄存器\n\n\n\n整数 &#x2F; 指针\nRAX\n\n\n64 位整数\nRAX\n\n\n浮点（double）\nXMM0\n\n\nkernelQ: 那么执行 syscall指令 会跳转执行到哪里呢？A: 当执行 syscall指令 时，cpu会根据 MSR寄存器 跳转到指定函数，MSR寄存器的注册是在syscall_init中做的。\n/* May not be marked __init: used by software suspend  * 由 cpu_init 调用 */void syscall_init(void)&#123;\twrmsr(MSR_STAR, 0, (__USER32_CS &lt;&lt; 16) | __KERNEL_CS);\t/* 把 entry_SYSCALL_64 地址写入MSR寄存器，*/\twrmsrl(MSR_LSTAR, (unsigned long)entry_SYSCALL_64);    ......&#125;\n\n而entry_SYSCALL_64是由汇编写的，它的实现在arch&#x2F;x86&#x2F;entry&#x2F;entry_64.S中\nSYM_CODE_START(entry_SYSCALL_64)\tUNWIND_HINT_ENTRY\tENDBR\tswapgs\t/* tss.sp2 is scratch space. */\tmovq\t%rsp, PER_CPU_VAR(cpu_tss_rw + TSS_sp2)\tSWITCH_TO_KERNEL_CR3 scratch_reg=%rsp\tmovq\tPER_CPU_VAR(pcpu_hot + X86_top_of_stack), %rspSYM_INNER_LABEL(entry_SYSCALL_64_safe_stack, SYM_L_GLOBAL)\tANNOTATE_NOENDBR\t/* Construct struct pt_regs on stack */\tpushq\t$__USER_DS\t\t\t\t/* pt_regs-&gt;ss */\tpushq\tPER_CPU_VAR(cpu_tss_rw + TSS_sp2)\t/* pt_regs-&gt;sp */\tpushq\t%r11\t\t\t\t\t/* pt_regs-&gt;flags */\tpushq\t$__USER_CS\t\t\t\t/* pt_regs-&gt;cs */\tpushq\t%rcx\t\t\t\t\t/* pt_regs-&gt;ip */SYM_INNER_LABEL(entry_SYSCALL_64_after_hwframe, SYM_L_GLOBAL)\tpushq\t%rax\t\t\t\t\t/* pt_regs-&gt;orig_ax */\tPUSH_AND_CLEAR_REGS rax=$-ENOSYS\t/* IRQs are off. */\tmovq\t%rsp, %rdi\t/* Sign extend the lower 32bit as syscall numbers are treated as int */\tmovslq\t%eax, %rsi\t/* clobbers %rax, make sure it is after saving the syscall nr */\tIBRS_ENTER\tUNTRAIN_RET\t/* 调用到 arch/x86/entry/common.c 中的 do_syscall_64 函数 */\tcall\tdo_syscall_64\t\t/* returns with IRQs disabled */    ......SYM_CODE_END(entry_SYSCALL_64)\n\n接着看 do_syscall_64 的实现：\n/* 导出该符号，并且该函数禁止插桩，防止死锁或栈破坏  * 由 entry_64.S 文件的 entry_SYSCALL_64 中调用 */__visible noinstr void do_syscall_64(struct pt_regs *regs, int nr)&#123;\t/* 每次syscall，内核栈随机偏移几个字节，防止被攻击，增强安全性 */\tadd_random_kstack_offset();\tnr = syscall_enter_from_user_mode(regs, nr);\t/* 从这里开始允许进行 instrumentation，入口不能插桩，但是syscall处理的部分可以 */\tinstrumentation_begin();\t/* 先在syscall64表查syscall调用号是否合法，不合法就在x32 ABI表查，\t * 还不合法，并且syscall调用号不是-1，那就得置返回值为无效，\t * 这个do_syscall_32 可不是 ia32_sys_call_table相关的，而是一个小众的ABI，几乎没有发行版使用，\t * 因为32位系统调用，不走syscall指令，而是通过 int 0x80 或者 sysenter */\tif (!do_syscall_x64(regs, nr) &amp;&amp; !do_syscall_x32(regs, nr) &amp;&amp; nr != -1) &#123;\t\t/* Invalid system call, but still a system call. \t\t * 无效的 syscall调用号 才会走进来，这里就是给返回值置成 ENOSYS */\t\tregs-&gt;ax = __x64_sys_ni_syscall(regs);\t&#125;\t/* 再次禁止插桩 */\tinstrumentation_end();\tsyscall_exit_to_user_mode(regs);&#125;/* 由 do_syscall_64 调用  * 返回 true，代表传入的 syscall调用号 合法，并且去执行了sys_call_table系统调用表的对应函数  * 返回 false，代表传入的 syscall调用号 不合法 */static __always_inline bool do_syscall_x64(struct pt_regs *regs, int nr)&#123;\t/*\t * Convert negative numbers to very high and thus out of range\t * numbers for comparisons.\t * 如果 nr 是负数，这里直接传给了 unr，会变成一个极大数，必然超出syscall表范围\t * 不需要再额外单独判断nr是否为负数了，代码很巧妙\t */\tunsigned int unr = nr;\t/* 进行系统调用号的有效性检查 */\tif (likely(unr &lt; NR_syscalls)) &#123;\t\tunr = array_index_nospec(unr, NR_syscalls);\t\t/* 执行unr 这个 系统调用号 对应的 内核入口函数 */\t\tregs-&gt;ax = sys_call_table[unr](regs);\t\treturn true;\t&#125;\treturn false;&#125;#define __SYSCALL(nr, sym) extern long __x64_##sym(const struct pt_regs *);#include &lt;asm/syscalls_64.h&gt;#undef __SYSCALL#define __SYSCALL(nr, sym) __x64_##sym,asmlinkage const sys_call_ptr_t sys_call_table[] = &#123;#include &lt;asm/syscalls_64.h&gt;&#125;;\n\n\n在编译时，会使用syscalltbl.sh脚本，将syscall_64.tbl，转换到syscalls_64.h，从而这个数组就是被填充成真实的函数地址\n也就是转换为：...extern long __x64_sys_open(const struct pt_regs *);...extern long __x64_sys_socket(const struct pt_regs *);...asmlinkage const sys_call_ptr_t sys_call_table[] = &#123;...,__x64_sys_open,...,__x64_sys_socket,&#125;;\n\n\n我们都知道，linux6.6内核中，找一个系统调用的入口，往往都是通过搜索 SYSCALL_DEFINEx(系统调用名称 来查找，其中的 x 代表的是系统调用的参数个数，系统调用名称 就是具体的系统调用名，如 socket、bind、open等。拿实例 socket 来看，其定义如下：\n路径：net&#x2F;socket.c\nSYSCALL_DEFINE3(socket, int, family, int, type, int, protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n到这里可能有疑问了，这也不是上面的sys_call_table里面的 __x64_sys_socket 啊？我们继续往下看。我们不贪多，一步一步展开，看起来会更加清晰。\n\n首先查看 SYSCALL_DEFINE3 这个宏是怎么定义的。\n#define SYSCALL_DEFINE3(name, ...) SYSCALL_DEFINEx(3, _##name, __VA_ARGS__)\n\n因此展开后得到：\nSYSCALL_DEFINEx(3, _socket, int, family, int, type, int, protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看 SYSCALL_DEFINEx 的定义：\n#define SYSCALL_DEFINEx(x, sname, ...)\t\t\t\t\\\tSYSCALL_METADATA(sname, x, __VA_ARGS__)\t\t\t\\\t__SYSCALL_DEFINEx(x, sname, __VA_ARGS__)\n\n因此展开后得到：\nSYSCALL_METADATA(_socket, 3, int, family, int, type, int, protocol) \\__SYSCALL_DEFINEx(3, _socket, int, family, int, type, int, protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看 SYSCALL_METADATA 的定义：\n#define SYSCALL_METADATA(sname, nb, ...)\t\t\t\\\tstatic const char *types_##sname[] = &#123;\t\t\t\\\t\t__MAP(nb,__SC_STR_TDECL,__VA_ARGS__)\t\t\\\t&#125;;\t\t\t\t\t\t\t\\\tstatic const char *args_##sname[] = &#123;\t\t\t\\\t\t__MAP(nb,__SC_STR_ADECL,__VA_ARGS__)\t\t\\\t&#125;;\t\t\t\t\t\t\t\\\tSYSCALL_TRACE_ENTER_EVENT(sname);\t\t\t\\\tSYSCALL_TRACE_EXIT_EVENT(sname);\t\t\t\\\tstatic struct syscall_metadata __used\t\t\t\\\t  __syscall_meta_##sname = &#123;\t\t\t\t\\\t\t.name \t\t= &quot;sys&quot;#sname,\t\t\t\\\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t\\\t\t.nb_args \t= nb,\t\t\t\t\\\t\t.types\t\t= nb ? types_##sname : NULL,\t\\\t\t.args\t\t= nb ? args_##sname : NULL,\t\\\t\t.enter_event\t= &amp;event_enter_##sname,\t\t\\\t\t.exit_event\t= &amp;event_exit_##sname,\t\t\\\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta_##sname.enter_fields), \\\t&#125;;\t\t\t\t\t\t\t\\\tstatic struct syscall_metadata __used\t\t\t\\\t  __section(&quot;__syscalls_metadata&quot;)\t\t\t\\\t *__p_syscall_meta_##sname = &amp;__syscall_meta_##sname;\n\n因此展开后得到：\n\tstatic const char *types__socket[] = &#123;\t\t\t\t\t__MAP(3,__SC_STR_TDECL, int, family, int, type, int, protocol)\t\t&#125;;\t\t\t\t\t\t\t\tstatic const char *args__socket[] = &#123;\t\t\t\t\t__MAP(3,__SC_STR_ADECL, int, family, int, type, int, protocol)\t\t&#125;;\t\t\t\t\t\t\t\tSYSCALL_TRACE_ENTER_EVENT(_socket);\t\t\t\tSYSCALL_TRACE_EXIT_EVENT(_socket);\t\t\t\tstatic struct syscall_metadata __used\t\t\t\t  __syscall_meta__socket = &#123;\t\t\t\t\t\t.name \t\t= &quot;sys_socket&quot;,\t\t\t\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t\t\t.nb_args \t= 3,\t\t\t\t\t\t.types\t\t= 3 ? types__socket : NULL,\t\t\t.args\t\t= 3 ? args__socket : NULL,\t\t\t.enter_event\t= &amp;event_enter__socket,\t\t\t\t.exit_event\t= &amp;event_exit__socket,\t\t\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta__socket.enter_fields),\t&#125;;\t\t\t\t\t\t\t\tstatic struct syscall_metadata __used\t\t\t\t  __section(&quot;__syscalls_metadata&quot;)\t\t\t\t *__p_syscall_meta__socket = &amp;__syscall_meta__socket;__SYSCALL_DEFINEx(3, _socket, int, family, int, type, int, protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看 __SYSCALL_DEFINEx 的定义：\n#define __SYSCALL_DEFINEx(x, name, ...)\t\t\t\t\t\\\tstatic long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__));\t\\\tstatic inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__));\\\t__X64_SYS_STUBx(x, name, __VA_ARGS__)\t\t\t\t\\\t__IA32_SYS_STUBx(x, name, __VA_ARGS__)\t\t\t\t\\\tstatic long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__))\t\\\t&#123;\t\t\t\t\t\t\t\t\\\t\tlong ret = __do_sys##name(__MAP(x,__SC_CAST,__VA_ARGS__));\\\t\t__MAP(x,__SC_TEST,__VA_ARGS__);\t\t\t\t\\\t\t__PROTECT(x, ret,__MAP(x,__SC_ARGS,__VA_ARGS__));\t\\\t\treturn ret;\t\t\t\t\t\t\\\t&#125;\t\t\t\t\t\t\t\t\\\tstatic inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))\n\n展开后得到：\nstatic const char *types__socket[] = &#123;\t\t\t\t__MAP(3,__SC_STR_TDECL, int, family, int, type, int, protocol)\t\t&#125;;\t\t\t\t\t\t\tstatic const char *args__socket[] = &#123;\t\t\t\t__MAP(3,__SC_STR_ADECL, int, family, int, type, int, protocol)\t\t&#125;;\t\t\t\t\t\t\tSYSCALL_TRACE_ENTER_EVENT(_socket);\t\t\tSYSCALL_TRACE_EXIT_EVENT(_socket);\t\t\tstatic struct syscall_metadata __used\t\t\t  __syscall_meta__socket = &#123;\t\t\t\t\t.name \t\t= &quot;sys_socket&quot;,\t\t\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t.nb_args \t= 3,\t\t\t\t\t.types\t\t= 3 ? types__socket : NULL,\t.args\t\t= 3 ? args__socket : NULL,\t\t.enter_event\t= &amp;event_enter__socket,\t\t\t.exit_event\t= &amp;event_exit__socket,\t\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta__socket.enter_fields),&#125;;\t\t\t\t\t\t\tstatic struct syscall_metadata __used\t\t\t  __section(&quot;__syscalls_metadata&quot;)\t\t\t *__p_syscall_meta__socket = &amp;__syscall_meta__socket; static long __se_sys_socket(__MAP(3,__SC_LONG, int, family, int, type, int, protocol));static inline long __do_sys_socket(__MAP(3,__SC_DECL, int, family, int, type, int, protocol));__X64_SYS_STUBx(3, _socket, int, family, int, type, int, protocol)\t\t\t\t__IA32_SYS_STUBx(3, _socket, int, family, int, type, int, protocol)\t\t\t\tstatic long __se_sys_socket(__MAP(3,__SC_LONG, int, family, int, type, int, protocol))\t&#123;\t\t\t\t\t\t\t\t\tlong ret = __do_sys_socket(__MAP(3,__SC_CAST, int, family, int, type, int, protocol));\t__MAP(3,__SC_TEST, int, family, int, type, int, protocol);\t\t\t\t\t__PROTECT(3, ret,__MAP(3,__SC_ARGS, int, family, int, type, int, protocol));\t\treturn ret;\t\t\t\t\t\t&#125;\t\t\t\t\t\t\t\tstatic inline long __do_sys_socket(__MAP(3,__SC_DECL, int, family, int, type, int, protocol))&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看 __MAP 的相关定义：\n#define __MAP0(m,...)#define __MAP1(m,t,a,...) m(t,a)#define __MAP2(m,t,a,...) m(t,a), __MAP1(m,__VA_ARGS__)#define __MAP3(m,t,a,...) m(t,a), __MAP2(m,__VA_ARGS__)#define __MAP4(m,t,a,...) m(t,a), __MAP3(m,__VA_ARGS__)#define __MAP5(m,t,a,...) m(t,a), __MAP4(m,__VA_ARGS__)#define __MAP6(m,t,a,...) m(t,a), __MAP5(m,__VA_ARGS__)#define __MAP(n,...) __MAP##n(__VA_ARGS__)\n\n展开后得到：\nstatic const char *types__socket[] = &#123;\t\t\t\t__SC_STR_TDECL(int, family), __SC_STR_TDECL(int, type), __SC_STR_TDECL(int, protocol)&#125;;\t\t\t\t\t\t\tstatic const char *args__socket[] = &#123;\t\t\t\t__SC_STR_ADECL(int, family), __SC_STR_ADECL(int, type), __SC_STR_ADECL(int, protocol)&#125;;\t\t\t\t\t\t\tSYSCALL_TRACE_ENTER_EVENT(_socket);\t\t\tSYSCALL_TRACE_EXIT_EVENT(_socket);\t\t\tstatic struct syscall_metadata __used\t\t\t  __syscall_meta__socket = &#123;\t\t\t\t\t.name \t\t= &quot;sys_socket&quot;,\t\t\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t.nb_args \t= 3,\t\t\t\t\t.types\t\t= 3 ? types__socket : NULL,\t.args\t\t= 3 ? args__socket : NULL,\t\t.enter_event\t= &amp;event_enter__socket,\t\t\t.exit_event\t= &amp;event_exit__socket,\t\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta__socket.enter_fields),&#125;;\t\t\t\t\t\t\tstatic struct syscall_metadata __used\t\t\t  __section(&quot;__syscalls_metadata&quot;)\t\t\t *__p_syscall_meta__socket = &amp;__syscall_meta__socket; static long __se_sys_socket(__SC_LONG(int, family), __SC_LONG(int, type), __SC_LONG(int, protocol));static inline long __do_sys_socket(__SC_DECL(int, family), __SC_DECL(int, type), __SC_DECL(int, protocol));__X64_SYS_STUBx(3, _socket, int, family, int, type, int, protocol)\t\t\t\t__IA32_SYS_STUBx(3, _socket, int, family, int, type, int, protocol)\t\t\t\tstatic long __se_sys_socket(__SC_LONG(int, family), __SC_LONG(int, type), __SC_LONG(int, protocol))\t&#123;\t\t\t\t\t\t\t\t\tlong ret = __do_sys_socket(__SC_CAST(int, family), __SC_CAST(int, type), __SC_CAST(int, protocol));\t__SC_TEST(int, family), __SC_TEST(int, type), __SC_TEST(int, protocol);\t\t__PROTECT(3, ret, __SC_ARGS(int, family), __SC_ARGS(int, type), __SC_ARGS(int, protocol));\t\treturn ret;\t\t\t\t\t\t&#125;\t\t\t\t\t\t\t\tstatic inline long __do_sys_socket(__SC_DECL(int, family), __SC_DECL(int, type), __SC_DECL(int, protocol))&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看 __SC_xxx 的相关定义：\n#define __SC_STR_ADECL(t, a)\t#a#define __SC_STR_TDECL(t, a)\t#t#define __SC_LONG(t, a) __typeof(__builtin_choose_expr(__TYPE_IS_LL(t), 0LL, 0L)) a#define __SC_CAST(t, a)\t(__force t) a#define __SC_ARGS(t, a)\ta#define __SC_TEST(t, a) (void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(t) &amp;&amp; sizeof(t) &gt; sizeof(long))#define __SC_DECL(t, a)\tt a\n\n展开后得到：\nstatic const char *types__socket[] = &#123;\t\t\t\t&quot;int&quot;, &quot;int&quot;, &quot;int&quot;&#125;;\t\t\t\t\t\t\tstatic const char *args__socket[] = &#123;\t&quot;family&quot;, &quot;type&quot;, &quot;protocol&quot;&#125;;\t\t\t\t\t\t\tSYSCALL_TRACE_ENTER_EVENT(_socket);\t\t\tSYSCALL_TRACE_EXIT_EVENT(_socket);\t\t\tstatic struct syscall_metadata __used\t\t\t  __syscall_meta__socket = &#123;\t\t\t\t\t.name \t\t= &quot;sys_socket&quot;,\t\t\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t.nb_args \t= 3,\t\t\t\t\t.types\t\t= 3 ? types__socket : NULL,\t.args\t\t= 3 ? args__socket : NULL,\t\t.enter_event\t= &amp;event_enter__socket,\t\t\t.exit_event\t= &amp;event_exit__socket,\t\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta__socket.enter_fields),&#125;;\t\t\t\t\t\t\tstatic struct syscall_metadata __used\t\t\t  __section(&quot;__syscalls_metadata&quot;)\t\t\t *__p_syscall_meta__socket = &amp;__syscall_meta__socket; static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol);static inline long __do_sys_socket(int family, int type, int protocol);__X64_SYS_STUBx(3, _socket, int, family, int, type, int, protocol)\t\t\t\t__IA32_SYS_STUBx(3, _socket, int, family, int, type, int, protocol)\t\t\t\tstatic long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol)&#123;\t\t\t\t\t\t\t\t\tlong ret = __do_sys_socket((__force int)family, (__force int)type, (__force int)protocol);\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t__PROTECT(3, ret, family, type, protocol);\t\treturn ret;\t\t\t\t\t\t&#125;\t\t\t\t\t\t\t\tstatic inline long __do_sys_socket(int family, int type, int protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看 __X64_SYS_STUBx 、 __IA32_SYS_STUBx 的相关定义：\n#define __X64_SYS_STUBx(x, name, ...)\t\t\t\t\t\\\t__SYS_STUBx(x64, sys##name,\t\t\t\t\t\\\t\t    SC_X86_64_REGS_TO_ARGS(x, __VA_ARGS__))#define __IA32_SYS_STUBx(x, name, ...)\t\t\t\t\t\\\t__SYS_STUBx(ia32, sys##name,\t\t\t\t\t\\\t\t    SC_IA32_REGS_TO_ARGS(x, __VA_ARGS__))\n\n展开后得到：\nstatic const char *types__socket[] = &#123;\t\t\t\t&quot;int&quot;, &quot;int&quot;, &quot;int&quot;&#125;;\t\t\t\t\t\t\tstatic const char *args__socket[] = &#123;\t&quot;family&quot;, &quot;type&quot;, &quot;protocol&quot;&#125;;\t\t\t\t\t\t\tSYSCALL_TRACE_ENTER_EVENT(_socket);\t\t\tSYSCALL_TRACE_EXIT_EVENT(_socket);\t\t\tstatic struct syscall_metadata __used\t\t\t  __syscall_meta__socket = &#123;\t\t\t\t\t.name \t\t= &quot;sys_socket&quot;,\t\t\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t.nb_args \t= 3,\t\t\t\t\t.types\t\t= 3 ? types__socket : NULL,\t.args\t\t= 3 ? args__socket : NULL,\t\t.enter_event\t= &amp;event_enter__socket,\t\t\t.exit_event\t= &amp;event_exit__socket,\t\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta__socket.enter_fields),&#125;;\t\t\t\t\t\t\tstatic struct syscall_metadata __used\t\t\t  __section(&quot;__syscalls_metadata&quot;)\t\t\t *__p_syscall_meta__socket = &amp;__syscall_meta__socket; static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol);static inline long __do_sys_socket(int family, int type, int protocol);__SYS_STUBx(x64, sys_socket,\tSC_X86_64_REGS_TO_ARGS(3, int, family, int, type, int, protocol))\t__SYS_STUBx(ia32, sys_socket, SC_IA32_REGS_TO_ARGS(3, int, family, int, type, int, protocol))static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol)&#123;\t\t\t\t\t\t\t\t\tlong ret = __do_sys_socket((__force int)family, (__force int)type, (__force int)protocol);\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t__PROTECT(3, ret, family, type, protocol);\t\treturn ret;\t\t\t\t\t\t&#125;\t\t\t\t\t\t\t\tstatic inline long __do_sys_socket(int family, int type, int protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看 __SYS_STUBx 、 ALLOW_ERROR_INJECTION 的相关定义：\n#define __SYS_STUBx(abi, name, ...)\t\t\t\t\t\\\tlong __##abi##_##name(const struct pt_regs *regs);\t\t\\\tALLOW_ERROR_INJECTION(__##abi##_##name, ERRNO);\t\t\t\\\tlong __##abi##_##name(const struct pt_regs *regs)\t\t\\\t&#123;\t\t\t\t\t\t\t\t\\\t\treturn __se_##name(__VA_ARGS__);\t\t\t\\\t&#125;#define ALLOW_ERROR_INJECTION(fname, _etype)\n\n展开后得到：\nstatic const char *types__socket[] = &#123;\t\t\t\t&quot;int&quot;, &quot;int&quot;, &quot;int&quot;&#125;;\t\t\t\t\t\t\tstatic const char *args__socket[] = &#123;\t&quot;family&quot;, &quot;type&quot;, &quot;protocol&quot;&#125;;\t\t\t\t\t\t\tSYSCALL_TRACE_ENTER_EVENT(_socket);\t\t\tSYSCALL_TRACE_EXIT_EVENT(_socket);\t\t\tstatic struct syscall_metadata __used\t\t\t  __syscall_meta__socket = &#123;\t\t\t\t\t.name \t\t= &quot;sys_socket&quot;,\t\t\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t.nb_args \t= 3,\t\t\t\t\t.types\t\t= 3 ? types__socket : NULL,\t.args\t\t= 3 ? args__socket : NULL,\t\t.enter_event\t= &amp;event_enter__socket,\t\t\t.exit_event\t= &amp;event_exit__socket,\t\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta__socket.enter_fields),&#125;;\t\t\t\t\t\t\tstatic struct syscall_metadata __used\t\t\t  __section(&quot;__syscalls_metadata&quot;)\t\t\t *__p_syscall_meta__socket = &amp;__syscall_meta__socket; static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol);static inline long __do_sys_socket(int family, int type, int protocol);long __x64_sys_socket(const struct pt_regs *regs);long __x64_sys_socket(const struct pt_regs *regs)\t\t&#123;\t\t\t\t\t\t\t\t\treturn __se_sys_socket(SC_X86_64_REGS_TO_ARGS(3, int, family, int, type, int, protocol));\t\t&#125;long __ia32_sys_socket(const struct pt_regs *regs);long __ia32_sys_socket(const struct pt_regs *regs)\t\t&#123;\t\t\t\t\t\t\t\t\treturn __se_sys_socket(SC_IA32_REGS_TO_ARGS(3, int, family, int, type, int, protocol));\t\t&#125;static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol)&#123;\t\t\t\t\t\t\t\t\tlong ret = __do_sys_socket((__force int)family, (__force int)type, (__force int)protocol);\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t__PROTECT(3, ret, family, type, protocol);\t\treturn ret;\t\t\t\t\t\t&#125;\t\t\t\t\t\t\t\tstatic inline long __do_sys_socket(int family, int type, int protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看 SC_X86_64_REGS_TO_ARGS 、 SC_IA32_REGS_TO_ARGS 的相关定义：\n/* Mapping of registers to parameters for syscalls on x86-64 and x32 */#define SC_X86_64_REGS_TO_ARGS(x, ...)\t\t\t\t\t\\\t__MAP(x,__SC_ARGS\t\t\t\t\t\t\\\t\t,,regs-&gt;di,,regs-&gt;si,,regs-&gt;dx\t\t\t\t\\\t\t,,regs-&gt;r10,,regs-&gt;r8,,regs-&gt;r9)\t\t\t\\/* Mapping of registers to parameters for syscalls on i386 */#define SC_IA32_REGS_TO_ARGS(x, ...)\t\t\t\t\t\\\t__MAP(x,__SC_ARGS\t\t\t\t\t\t\\\t      ,,(unsigned int)regs-&gt;bx,,(unsigned int)regs-&gt;cx\t\t\\\t      ,,(unsigned int)regs-&gt;dx,,(unsigned int)regs-&gt;si\t\t\\\t      ,,(unsigned int)regs-&gt;di,,(unsigned int)regs-&gt;bp)\n\n展开后得到：\nstatic const char *types__socket[] = &#123;\t\t\t\t&quot;int&quot;, &quot;int&quot;, &quot;int&quot;&#125;;\t\t\t\t\t\t\tstatic const char *args__socket[] = &#123;\t&quot;family&quot;, &quot;type&quot;, &quot;protocol&quot;&#125;;\t\t\t\t\t\t\tSYSCALL_TRACE_ENTER_EVENT(_socket);\t\t\tSYSCALL_TRACE_EXIT_EVENT(_socket);\t\t\tstatic struct syscall_metadata __used\t\t\t  __syscall_meta__socket = &#123;\t\t\t\t\t.name \t\t= &quot;sys_socket&quot;,\t\t\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t.nb_args \t= 3,\t\t\t\t\t.types\t\t= 3 ? types__socket : NULL,\t.args\t\t= 3 ? args__socket : NULL,\t\t.enter_event\t= &amp;event_enter__socket,\t\t\t.exit_event\t= &amp;event_exit__socket,\t\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta__socket.enter_fields),&#125;;\t\t\t\t\t\t\tstatic struct syscall_metadata __used\t\t\t  __section(&quot;__syscalls_metadata&quot;)\t\t\t *__p_syscall_meta__socket = &amp;__syscall_meta__socket; static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol);static inline long __do_sys_socket(int family, int type, int protocol);long __x64_sys_socket(const struct pt_regs *regs);long __x64_sys_socket(const struct pt_regs *regs)\t\t&#123;\t\t\t\t\t\t\t\t\treturn __se_sys_socket(__MAP(3, __SC_ARGS,,regs-&gt;di,,regs-&gt;si,,regs-&gt;dx,,regs-&gt;r10,,regs-&gt;r8,,regs-&gt;r9));&#125;long __ia32_sys_socket(const struct pt_regs *regs);long __ia32_sys_socket(const struct pt_regs *regs)\t\t&#123;\t\t\t\t\t\t\t\t\treturn __se_sys_socket(__MAP(3,__SC_ARGS,,(unsigned int)regs-&gt;bx,,(unsigned int)regs-&gt;cx\t\t\t\t\t\t\t\t,,(unsigned int)regs-&gt;dx,,(unsigned int)regs-&gt;si      \t\t\t\t\t\t\t,,(unsigned int)regs-&gt;di,,(unsigned int)regs-&gt;bp));\t\t&#125;static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol)&#123;\t\t\t\t\t\t\t\t\tlong ret = __do_sys_socket((__force int)family, (__force int)type, (__force int)protocol);\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t__PROTECT(3, ret, family, type, protocol);\t\treturn ret;\t\t\t\t\t\t&#125;\t\t\t\t\t\t\t\tstatic inline long __do_sys_socket(int family, int type, int protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看  __MAP 、 __SC_ARGS 的相关定义：\n#define __MAP0(m,...)#define __MAP1(m,t,a,...) m(t,a)#define __MAP2(m,t,a,...) m(t,a), __MAP1(m,__VA_ARGS__)#define __MAP3(m,t,a,...) m(t,a), __MAP2(m,__VA_ARGS__)#define __MAP4(m,t,a,...) m(t,a), __MAP3(m,__VA_ARGS__)#define __MAP5(m,t,a,...) m(t,a), __MAP4(m,__VA_ARGS__)#define __MAP6(m,t,a,...) m(t,a), __MAP5(m,__VA_ARGS__)#define __MAP(n,...) __MAP##n(__VA_ARGS__)#define __SC_ARGS(t, a)\ta\n\n展开后得到：\nstatic const char *types__socket[] = &#123;\t\t\t\t&quot;int&quot;, &quot;int&quot;, &quot;int&quot;&#125;;\t\t\t\t\t\t\tstatic const char *args__socket[] = &#123;\t&quot;family&quot;, &quot;type&quot;, &quot;protocol&quot;&#125;;\t\t\t\t\t\t\tSYSCALL_TRACE_ENTER_EVENT(_socket);\t\t\tSYSCALL_TRACE_EXIT_EVENT(_socket);\t\t\tstatic struct syscall_metadata __used\t\t\t  __syscall_meta__socket = &#123;\t\t\t\t\t.name \t\t= &quot;sys_socket&quot;,\t\t\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t.nb_args \t= 3,\t\t\t\t\t.types\t\t= 3 ? types__socket : NULL,\t.args\t\t= 3 ? args__socket : NULL,\t\t.enter_event\t= &amp;event_enter__socket,\t\t\t.exit_event\t= &amp;event_exit__socket,\t\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta__socket.enter_fields),&#125;;\t\t\t\t\t\t\tstatic struct syscall_metadata __used\t\t\t  __section(&quot;__syscalls_metadata&quot;)\t\t\t *__p_syscall_meta__socket = &amp;__syscall_meta__socket; static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol);static inline long __do_sys_socket(int family, int, type, int, protocol);long __x64_sys_socket(const struct pt_regs *regs);long __x64_sys_socket(const struct pt_regs *regs)\t\t&#123;\t\t\t\t\t\t\t\t\treturn __se_sys_socket(regs-&gt;di, regs-&gt;si, regs-&gt;dx);&#125;long __ia32_sys_socket(const struct pt_regs *regs);long __ia32_sys_socket(const struct pt_regs *regs)\t\t&#123;\t\t\t\t\t\t\t\t\treturn __se_sys_socket((unsigned int)regs-&gt;bx, (unsigned int)regs-&gt;cx, (unsigned int)regs-&gt;dx);\t&#125;static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol)&#123;\t\t\t\t\t\t\t\t\tlong ret = __do_sys_socket((__force int)family, (__force int)type, (__force int)protocol);\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t__PROTECT(3, ret, family, type, protocol);\t\treturn ret;\t\t\t\t\t\t&#125;\t\t\t\t\t\t\t\tstatic inline long __do_sys_socket(int family, int type, int protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n\n继续查看  SYSCALL_TRACE_ENTER_EVENT 、 SYSCALL_TRACE_EXIT_EVENT 的相关定义：\n#define SYSCALL_TRACE_ENTER_EVENT(sname)\t\t\t\t\\\tstatic struct syscall_metadata __syscall_meta_##sname;\t\t\\\tstatic struct trace_event_call __used\t\t\t\t\\\t  event_enter_##sname = &#123;\t\t\t\t\t\\\t\t.class\t\t\t= &amp;event_class_syscall_enter,\t\\\t\t&#123;\t\t\t\t\t\t\t\\\t\t\t.name                   = &quot;sys_enter&quot;#sname,\t\\\t\t&#125;,\t\t\t\t\t\t\t\\\t\t.event.funcs            = &amp;enter_syscall_print_funcs,\t\\\t\t.data\t\t\t= (void *)&amp;__syscall_meta_##sname,\\\t\t.flags                  = TRACE_EVENT_FL_CAP_ANY,\t\\\t&#125;;\t\t\t\t\t\t\t\t\\\tstatic struct trace_event_call __used\t\t\t\t\\\t  __section(&quot;_ftrace_events&quot;)\t\t\t\t\t\\\t *__event_enter_##sname = &amp;event_enter_##sname;#define SYSCALL_TRACE_EXIT_EVENT(sname)\t\t\t\t\t\\\tstatic struct syscall_metadata __syscall_meta_##sname;\t\t\\\tstatic struct trace_event_call __used\t\t\t\t\\\t  event_exit_##sname = &#123;\t\t\t\t\t\\\t\t.class\t\t\t= &amp;event_class_syscall_exit,\t\\\t\t&#123;\t\t\t\t\t\t\t\\\t\t\t.name                   = &quot;sys_exit&quot;#sname,\t\\\t\t&#125;,\t\t\t\t\t\t\t\\\t\t.event.funcs\t\t= &amp;exit_syscall_print_funcs,\t\\\t\t.data\t\t\t= (void *)&amp;__syscall_meta_##sname,\\\t\t.flags                  = TRACE_EVENT_FL_CAP_ANY,\t\\\t&#125;;\t\t\t\t\t\t\t\t\\\tstatic struct trace_event_call __used\t\t\t\t\\\t  __section(&quot;_ftrace_events&quot;)\t\t\t\t\t\\\t*__event_exit_##sname = &amp;event_exit_##sname;\n\n展开后得到：\nstatic const char *types__socket[] = &#123;\t\t\t\t&quot;int&quot;, &quot;int&quot;, &quot;int&quot;&#125;;\t\t\t\t\t\t\tstatic const char *args__socket[] = &#123;\t&quot;family&quot;, &quot;type&quot;, &quot;protocol&quot;&#125;;\t\t\t\t\t\t\tstatic struct syscall_metadata __syscall_meta__socket;\tstatic struct trace_event_call __used event_enter__socket = &#123;\t\t\t\t\t\t.class\t\t\t= &amp;event_class_syscall_enter,\t\t&#123;\t\t\t\t\t\t\t\t\t.name                   = &quot;sys_enter_socket&quot;,\t\t&#125;,\t\t\t\t\t\t\t.event.funcs            = &amp;enter_syscall_print_funcs,\t.data\t\t\t= (void *)&amp;__syscall_meta__socket,\t.flags                  = TRACE_EVENT_FL_CAP_ANY,\t&#125;;\t\t\t\t\t\t\t\tstatic struct trace_event_call __used __section(&quot;_ftrace_events&quot;) *__event_enter__socket = &amp;event_enter__socket;static struct syscall_metadata __syscall_meta__socket;\tstatic struct trace_event_call __used event_exit__socket = &#123;\t\t\t\t\t\t.class\t\t\t= &amp;event_class_syscall_exit,\t\t&#123;\t\t\t\t\t\t\t\t\t.name                   = &quot;sys_exit_socket&quot;,\t\t&#125;,\t\t\t\t\t\t\t\t.event.funcs\t\t= &amp;exit_syscall_print_funcs,\t\t.data\t\t\t= (void *)&amp;__syscall_meta__socket,\t.flags                  = TRACE_EVENT_FL_CAP_ANY,\t&#125;;\t\t\t\t\t\t\t\tstatic struct trace_event_call __used __section(&quot;_ftrace_events&quot;) *__event_exit__socket = &amp;event_exit__socket;static struct syscall_metadata __used __syscall_meta__socket = &#123;\t\t\t\t\t.name \t\t= &quot;sys_socket&quot;,\t\t\t\t.syscall_nr\t= -1,\t/* Filled in at boot */\t.nb_args \t= 3,\t\t\t\t\t.types\t\t= 3 ? types__socket : NULL,\t.args\t\t= 3 ? args__socket : NULL,\t\t.enter_event\t= &amp;event_enter__socket,\t\t\t.exit_event\t= &amp;event_exit__socket,\t\t\t.enter_fields\t= LIST_HEAD_INIT(__syscall_meta__socket.enter_fields),&#125;;\t\t\t\t\t\t\tstatic struct syscall_metadata __used __section(&quot;__syscalls_metadata&quot;) *__p_syscall_meta__socket = &amp;__syscall_meta__socket; static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol);static inline long __do_sys_socket(int family, int type, int protocol);long __x64_sys_socket(const struct pt_regs *regs);long __x64_sys_socket(const struct pt_regs *regs)\t\t&#123;\t\t\t\t\t\t\t\t\treturn __se_sys_socket(regs-&gt;di, regs-&gt;si, regs-&gt;dx);&#125;long __ia32_sys_socket(const struct pt_regs *regs);long __ia32_sys_socket(const struct pt_regs *regs)\t\t&#123;\t\t\t\t\t\t\t\t\treturn __se_sys_socket((unsigned int)regs-&gt;bx, (unsigned int)regs-&gt;cx, (unsigned int)regs-&gt;dx);\t&#125;static long __se_sys_socket(__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) family, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) type, \t\t\t\t\t\t\t__typeof(__builtin_choose_expr(__TYPE_IS_LL(int), 0LL, 0L)) protocol)&#123;\t\t\t\t\t\t\t\t\tlong ret = __do_sys_socket((__force int)family, (__force int)type, (__force int)protocol);\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t(void)BUILD_BUG_ON_ZERO(!__TYPE_IS_LL(int) &amp;&amp; sizeof(int) &gt; sizeof(long)),\t__PROTECT(3, ret, family, type, protocol);\t\treturn ret;\t\t\t\t\t\t&#125;\t\t\t\t\t\t\t\tstatic inline long __do_sys_socket(int family, int type, int protocol)&#123;\treturn __sys_socket(family, type, protocol);&#125;\n\n整体流程大概就是这样串起来的，到此就一目了然了。对于syscall来说，4.7内核版本是个分界线。因为sys_call_table里存的函数由 真正的系统调用实现函数 变成了 系统调用实现函数wrapper函数，多了一次，这是值得注意的地方。\n","categories":["linux6.6内核"],"tags":["syscall"]}]